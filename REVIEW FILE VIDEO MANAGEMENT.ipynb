{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356e59f7",
   "metadata": {},
   "source": [
    "ATO MIASA MI COPIER REVIEW FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5191b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated translation review file has been saved as to translate/translation_review_updated.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_segments(content):\n",
    "    \"\"\"\n",
    "    Parse the content into segments based on the segment header.\n",
    "    Returns a dictionary with segment numbers (as integers) as keys and the full segment text as values.\n",
    "    \"\"\"\n",
    "    segments = {}\n",
    "    # The pattern finds segments that start with \"Segment <number>\" until the next segment or end of file.\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, content, re.DOTALL | re.MULTILINE)\n",
    "    for full_seg, seg_no in matches:\n",
    "        segments[int(seg_no)] = full_seg\n",
    "    return segments\n",
    "\n",
    "def get_field_text(segment_text, field_name):\n",
    "    \"\"\"\n",
    "    Extract the text following a given field marker (e.g., **Original:**, **Auto Translated:**, **Final Translation:**)\n",
    "    from the segment text. Returns the text stripped of leading/trailing spaces.\n",
    "    \"\"\"\n",
    "    # Using a regex pattern that stops at the end of the line.\n",
    "    pattern = r\"\\*\\*\" + re.escape(field_name) + r\":\\*\\*\\s*(.*)\"\n",
    "    match = re.search(pattern, segment_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def update_segment_fields(review_segment, updated_segment, fields):\n",
    "    \"\"\"\n",
    "    Replace the specified fields in the review_segment with the ones extracted\n",
    "    from the updated_segment.\n",
    "    \n",
    "    fields should be a list of field names such as [\"Original\", \"Auto Translated\", \"Final Translation\"].\n",
    "    \"\"\"\n",
    "    updated_seg = review_segment\n",
    "    for field in fields:\n",
    "        new_text = get_field_text(updated_segment, field)\n",
    "        if new_text is not None:\n",
    "            # Replace the entire line for the field in the review segment.\n",
    "            # The regex captures the marker and then replaces what follows.\n",
    "            pattern = r\"(\\*\\*\" + re.escape(field) + r\":\\*\\*\\s*).*$\"\n",
    "            replacement = r\"\\1\" + new_text\n",
    "            updated_seg = re.sub(pattern, replacement, updated_seg, flags=re.MULTILINE)\n",
    "    return updated_seg\n",
    "\n",
    "def update_translation_review(review_content, updated_segments, fields):\n",
    "    \"\"\"\n",
    "    For each segment in review_content, replace the specified fields with those from the updated segments.\n",
    "    \"\"\"\n",
    "    # Find the segments in review content using the same segmentation parser.\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, review_content, re.DOTALL | re.MULTILINE)\n",
    "\n",
    "    updated_content = review_content  # Work on a copy to allow replacements.\n",
    "\n",
    "    for full_seg, seg_no in matches:\n",
    "        seg_no_int = int(seg_no)\n",
    "        if seg_no_int in updated_segments:\n",
    "            # Replace the fields (Original, Auto Translated, Final Translation) based on updated segments.\n",
    "            new_seg = update_segment_fields(full_seg, updated_segments[seg_no_int],\n",
    "                                            fields)\n",
    "            # Replace the old segment in the overall content with the updated segment.\n",
    "            updated_content = updated_content.replace(full_seg, new_seg)\n",
    "    return updated_content\n",
    "\n",
    "def main():\n",
    "    # Define the file paths (adjust these paths as needed)\n",
    "    updated_file_path = \"to translate/translation_review_modifs ad 05.08 (2).txt\"\n",
    "    review_file_path = \"to translate/translation_review.txt\"\n",
    "    \n",
    "    # Read the updated file content\n",
    "    with open(updated_file_path, encoding='utf-8') as f:\n",
    "        updated_content = f.read()\n",
    "    \n",
    "    # Read the review file content\n",
    "    with open(review_file_path, encoding='utf-8') as f:\n",
    "        review_content = f.read()\n",
    "    \n",
    "    # Parse segments from the updated file content\n",
    "    updated_segments = parse_segments(updated_content)\n",
    "    \n",
    "    # Define the list of fields to update.\n",
    "    fields_to_update = [\"Original\", \"Auto Translated\", \"Final Translation\"]\n",
    "    \n",
    "    # Replace the fields in the review content using the updated segments\n",
    "    new_review_content = update_translation_review(review_content, updated_segments,\n",
    "                                                   fields_to_update)\n",
    "    \n",
    "    # Write the updated content to a new file (or overwrite the original file if desired)\n",
    "    output_file_path = \"to translate/translation_review_updated.txt\"\n",
    "    with open(output_file_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(new_review_content)\n",
    "    \n",
    "    print(f\"Updated translation review file has been saved as {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9cab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated translation review file has been saved as to translate/translation_review_updated.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_segments(content):\n",
    "    \"\"\"\n",
    "    Parse the content into segments using a regular expression that captures each segment.\n",
    "    Returns a dictionary with segment numbers (as integers) as keys and the full segment text as values.\n",
    "    \"\"\"\n",
    "    segments = {}\n",
    "    # This pattern finds segments that start with \"Segment <number>\" and goes until the next segment or end of file.\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, content, re.DOTALL | re.MULTILINE)\n",
    "    for full_seg, seg_no in matches:\n",
    "        segments[int(seg_no)] = full_seg\n",
    "    return segments\n",
    "\n",
    "def get_final_translation(segment_text):\n",
    "    \"\"\"\n",
    "    Extracts the final translation text from a segment.\n",
    "    It looks for the pattern **Final Translation:** followed by any text.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\*\\*Final Translation:\\*\\*\\s*(.*)\", segment_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def update_translation_review(review_content, updated_segments):\n",
    "    \"\"\"\n",
    "    For each segment in the review file's content, replaces the **Final Translation:** text\n",
    "    with the one from the updated segments.\n",
    "    \"\"\"\n",
    "    # Parse the review content into segments using the same parser\n",
    "    review_segments = {}\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, review_content, re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    updated_content = review_content  # Work on a copy of the content\n",
    "\n",
    "    for full_seg, seg_no in matches:\n",
    "        seg_no_int = int(seg_no)\n",
    "        if seg_no_int in updated_segments:\n",
    "            updated_final = get_final_translation(updated_segments[seg_no_int])\n",
    "            if updated_final is not None:\n",
    "                # Replace the **Final Translation:** line in this segment with the new translation.\n",
    "                # This regex pattern matches the '**Final Translation:**' line and captures the prefix.\n",
    "                new_seg = re.sub(\n",
    "                    r\"(\\*\\*Final Translation:\\*\\*\\s*).*\",  # match the line starting with **Final Translation:**\n",
    "                    r\"\\1\" + updated_final,  # replace with the captured prefix plus the updated text\n",
    "                    full_seg\n",
    "                )\n",
    "                # Replace the old segment in the content with the updated segment.\n",
    "                updated_content = updated_content.replace(full_seg, new_seg)\n",
    "\n",
    "    return updated_content\n",
    "\n",
    "def main():\n",
    "    # Define file paths (make sure these paths are correct)\n",
    "    updated_file_path = \"to translate/translation_review_farany.txt\"\n",
    "    review_file_path = \"to translate/translation_review.txt\"\n",
    "    \n",
    "    # Read updated file content\n",
    "    with open(updated_file_path, encoding='utf-8') as f:\n",
    "        updated_content = f.read()\n",
    "    \n",
    "    # Read review file content\n",
    "    with open(review_file_path, encoding='utf-8') as f:\n",
    "        review_content = f.read()\n",
    "    \n",
    "    # Parse segments from the updated content\n",
    "    updated_segments = parse_segments(updated_content)\n",
    "    \n",
    "    # Replace the **Final Translation:** values in the review content\n",
    "    new_review_content = update_translation_review(review_content, updated_segments)\n",
    "    \n",
    "    # Write the updated content to a new file (or overwrite the original file if desired)\n",
    "    output_file_path = \"to translate/translation_review_updated.txt\"\n",
    "    with open(output_file_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(new_review_content)\n",
    "    \n",
    "    print(f\"Updated translation review file has been saved as {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61940deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1921' coro=<async_main() done, defined at C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py:401> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py\", line 419, in <module>\n",
      "    asyncio.run(async_main())\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py\", line 407, in async_main\n",
      "    language, segments = transcribe(audio_path)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py\", line 70, in transcribe\n",
      "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py\", line 900, in transcribe\n",
      "    ) = self.detect_language(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py\", line 1777, in detect_language\n",
      "    encoder_output = self.encode(\n",
      "                     ^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py\", line 1358, in encode\n",
      "    return self.model.encode(features, to_cpu=to_cpu)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 419\u001b[39m\n\u001b[32m    416\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m persistent_connector.close()\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py:133\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m curr_task = curr_tasks.pop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[43mhandle\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py:84\u001b[39m, in \u001b[36mHandle._run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 407\u001b[39m, in \u001b[36masync_main\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    405\u001b[39m audio_path = extract_audio()\n\u001b[32m    406\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTranscribing audio...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m language, segments = \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating English subtitles...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    409\u001b[39m generate_subtitle_file(segments, subtitle_file_en)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mtranscribe\u001b[39m\u001b[34m(audio_path)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDetected language: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m transcript_segments = []\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtranscript_segments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstart\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m language, transcript_segments\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py:1148\u001b[39m, in \u001b[36mWhisperModel.generate_segments\u001b[39m\u001b[34m(self, features, tokenizer, options, log_progress, encoder_output)\u001b[39m\n\u001b[32m   1145\u001b[39m previous_tokens = all_tokens[prompt_reset_since:]\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seek > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m encoder_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1148\u001b[39m     encoder_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m options.multilingual:\n\u001b[32m   1151\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.model.detect_language(encoder_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py:1358\u001b[39m, in \u001b[36mWhisperModel.encode\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m   1355\u001b[39m     features = np.expand_dims(features, \u001b[32m0\u001b[39m)\n\u001b[32m   1356\u001b[39m features = get_ctranslate2_storage(features)\n\u001b[32m-> \u001b[39m\u001b[32m1358\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "from aiohttp import ClientConnectorError\n",
    "import random\n",
    "import concurrent.futures\n",
    "import pyttsx3\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.2_Flux de navigation_Avr_08_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Choose which TTS engine to use by default:\n",
    "# If USE_PYTTSX3 is True then offline pyttsx3 will be used,\n",
    "# otherwise robust Edge TTS (cloud-based) is used.\n",
    "USE_PYTTSX3 = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"---\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r\"[.!?]$\", word):\n",
    "            if (i == len(words) - 1) or (words[i + 1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Robust Edge TTS and Offline pyttsx3 Fallback ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Uses exponential backoff with jitter.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(connector=connector, timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate,\n",
    "                    connector=connector\n",
    "                )\n",
    "                await communicate.save(output_path)\n",
    "                return\n",
    "        except (ClientConnectorError, ConnectionResetError) as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Connection error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "def synthesize_phrase_pyttsx3(phrase: str, output_path: str, voice: str = None, rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Synthesize speech using offline pyttsx3.\n",
    "    Saves the output as a WAV file.\n",
    "    \"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    if voice is not None:\n",
    "        engine.setProperty(\"voice\", voice)\n",
    "    base_rate = engine.getProperty(\"rate\")\n",
    "    try:\n",
    "        modifier = int(rate.strip(\" %+\"))\n",
    "    except Exception:\n",
    "        modifier = 0\n",
    "    new_rate = base_rate + modifier\n",
    "    engine.setProperty(\"rate\", new_rate)\n",
    "    # Save to file (WAV format)\n",
    "    engine.save_to_file(phrase, output_path)\n",
    "    engine.runAndWait()\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Wrapper function to choose the TTS engine.\n",
    "    If USE_PYTTSX3 is True, use the offline pyttsx3 engine (runs in executor);\n",
    "    otherwise, use robust Edge TTS.\n",
    "    \"\"\"\n",
    "    if USE_PYTTSX3:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        with concurrent.futures.ThreadPoolExecutor() as pool:\n",
    "            await loop.run_in_executor(pool, synthesize_phrase_pyttsx3, phrase, output_path, voice, rate)\n",
    "    else:\n",
    "        await robust_synthesize_phrase(phrase, output_path, connector, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, connector, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Persistent Connector Creation ==============\n",
    "def create_persistent_connector():\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context, limit=10)\n",
    "    return connector\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path, persistent_connector):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(\n",
    "                    phrase, temp_path, connector=persistent_connector, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            # Now try to load the file; if decoding fails, fallback to pyttsx3\n",
    "            try:\n",
    "                audio = AudioSegment.from_mp3(temp_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Decoding failed for file {temp_path}: {e}. Falling back to offline pyttsx3.\")\n",
    "                fallback_path = temp_path.replace(\".mp3\", \".wav\")\n",
    "                try:\n",
    "                    synthesize_phrase_pyttsx3(phrase, fallback_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "                    audio = AudioSegment.from_file(fallback_path, format=\"wav\")\n",
    "                    os.remove(fallback_path)\n",
    "                except Exception as ex:\n",
    "                    print(f\"[Warning] Offline fallback failed for phrase '{phrase}': {ex}. Skipping this phrase.\")\n",
    "                    continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    persistent_connector = create_persistent_connector()\n",
    "    try:\n",
    "        print(\"Extracting audio...\")\n",
    "        audio_path = extract_audio()\n",
    "        print(\"Transcribing audio...\")\n",
    "        language, segments = transcribe(audio_path)\n",
    "        print(\"Generating English subtitles...\")\n",
    "        generate_subtitle_file(segments, subtitle_file_en)\n",
    "        print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "        await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file, persistent_connector)\n",
    "        print(\"Merging audio and video...\")\n",
    "        merge_audio_video()\n",
    "        print(f\"Process completed! Output video: {output_video}\")\n",
    "    finally:\n",
    "        await persistent_connector.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import random\n",
    "import concurrent.futures\n",
    "import pyttsx3\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version, we use only offline pyttsx3.\n",
    "USE_PYTTSX3 = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"---\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r\"[.!?]$\", word):\n",
    "            if (i == len(words) - 1) or (words[i + 1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Offline pyttsx3 Only ==============\n",
    "def synthesize_phrase_pyttsx3(phrase: str, output_path: str, voice: str = None, rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Synthesize speech using offline pyttsx3.\n",
    "    Saves the output as a WAV file.\n",
    "    \"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    # Optionally set the voice if available on your system.\n",
    "    if voice is not None:\n",
    "        engine.setProperty(\"voice\", voice)\n",
    "    base_rate = engine.getProperty(\"rate\")\n",
    "    try:\n",
    "        modifier = int(rate.strip(\" %+\"))\n",
    "    except Exception:\n",
    "        modifier = 0\n",
    "    new_rate = base_rate + modifier\n",
    "    engine.setProperty(\"rate\", new_rate)\n",
    "    engine.save_to_file(phrase, output_path)\n",
    "    engine.runAndWait()\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Asynchronous wrapper for pyttsx3 synthesis.\n",
    "    Runs the blocking pyttsx3 call inside an executor.\n",
    "    \"\"\"\n",
    "    loop = asyncio.get_event_loop()\n",
    "    with concurrent.futures.ThreadPoolExecutor() as pool:\n",
    "        await loop.run_in_executor(pool, synthesize_phrase_pyttsx3, phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.wav\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            try:\n",
    "                audio = AudioSegment.from_file(temp_path, format=\"wav\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Unable to load audio from {temp_path}: {e}. Skipping this phrase.\")\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "                continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94202637",
   "metadata": {},
   "source": [
    "testa hanova voix -ATO NDRAY MIASA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e5ec9",
   "metadata": {},
   "source": [
    "to translate/4.2.2_Flux de navigation_Avr_08_Latest.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n",
      "Detected language: en\n",
      "Generating English subtitles...\n",
      "Generating French audio with synchronization and manual overrides...\n",
      "✅ Review file created at: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\translation_review.txt  (split into 28 segments)\n",
      "Parsed review overrides:\n",
      "  Segment 1: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 2: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 3: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 4: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 5: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 6: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 7: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 8: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 9: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 10: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 11: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 12: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 13: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 14: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 15: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 16: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 17: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 18: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 19: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 20: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 21: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 22: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 23: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 24: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 25: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 26: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous allons voir les configurations de l'application EPM.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous verrons comment créer une règle métier ou une formule de membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous verrons comment la sécurité fonctionne dans l'application EPM et nous couvrirons comment créer et configurer des formulaires de données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La sécurité dans EPM comprendra la sécurité dimensionnelle, la sécurité des artefacts, la sécurité par tâches ou le flux de travail, la sécurité des règles métier et la sécurité des données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'À partir de la page d'accueil, cliquez sur le navigateur et accédez aux dimensions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Maintenant, je vais sélectionner le cube et pour la dimension du compte, je vais rechercher le membre pour lequel je souhaite mettre à jour la formule du membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que le membre est mis en évidence, nous pouvons modifier les propriétés de formule de membres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons sélectionner le cube pour voir la formule du membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La formule des membres est utilisée n'importe où dans l'application.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ici, le matériel OFS sera divisé par le volume OFS.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que nous avons la formule des membres, nous pouvons la valider et nous pouvons voir qu'elle est validée avec succès.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que nous avons la formule des membres, nous pouvons la valider et nous pouvons voir qu'elle est validée avec succès.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B2F0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.18 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que nous avons la formule des membres, nous pouvons la valider et nous pouvons voir qu'elle est validée avec succès.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons enregistrer, réinitialiser ou annuler.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais annuler dans ce cas.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je vais annuler dans ce cas.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B800> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.23 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je vais annuler dans ce cas.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Je vais annuler dans ce cas.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BA40> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.19 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Je vais annuler dans ce cas.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour voir une règle métier, cliquer sur l'icône Navigateur et cliquer sur Règles.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ceci ouvrira la fenêtre de Calculation Manager qui est également appelé règles métier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous pouvez voir l'application EPM Cloud et l'expansion nous montrera l'EPBCS et nous allons créer la règle sous OEP FS.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Vous pouvez voir l'application EPM Cloud et l'expansion nous montrera l'EPBCS et nous allons créer la règle sous OEP FS.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AF90> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.50 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Vous pouvez voir l'application EPM Cloud et l'expansion nous montrera l'EPBCS et nous allons créer la règle sous OEP FS.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Permettez-moi de sélectionner OEP FS et sous des actions, je peux soit créer une nouvelle règle, script, formule, je peux importer, je peux voir les propriétés.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans cette démo, je vais créer une règle.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comme j'ai sélectionné le cube et l'application, toutes ces informations sont prépopulées.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais sélectionner Règles en créant une formule de membre avec ce nom et je vais cliquer sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Il dira que la règle a été créé et si nous voulons apporter des modifications.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais dire oui et une fois que nous avons créé, ceci est la première page que nous allons voir et surtout les administrateurs utilisent la vue de concepteur et il y a aussi une vue de script.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais sélectionner la vue du script.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons toutes les dimensions requises dont nous avons besoin ici et je vais actuellement copier les données de FY24 pour le scénario plan, working de la contrepartie de l'allocation d'entité au plan FY23, working, contrepartie de l'allocation d'entité.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous avons toutes les dimensions requises dont nous avons besoin ici et je vais actuellement copier les données de FY24 pour le scénario plan, working de la contrepartie de l'allocation d'entité au plan FY23, working, contrepartie de l'allocation d'entité.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B800> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.91 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous avons toutes les dimensions requises dont nous avons besoin ici et je vais actuellement copier les données de FY24 pour le scénario plan, working de la contrepartie de l'allocation d'entité au plan FY23, working, contrepartie de l'allocation d'entité.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_10.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Il s'agit d'une règle métier de base.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Il s'agit d'une règle métier de base.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B0B0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.39 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Il s'agit d'une règle métier de base.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_11.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons avoir des règles métier pour des scénarios complexes et toutes ces règles métiers s'exécutent en quelques secondes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_12.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais donc le valider et le sauver.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_13.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que je l'ai enregistré, je peux la déployer.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que je l'ai enregistré, je peux la déployer.'. Exception: No audio was received. Please verify that your parameters are correct.\n",
      "[Debug] Retrying in 1.34 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que je l'ai enregistré, je peux la déployer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_3_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Maintenant, je vais ouvrir un formulaire de données pour montrer comment fonctionne cette règle métier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_4_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai déjà un formulaire ici et comme vous pouvez le voir, c'est FY23-24 et j'ai des données dans FY24 pour tous les trimestres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_5_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour FY23, je n'ai pas de données pour cette intersection.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_5_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour copier des données, nous devons simplement exécuter la règle métier et il copiera les données de FY24 à FY23 une fois que j'ai exécuté la règle.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais aller à ma règle et cliquer sur ce bouton, lance la règle métier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais la lancer.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je vais la lancer.'. Exception: No audio was received. Please verify that your parameters are correct.\n",
      "[Debug] Retrying in 1.31 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je vais la lancer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons faire lancer cette règle métier à partir d'ici ou nous pouvons joindre cette règle métier à tout autre artéfact comme les formulaires de données ou tableau de bord.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur Actualiser.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous voyez comment les données sont copiées et elles sont remplies dans ce formulaire.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Vous voyez comment les données sont copiées et elles sont remplies dans ce formulaire.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B5C0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.08 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Vous voyez comment les données sont copiées et elles sont remplies dans ce formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'L'exécuter à partir du calculation manager, je peux joindre la règle métier directement au formulaire et vérifier les options comme exécuter à l'enregistrement, exécuter au chargement.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cela nous aide donc à exécuter les règles une fois que nous avons cliqué sur le bouton Enregistrer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également céduler la règle métier dans nos automations et gérer dans le cadre des travaux quotidiens d'automatisation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La sécurité peut être appliquée aux règles métiers qui permettront de restreindre les utilisateurs et ceci peut être fait en utilisant la sécurité des règles métier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour en savoir plus sur la sécurité, cliquez sur Outils et accédez au contrôle d'accès où nous pouvons créer des groupes pour gérer les utilisateurs au sein de ces groupes et nous avons des groupes définis par défaut qui définissent les administrateurs système, les super utilisateurs, les utilisateurs et les utilisateurs en lecture seule.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons voir la liste des utilisateurs ici.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons voir la liste des utilisateurs ici.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AF90> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.86 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons voir la liste des utilisateurs ici.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous pouvons voir la liste des utilisateurs ici.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B410> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.25 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous pouvons voir la liste des utilisateurs ici.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons attribuer différents rôles à ces utilisateurs, ce qui les aidera à effectuer plusieurs tâches.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons attribuer des rôles supplémentaires aux groupes ou à l'utilisateur qui les aideront à créer ou à exécuter des intégrations, à gérer ou à approuver les gestionnaires de tâches, à créer et à utiliser des formulaires ad hoc.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons exporter à partir de n'importe quelle instance et importer un format CSV avec la liste des utilisateurs et des groupes à partir de toute instance différente dans cette instance particulière.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais montrer plus de détails sur la façon dont la sécurité joue un rôle majeur dans EPM.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Regardons la sécurité dimensionnelle.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour cette dimension particulière, nous avons des rôles de sécurité affectés à chaque niveau de membre, ce qui donnera accès seulement à des utilisateurs particuliers ou à des groupes assignés.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons créer ou ajouter des utilisateurs et nous pouvons attribuer des accès en lecture, écriture ou sans accès, ainsi que des fonctions comme les membres, les enfants du membre, ou les descendants du membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La sécurité attribue la sécurité des niveaux d'artefacts comme les formulaires de données, les rapports, les tableaux de bord, les tâches, les flux.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Voyons comment nous pouvons attribuer la sécurité pour un formulaire de données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais aller dans le dossier Démo et j'ai un formulaire et en cliquant sur ceci, je vais ajouter un groupe et donc le groupe Account Recon, lecture, si je l'ajoute et leur donne les fonctions requises, ils pourront accéder à ce formulaire de données particulier et il sera limité pour les autres utilisateurs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous allons maintenant regarder la sécurité au niveau des données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les intersections valides peuvent vous aider à contrôler la saisie des données en définissant des combinaisons valides des membres de la dimension pour éviter les entrées de données non valides.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Les intersections valides peuvent vous aider à contrôler la saisie des données en définissant des combinaisons valides des membres de la dimension pour éviter les entrées de données non valides.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B6F2240E0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.52 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Les intersections valides peuvent vous aider à contrôler la saisie des données en définissant des combinaisons valides des membres de la dimension pour éviter les entrées de données non valides.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devons simplement définir les combinaisons et l'enregistrer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons également une sécurité au niveau des cellules qui contrôle l'accès aux cellules individuelles en fonction des dimensions et des sélections de membres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons créer une nouvelle ou faire une importation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Voyons comment créer et configurer un formulaire de données. À partir de la page d'accueil cliquez sur la carte Données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Sous actions, nous pouvons créer un ad hoc ou créer un formulaire.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Sous actions, nous pouvons créer un ad hoc ou créer un formulaire.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B4A0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.65 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Sous actions, nous pouvons créer un ad hoc ou créer un formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur Créer un formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devons entrer le nom.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devrons sélectionner le cube.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous aurons toutes les dimensions ici.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_10.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devons faire glisser les dimensions sur les lignes et colonnes respectives.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_11.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également avoir des dimensions sur les pages.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_12.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devrons sélectionner les membres en conséquence.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_13.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cliquer sur l'icône me donnera le sélecteur de membres et je peux ajouter le membre requis.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Cliquer sur l'icône me donnera le sélecteur de membres et je peux ajouter le membre requis.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B380> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.84 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Cliquer sur l'icône me donnera le sélecteur de membres et je peux ajouter le membre requis.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_14.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai la possibilité de personnaliser en fonction de la façon dont je veux voir les données si j'ai besoin de menus.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai la possibilité de personnaliser en fonction de la façon dont je veux voir les données si j'ai besoin de menus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BB60> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.56 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai la possibilité de personnaliser en fonction de la façon dont je veux voir les données si j'ai besoin de menus.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'J'ai la possibilité de personnaliser en fonction de la façon dont je veux voir les données si j'ai besoin de menus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.55 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'J'ai la possibilité de personnaliser en fonction de la façon dont je veux voir les données si j'ai besoin de menus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_15.mp3\n",
      "[Debug] Segment 10: adjusting speed factor=1.001\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les menus nous aident à passer d'un formulaire à un autre juste en cliquant avec le bouton droit sur le formulaire de données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'C'est là que nous pouvons ajouter une règle métier que nous avons créée pour cette application.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'C'est là que nous pouvons ajouter une règle métier que nous avons créée pour cette application.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B020> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.01 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'C'est là que nous pouvons ajouter une règle métier que nous avons créée pour cette application.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons dire comment nous voulons gérer cette règle métier.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons dire comment nous voulons gérer cette règle métier.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AF00> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.75 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons dire comment nous voulons gérer cette règle métier.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous pouvons dire comment nous voulons gérer cette règle métier.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BEC0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.21 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous pouvons dire comment nous voulons gérer cette règle métier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans la disposition, nous pouvons voir différentes options si nous voulons supprimer les données, supprimer les lignes, supprimer les colonnes.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Dans la disposition, nous pouvons voir différentes options si nous voulons supprimer les données, supprimer les lignes, supprimer les colonnes.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.57 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Dans la disposition, nous pouvons voir différentes options si nous voulons supprimer les données, supprimer les lignes, supprimer les colonnes.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Dans la disposition, nous pouvons voir différentes options si nous voulons supprimer les données, supprimer les lignes, supprimer les colonnes.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B260> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.17 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Dans la disposition, nous pouvons voir différentes options si nous voulons supprimer les données, supprimer les lignes, supprimer les colonnes.'\n",
      "[Error] Attempt 3/5 failed for phrase: 'Dans la disposition, nous pouvons voir différentes options si nous voulons supprimer les données, supprimer les lignes, supprimer les colonnes.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B2F0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 4.01 seconds...\n",
      "[Debug] Attempt 4: Synthesizing phrase: 'Dans la disposition, nous pouvons voir différentes options si nous voulons supprimer les données, supprimer les lignes, supprimer les colonnes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons définir des propriétés pour les dimensions si nous voulons voir l'alias du membre au lieu du nom du membre, masquer le membre, voir la description.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également définir les propriétés de segment qui est une propriété de ligne et la propriété de colonne et ce que nous voulons voir.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons également définir les propriétés de segment qui est une propriété de ligne et la propriété de colonne et ce que nous voulons voir.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.07 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons également définir les propriétés de segment qui est une propriété de ligne et la propriété de colonne et ce que nous voulons voir.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous pouvons également définir les propriétés de segment qui est une propriété de ligne et la propriété de colonne et ce que nous voulons voir.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9A960> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.36 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous pouvons également définir les propriétés de segment qui est une propriété de ligne et la propriété de colonne et ce que nous voulons voir.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons également différentes options en termes de façon de voir les données sous ce formulaire particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Il y a également des règles pour valider certaines conditions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai créé le formulaire de données en conservant la version, le produit, le marché, la devise et le type d'usine dans le point de vue et le scénario dans la page.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans les colonnes, nous avons l'année, la période et le compte.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans les lignes, nous avons l'entité.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_10.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai utilisé une variable de substitution ou une variable utilisateur ici.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_11.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, en sélectionnant l'icône du sélecteur de membres, nous voyons les membres mais aussi nous voyons des variables.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_12.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons définir les variables qui nous aideront à préparer dynamiquement le formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_13.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai mis une condition ici pour la ligne 3.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_14.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Donc, si la valeur de la devise est supérieure à 6000, la cellule doit être en rouge.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons valider la condition et nous obtiendrons la boîte de dialogue.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous cliquerons sur OK.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous cliquerons sur OK.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B5C0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.87 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous cliquerons sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous cliquerons à nouveau sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais enregistrer ce formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais fermer ce formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ceci est le formulaire que nous avons modifiée.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Ceci est le formulaire que nous avons modifiée.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.47 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Ceci est le formulaire que nous avons modifiée.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Ceci est le formulaire que nous avons modifiée.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AD50> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.18 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Ceci est le formulaire que nous avons modifiée.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais l'ouvrir.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En développant l'année, je peux voir que le montant de 6000 a été mis en évidence selon la condition et je peux développer plus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai également l'option d'ajuster les cellules comme je peux dire que c'est un ajustement de 10%.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux donc avoir une valeur négative, positive ou un pourcentage.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_13_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur OK.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je vais cliquer sur OK.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B800> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.00 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je vais cliquer sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_13_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La cellule est mise à jour et nous pouvons voir comment la valeur est modifiée pour l'année totale.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_14_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Chaque fois que la cellule est mise à jour en jaune lorsque nous les enregistrons, les données sont enregistrées immédiatement et nous pouvons voir comment les données sont reflétées.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_15_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Tout comme Excel, nous pouvons faire glisser des données et apporter des données à toutes ces lignes afin que toutes les données du trimestre soient mises à jour avec le total et que je vais les enregistrer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_15_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je veux également refléter ces données pour tous les autres chiffres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_16_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour celles-ci, je vais augmenter les données de 20%.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_16_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et pour cela, je vais augmenter les données de 50%.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_17_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai également la possibilité de copier et coller les données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_18_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai également la possibilité d'ajuster le niveau de la grille de données de la façon dont je souhaite l'ajuster.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_19_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Est-ce un ajustement proportionnel ou un ajustement uniforme?'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_20_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Disons donc pour le troisième trimestre où j'ai des données pour juillet, août et septembre, je vais ajuster les données proportionnellement et faire un ajustement de 1000.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_20_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous pouvez voir comment les données sont ajustées.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Vous pouvez voir comment les données sont ajustées.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B9B0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.24 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Vous pouvez voir comment les données sont ajustées.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Vous pouvez voir comment les données sont ajustées.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B260> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.57 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Vous pouvez voir comment les données sont ajustées.'\n",
      "[Error] Attempt 3/5 failed for phrase: 'Vous pouvez voir comment les données sont ajustées.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AD50> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 4.08 seconds...\n",
      "[Debug] Attempt 4: Synthesizing phrase: 'Vous pouvez voir comment les données sont ajustées.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_21_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également ajouter des pièces jointes, ajouter des commentaires et joindre les détails de support de nos fichiers locaux et le publier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_22_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'L'utilisateur sera en mesure de voir le nom d'utilisateur, la date à laquelle le commentaire a été fait, l'heure et le commentaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_23_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, un utilisateur peut faire des commentaires s'il a accès au formulaire et à la cellule.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_24_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Lorsqu'un icône bleu est visible sur la cellule, ceci signifie que nous avons une pièce jointe ou un commentaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_24_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également définir les préférences à partir des outils.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons définir la langue et les zones.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons définir la façon dont nous voulons voir les données, la précision, les suppressions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous définirons les variables utilisateur à partir d'ici en sélectionnant le sélecteur de membre et en sélectionnant le membre respectif et en cliquant sur OK, puis en le enregistrant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We can also set the preference from the tools.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_26_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We can set the language and the areas.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_26_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We can set how we want to see the data,'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_26_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'the precision, suppressions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_27_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We will set the user variables from here by selecting the member selector and selecting the respective member and clicking on OK and then saving it.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'We will set the user variables from here by selecting the member selector and selecting the respective member and clicking on OK and then saving it.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B920> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.70 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'We will set the user variables from here by selecting the member selector and selecting the respective member and clicking on OK and then saving it.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_27_1.mp3\n",
      "✅ Translated audio saved to: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.wav\n",
      "📝 Debug log saved to: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\translation_debug_log.txt\n",
      "Merging audio and video...\n",
      "Moviepy - Building video 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4\n",
      "Process completed! Output video: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version we rely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def split_long_groups(groups, max_group_duration_secs):\n",
    "    \"\"\"\n",
    "    For each group (list of SubRipItems), if its duration > max_group_duration_secs,\n",
    "    split it at the *last* subtitle in that group whose text ends in punctuation\n",
    "    (.,!? or comma) before the duration threshold.\n",
    "    Falls back to a simple split if no such “safe” break exists.\n",
    "    \"\"\"\n",
    "    new_groups = []\n",
    "    for group in groups:\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        total   = end_s - start_s\n",
    "\n",
    "        # if already shorter than threshold, keep it\n",
    "        if total <= max_group_duration_secs:\n",
    "            new_groups.append(group)\n",
    "            continue\n",
    "\n",
    "        # otherwise walk through, tracking safe_breaks\n",
    "        temp = []\n",
    "        temp_start = start_s\n",
    "        last_safe_idx = None\n",
    "        for idx, item in enumerate(group):\n",
    "            temp.append(item)\n",
    "            # mark this idx if it ends in punctuation or comma\n",
    "            if re.search(r\"[.,!?]$\", item.text.strip()):\n",
    "                last_safe_idx = idx\n",
    "\n",
    "            current_end = item.end.ordinal / 1000\n",
    "            if (current_end - temp_start) >= max_group_duration_secs:\n",
    "                # if we have a safe break before or at idx, split there\n",
    "                if last_safe_idx is not None:\n",
    "                    # emit group up through last_safe_idx\n",
    "                    safe_group = temp[: last_safe_idx+1 ]\n",
    "                    new_groups.append(safe_group)\n",
    "                    # restart temp from the items after safe_idx\n",
    "                    temp = temp[last_safe_idx+1 :]\n",
    "                    temp_start = temp[0].start.ordinal / 1000 if temp else current_end\n",
    "                else:\n",
    "                    # no safe break—just split at current idx\n",
    "                    new_groups.append(temp)\n",
    "                    temp = []\n",
    "                    temp_start = current_end\n",
    "\n",
    "                # reset safe marker\n",
    "                last_safe_idx = None\n",
    "\n",
    "        # anything left over\n",
    "        if temp:\n",
    "            new_groups.append(temp)\n",
    "\n",
    "    return new_groups\n",
    "\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    \"\"\"\n",
    "    Parse **Final Translation**, **Voice Speed**, **Pre‑Silence**, **Post‑Silence**.\n",
    "    Returns a list of dicts, one per segment.\n",
    "    \"\"\"\n",
    "    overrides = []\n",
    "    text = open(review_file_path, \"r\", encoding=\"utf-8\").read()\n",
    "    blocks = [b.strip() for b in text.split(\"----------------------------------------------------------------\") if b.strip()]\n",
    "\n",
    "    for blk in blocks:\n",
    "        ft = vs = None\n",
    "        pre_ms = 0.0\n",
    "        post_ms = 100.0  # Default to 100ms if not specified\n",
    "\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                ft = line.split(\"**Final Translation:**\",1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                vs = line.split(\"**Voice Speed:**\",1)[1].strip()\n",
    "            # Corrected hyphen in Pre-Silence and Post-Silence\n",
    "            elif line.startswith(\"**Pre-Silence:**\"):\n",
    "                try:\n",
    "                    pre_ms = float(line.split(\"**Pre-Silence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    pre_ms = 0.0\n",
    "            elif line.startswith(\"**Post-Silence:**\"):\n",
    "                try:\n",
    "                    post_ms = float(line.split(\"**Post-Silence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    post_ms = 100.0\n",
    "\n",
    "        if ft is not None and vs is not None:\n",
    "            overrides.append({\n",
    "                \"final_translation\": ft,\n",
    "                \"voice_speed\":      vs,\n",
    "                \"pre_silence\":      pre_ms,\n",
    "                \"post_silence\":     post_ms\n",
    "            })\n",
    "\n",
    "    print(\"Parsed review overrides:\")\n",
    "    for idx, o in enumerate(overrides, 1):\n",
    "        print(f\"  Segment {idx}: pre={o['pre_silence']}ms, post={o['post_silence']}ms, speed={o['voice_speed']}\")\n",
    "    return overrides\n",
    "\n",
    "def generate_translation_review_file(\n",
    "    source_path, review_file_path,\n",
    "    from_lang=\"en\", to_lang=\"fr\",\n",
    "    max_group_duration_secs: float = 25.0  # Increased max duration to reduce splits\n",
    "):\n",
    "    \"\"\"\n",
    "    1. Translates and groups by sentence.\n",
    "    2. Splits any group longer than max_group_duration_secs\n",
    "       into shorter chunks at subtitle-item boundaries.\n",
    "    3. Writes the review file as before, one block per (sub-)group.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "\n",
    "    # 1) Build initial sentence‑based groups\n",
    "    sentence_end = re.compile(r\"[.!?]\\s*$\")\n",
    "    groups = []\n",
    "    current = []\n",
    "    for sub in subs:\n",
    "        current.append(sub)\n",
    "        if sentence_end.search(sub.text):\n",
    "            groups.append(current)\n",
    "            current = []\n",
    "    if current:\n",
    "        groups.append(current)\n",
    "\n",
    "    # 2) Split any over‑long groups at safe punctuation boundaries\n",
    "    groups = split_long_groups(groups, max_group_duration_secs)\n",
    "    \n",
    "    # 3) Enforce punctuation boundaries to prevent mid-sentence splits\n",
    "    groups = enforce_punctuation_boundaries(groups)\n",
    "\n",
    "    # 4) Write the review file\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Pre-Silence:**, **Post-Silence:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "        for idx, group in enumerate(groups, 1):\n",
    "            start_s = group[0].start.ordinal / 1000\n",
    "            end_s   = group[-1].end.ordinal   / 1000\n",
    "            original = \" \".join(s.text for s in group)\n",
    "            auto_tr  = translator.translate(text=original)\n",
    "\n",
    "            f.write(f\"Segment {idx} (start: {start_s:.2f}s, end: {end_s:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Voice Speed:** +0%\\n\")\n",
    "            f.write(f\"**Pre-Silence:** 100\\n\")  # Default pre-silence\n",
    "            f.write(f\"**Post-Silence:** 100\\n\")  # Default post-silence\n",
    "            f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    print(f\"✅ Review file created at: {review_file_path}  (split into {len(groups)} segments)\")\n",
    "    input(\"Type 'Y' when ready to continue: \")\n",
    "    return groups\n",
    "\n",
    "\n",
    "def enforce_punctuation_boundariesolf(groups):\n",
    "    \"\"\"\n",
    "    Ensure each group’s last subtitle ends in .,!? or comma.\n",
    "    If not, merge it with the next group (and repeat) until it does.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    fixed = []\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        # if last line of this group doesn't end in safe punctuation\n",
    "        if not safe_re.search(g[-1].text.strip()):\n",
    "            # and there *is* a next group, merge them\n",
    "            if i + 1 < len(groups):\n",
    "                groups[i+1] = g + groups[i+1]\n",
    "                i += 1\n",
    "                continue\n",
    "        # otherwise it's “safe” (or no next group to merge), keep it\n",
    "        fixed.append(g)\n",
    "        i += 1\n",
    "    return fixed\n",
    "\n",
    "def enforce_punctuation_boundaries(groups):\n",
    "    \"\"\"Ensure groups end with proper punctuation\"\"\"\n",
    "    i = 0\n",
    "    safe_punctuation = r\"[.!?,;:]$\"\n",
    "    while i < len(groups):\n",
    "        last_text = groups[i][-1].text.strip()\n",
    "        if not re.search(safe_punctuation, last_text):\n",
    "            if i+1 < len(groups):\n",
    "                groups[i] += groups.pop(i+1)\n",
    "            else:  # Add artificial pause for final group\n",
    "                groups[i][-1].text += \".\"\n",
    "        else:\n",
    "            i += 1\n",
    "    return groups\n",
    "\n",
    "\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text)\n",
    "    return [phrase.strip() for phrase in phrases if phrase.strip()]\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    Note: In Edge TTS v7.0.0 the 'session' parameter is not supported.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session for each attempt.\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate\n",
    "                )\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "\n",
    "\n",
    "\n",
    "async def async_generate_translated_audio_with_sync_using_review(\n",
    "    subtitle_source_path, output_audio_path,\n",
    "    debug_log_path, review_file_path\n",
    "):\n",
    "    # 1) Build/write review file & parse overrides\n",
    "    groups    = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "\n",
    "    # Pad overrides list so it matches the number of groups\n",
    "    default_override = {\n",
    "        \"final_translation\": None,   # we'll fall back to original text below\n",
    "        \"voice_speed\":      \"+0%\",\n",
    "        \"pre_silence\":      0.0,\n",
    "        \"post_silence\":     100.0\n",
    "    }\n",
    "    while len(overrides) < len(groups):\n",
    "        overrides.append(default_override.copy())\n",
    "\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines    = []\n",
    "    offset_threshold = 0.05  # seconds\n",
    "\n",
    "    for idx, group in enumerate(groups):\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        seg_dur = end_s - start_s\n",
    "\n",
    "        orig = \" \".join(s.text for s in group)\n",
    "        ovr  = overrides[idx]\n",
    "        fr_text = ovr[\"final_translation\"] or orig\n",
    "        rate    = ovr[\"voice_speed\"]\n",
    "        pre_ms  = ovr[\"pre_silence\"]\n",
    "        post_ms = ovr[\"post_silence\"]\n",
    "        total_ms = int(seg_dur * 1000)\n",
    "\n",
    "        # allocate content time (subtract pre & post)\n",
    "        content_ms = max(0, total_ms - int(pre_ms) - int(post_ms))\n",
    "\n",
    "        # split into phrases & weights\n",
    "        phrases = split_french_phrases(fr_text)\n",
    "        weights = calculate_phrase_weights(orig, phrases)\n",
    "\n",
    "        # synth & adjust each phrase\n",
    "        phrase_audios = []\n",
    "        for i, ph in enumerate(phrases):\n",
    "            dur = content_ms * weights[i] / 1000.0\n",
    "            tmp = os.path.join(tempfile.gettempdir(), f\"tmp_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(ph, tmp, voice=\"fr-FR-DeniseNeural\", rate=rate)\n",
    "                aud = AudioSegment.from_mp3(tmp)\n",
    "                aud = adjust_audio_duration(aud, dur)\n",
    "                phrase_audios.append(aud)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] phrase {i} failed: {e}\")\n",
    "            finally:\n",
    "                if os.path.exists(tmp):\n",
    "                    os.remove(tmp)\n",
    "\n",
    "        # assemble with pre & post silence\n",
    "        seg_audio = AudioSegment.silent(duration=pre_ms)\n",
    "        for aud in phrase_audios:\n",
    "            seg_audio += aud\n",
    "        seg_audio += AudioSegment.silent(duration=post_ms)\n",
    "\n",
    "        # trim/pad to exactly total_ms\n",
    "        seg_audio = seg_audio[:total_ms]\n",
    "\n",
    "        # if needed, apply global speed adjustment\n",
    "        gen_dur = seg_audio.duration_seconds\n",
    "        diff = seg_dur - gen_dur\n",
    "        if abs(diff) > offset_threshold:\n",
    "            factor = seg_dur / gen_dur\n",
    "            print(f\"[Debug] Segment {idx+1}: adjusting speed factor={factor:.3f}\")\n",
    "            seg_audio = change_playback_speed(seg_audio, factor)\n",
    "\n",
    "        # place at the correct start in the combined track\n",
    "        start_ms = int(start_s * 1000)\n",
    "        if len(combined_audio) < start_ms:\n",
    "            combined_audio += AudioSegment.silent(duration=start_ms - len(combined_audio))\n",
    "        combined_audio += seg_audio\n",
    "\n",
    "        # log\n",
    "        debug_lines.append(\n",
    "            f\"Segment {idx+1} ({start_s:.2f}-{end_s:.2f}s): \"\n",
    "            f\"pre={pre_ms}ms, post={post_ms}ms, speed={rate}, phrases={phrases}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # write debug log & export\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as df:\n",
    "        df.write(\"Translation Debug Log\\n\\n\")\n",
    "        df.writelines(debug_lines)\n",
    "\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790acbb9",
   "metadata": {},
   "source": [
    "OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad9974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "1️⃣ Extracting audio…\n",
      "2️⃣ Transcribing…\n",
      "Detected language: en\n",
      "3️⃣ Writing SRT…\n",
      "4️⃣ Preparing translation review…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "\n",
    "# Paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "extracted_audio = os.path.join(output_dir, f\"{base_name}-extracted-audio.wav\")\n",
    "subtitle_file = os.path.join(output_dir, f\"{base_name}-english.srt\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{base_name}-french.wav\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "output_video = os.path.join(output_dir, f\"{base_name}-french.mp4\")\n",
    "\n",
    "# ============== Audio extraction & transcription ==============\n",
    "def extract_audio():\n",
    "    \"\"\"\n",
    "    Extracts the audio track from the input video into a 16kHz mono WAV file.\n",
    "    Prints full ffmpeg stderr on failure for easier debugging.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run ffmpeg without capturing stderr so we can see any errors directly\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run()\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        # ffmpeg.Error contains stdout and stderr bytes\n",
    "        print(\"⚠️ ffmpeg failed to extract audio. ffmpeg stderr output below:\")\n",
    "        try:\n",
    "            print(e.stderr.decode('utf-8', errors='replace'))\n",
    "        except Exception:\n",
    "            print(e.stderr)\n",
    "        raise\n",
    "    \n",
    "    # Should never reach here\n",
    "    return None\n",
    "\n",
    "class SubRipTimeConverter:\n",
    "    @staticmethod\n",
    "    def to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "        h = int(seconds // 3600)\n",
    "        seconds %= 3600\n",
    "        m = int(seconds // 60)\n",
    "        s = int(seconds % 60)\n",
    "        ms = int((seconds - s) * 1000)\n",
    "        return pysrt.SubRipTime(hours=h, minutes=m, seconds=s, milliseconds=ms)\n",
    "\n",
    "def generate_subtitles(segments, path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, seg in enumerate(segments, 1):\n",
    "        item = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=SubRipTimeConverter.to_subrip(seg['start']),\n",
    "            end=SubRipTimeConverter.to_subrip(seg['end']),\n",
    "            text=seg['text']\n",
    "        )\n",
    "        subs.append(item)\n",
    "    subs.save(path, encoding='utf-8')\n",
    "    return path\n",
    "\n",
    "async def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    print(f\"Detected language: {info.language}\")\n",
    "    out = []\n",
    "    for s in segments:\n",
    "        out.append({'start': s.start, 'end': s.end, 'text': s.text.strip()})\n",
    "    return info.language, out\n",
    "\n",
    "# ============== Review file grouping & splitting ==============\n",
    "def split_long_groupsO(groups, max_secs):\n",
    "    new = []\n",
    "    safe = re.compile(r\"[.,!?]$\")\n",
    "    for grp in groups:\n",
    "        st = grp[0].start.ordinal/1000\n",
    "        en = grp[-1].end.ordinal/1000\n",
    "        if en-st <= max_secs:\n",
    "            new.append(grp)\n",
    "            continue\n",
    "        temp, ts, last_safe = [], st, None\n",
    "        for i,item in enumerate(grp):\n",
    "            temp.append(item)\n",
    "            if safe.search(item.text.strip()): last_safe = i\n",
    "            now = item.end.ordinal/1000\n",
    "            if now-ts >= max_secs:\n",
    "                if last_safe is not None:\n",
    "                    new.append(temp[:last_safe+1])\n",
    "                    temp = temp[last_safe+1:]\n",
    "                else:\n",
    "                    new.append(temp)\n",
    "                    temp = []\n",
    "                ts = temp[0].start.ordinal/1000 if temp else now\n",
    "                last_safe = None\n",
    "        if temp: new.append(temp)\n",
    "    return new\n",
    "\n",
    "def enforce_punctuation_boundariesO(groups):\n",
    "    safe = re.compile(r\"[.,!?]$\")\n",
    "    out, i = [], 0\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        if not safe.search(g[-1].text.strip()) and i+1 < len(groups):\n",
    "            groups[i+1] = g + groups[i+1]\n",
    "        else:\n",
    "            out.append(g)\n",
    "            i += 1\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def split_long_groups(groups, max_group_duration_secs):\n",
    "    \"\"\"\n",
    "    For each group (list of SubRipItems), if its duration > max_group_duration_secs,\n",
    "    split it at the *last* subtitle in that group whose text ends in punctuation\n",
    "    (.,!? or comma) before the duration threshold.\n",
    "    Falls back to a simple split if no such “safe” break exists.\n",
    "    \"\"\"\n",
    "    new_groups = []\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    for group in groups:\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        total   = end_s - start_s\n",
    "\n",
    "        if total <= max_group_duration_secs:\n",
    "            new_groups.append(group)\n",
    "            continue\n",
    "\n",
    "        temp = []\n",
    "        temp_start = start_s\n",
    "        last_safe_idx = None\n",
    "        for idx, item in enumerate(group):\n",
    "            temp.append(item)\n",
    "            if safe_re.search(item.text.strip()):\n",
    "                last_safe_idx = idx\n",
    "\n",
    "            current_end = item.end.ordinal / 1000\n",
    "            if (current_end - temp_start) >= max_group_duration_secs:\n",
    "                if last_safe_idx is not None:\n",
    "                    # split at last safe punctuation\n",
    "                    new_groups.append(temp[: last_safe_idx+1])\n",
    "                    temp = temp[last_safe_idx+1 :]\n",
    "                else:\n",
    "                    # no safe break, just split here\n",
    "                    new_groups.append(temp)\n",
    "                    temp = []\n",
    "                temp_start = temp[0].start.ordinal / 1000 if temp else current_end\n",
    "                last_safe_idx = None\n",
    "\n",
    "        if temp:\n",
    "            new_groups.append(temp)\n",
    "\n",
    "    return new_groups\n",
    "\n",
    "def enforce_punctuation_boundaries(groups):\n",
    "    \"\"\"\n",
    "    Ensure each group’s last subtitle ends in .,!? or comma.\n",
    "    If not, merge it with the next group (and repeat) until it does.\n",
    "    \"\"\"\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        if not safe_re.search(g[-1].text.strip()) and i + 1 < len(groups):\n",
    "            # merge into next\n",
    "            groups[i+1] = g + groups[i+1]\n",
    "        else:\n",
    "            fixed.append(g)\n",
    "            i += 1\n",
    "    return fixed\n",
    "\n",
    "\n",
    "# ============== Parse overrides ==============\n",
    "def parse_review_overrides(review_path):\n",
    "    blocks = [b.strip() for b in open(review_path, 'r', encoding='utf-8').read().split('----------------------------------------------------------------') if b.strip()]\n",
    "    out=[]\n",
    "    for blk in blocks:\n",
    "        ft,vs,pre,post = None,'+0%',0,100\n",
    "        for ln in blk.splitlines():\n",
    "            if ln.startswith('**Final Translation:**'):\n",
    "                ft = ln.split('**Final Translation:**',1)[1].strip()\n",
    "            elif ln.startswith('**Voice Speed:**'):\n",
    "                vs = ln.split('**Voice Speed:**',1)[1].strip()\n",
    "            elif ln.startswith('**Pre-Silence:**'):\n",
    "                pre = float(ln.split('**Pre-Silence:**',1)[1].strip())\n",
    "            elif ln.startswith('**Post-Silence:**'):\n",
    "                post= float(ln.split('**Post-Silence:**',1)[1].strip())\n",
    "        out.append({\n",
    "            'final_translation': ft,\n",
    "            'voice_speed': vs,\n",
    "            'pre_silence': int(pre),\n",
    "            'post_silence':int(post)\n",
    "        })\n",
    "    print(f\"Parsed {len(out)} overrides\")\n",
    "    return out\n",
    "\n",
    "# ============== Phrase splitting & weights ==============\n",
    "def split_french_phrases(text):\n",
    "    return [p.strip() for p in re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text) if p.strip()]\n",
    "\n",
    "def calculate_phrase_weights(orig, phrases):\n",
    "    counts = [len(p.split()) for p in phrases]\n",
    "    total  = sum(counts)\n",
    "    return [c/total if total>0 else 1/len(phrases) for c in counts]\n",
    "\n",
    "# ============== Robust Edge-TTS ==============\n",
    "async def robust_synthesize_phrase(text, output_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\", max_retries=5):\n",
    "    tmp = output_path + \".tmp.mp3\"\n",
    "    for attempt in range(1, max_retries+1):\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as sess:\n",
    "                comm = edge_tts.Communicate(text=text, voice=voice, rate=rate)\n",
    "                print(f\"[TTS] Attempt {attempt}: {text[:30]}…\")\n",
    "                await comm.save(tmp)\n",
    "            seg = AudioSegment.from_mp3(tmp)\n",
    "            seg.export(output_path, format='wav')\n",
    "            os.remove(tmp)\n",
    "            return\n",
    "        except Exception as e:\n",
    "            delay = 2**(attempt-1) + random.random()\n",
    "            print(f\"[TTS] Fail #{attempt}: {e} – retry in {delay:.1f}s\")\n",
    "            try: os.remove(tmp)\n",
    "            except: pass\n",
    "            await asyncio.sleep(delay)\n",
    "    # fallback\n",
    "    AudioSegment.silent(duration=1000).export(output_path, format='wav')\n",
    "\n",
    "async def async_generate_translated_audio_with_sync_using_review(\n",
    "    subtitle_srt, out_audio, debug_log, review_txt\n",
    "):\n",
    "    groups    = generate_translation_review_file(subtitle_srt, review_txt)\n",
    "    overrides = parse_review_overrides(review_txt)\n",
    "    default   = {'final_translation':None,'voice_speed':'+0%','pre_silence':0,'post_silence':100}\n",
    "    while len(overrides)<len(groups): overrides.append(default.copy())\n",
    "\n",
    "    combined = AudioSegment.silent(duration=0)\n",
    "    debug    = []\n",
    "    TH       = 0.05\n",
    "\n",
    "    for i,grp in enumerate(groups):\n",
    "        st = grp[0].start.ordinal/1000\n",
    "        en = grp[-1].end.ordinal/1000\n",
    "        dur_ms = int((en-st)*1000)\n",
    "        orig = \" \".join(x.text for x in grp)\n",
    "        ovr  = overrides[i]\n",
    "        fr   = ovr['final_translation'] or orig\n",
    "        rate = ovr['voice_speed']\n",
    "        pre  = ovr['pre_silence']\n",
    "        post = ovr['post_silence']\n",
    "        content_ms = max(0, dur_ms-pre-post)\n",
    "\n",
    "        phrases = split_french_phrases(fr)\n",
    "        weights = calculate_phrase_weights(orig, phrases)\n",
    "\n",
    "        seg_audio = AudioSegment.silent(pre)\n",
    "        for j,ph in enumerate(phrases):\n",
    "            tmp = os.path.join(tempfile.gettempdir(), f\"tts_{i}_{j}.wav\")\n",
    "            await robust_synthesize_phrase(ph, tmp, rate=rate)\n",
    "            part = AudioSegment.from_wav(tmp)\n",
    "            part = adjust_audio_duration(part, content_ms*weights[j]/1000)\n",
    "            seg_audio += part\n",
    "            os.remove(tmp)\n",
    "        seg_audio += AudioSegment.silent(post)\n",
    "        seg_audio = seg_audio[:dur_ms]\n",
    "\n",
    "        # speed adjust\n",
    "        gd = seg_audio.duration_seconds\n",
    "        td = en-st\n",
    "        if abs(td-gd)>TH:\n",
    "            factor = td/gd\n",
    "            seg_audio = change_playback_speed(seg_audio, factor)\n",
    "\n",
    "        offset = int(st*1000)\n",
    "        if len(combined)<offset:\n",
    "            combined += AudioSegment.silent(offset-len(combined))\n",
    "        combined += seg_audio\n",
    "        debug.append(f\"Segment {i+1}: {st:.2f}-{en:.2f}s pre={pre} post={post} rate={rate}\\n\")\n",
    "\n",
    "    combined.export(out_audio, format='wav')\n",
    "    with open(debug_log,'w',encoding='utf-8') as df:\n",
    "        df.write(\"Debug Log\\n\\n\"+\"\".join(debug))\n",
    "\n",
    "# ============== Helpers ==============\n",
    "def adjust_audio_duration(audio, target_dur_s):\n",
    "    cur = audio.duration_seconds\n",
    "    diff= target_dur_s - cur\n",
    "    if diff>0.1:\n",
    "        return audio + AudioSegment.silent(duration=int(diff*1000))\n",
    "    if diff<-0.1:\n",
    "        return audio[:int(target_dur_s*1000)]\n",
    "    return audio\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    fr = int(sound.frame_rate * speed)\n",
    "    sp = sound._spawn(sound.raw_data, overrides={'frame_rate': fr})\n",
    "    return sp.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "def merge_audio_video(video_in, audio_in, video_out):\n",
    "    vid = VideoFileClip(video_in)\n",
    "    aud = AudioFileClip(audio_in)\n",
    "    vid = vid.set_audio(aud)\n",
    "    vid.write_videofile(video_out, codec='libx264', audio_codec='aac')\n",
    "\n",
    "\n",
    "import re\n",
    "import pysrt\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def generate_translation_review_file(\n",
    "    source_path,\n",
    "    review_file_path,\n",
    "    from_lang: str = \"en\",\n",
    "    to_lang:   str = \"fr\",\n",
    "    max_group_duration_secs: float = 15.0,\n",
    "    pause_for_review: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Group by sentence.\n",
    "    2) Split groups longer than max_group_duration_secs at safe punctuation.\n",
    "    3) Enforce that each group ends on .,!? or comma.\n",
    "    4) Batch‑translate via GoogleTranslator.translate_batch(batch=…).\n",
    "    5) Write the standard review file template.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs       = pysrt.open(source_path)\n",
    "    sentence_end = re.compile(r\"[.!?]\\s*$\")\n",
    "\n",
    "    # 1) Build initial sentence‑based groups\n",
    "    groups = []\n",
    "    cur = []\n",
    "    for sub in subs:\n",
    "        cur.append(sub)\n",
    "        if sentence_end.search(sub.text):\n",
    "            groups.append(cur)\n",
    "            cur = []\n",
    "    if cur:\n",
    "        groups.append(cur)\n",
    "\n",
    "    # 2) Split any over‑long groups\n",
    "    groups = split_long_groups(groups, max_group_duration_secs)\n",
    "\n",
    "    # 3) Enforce natural ending punctuation\n",
    "    groups = enforce_punctuation_boundaries(groups)\n",
    "\n",
    "    # 4) Prepare originals & auto‑translate in batch\n",
    "    originals = [\" \".join(item.text for item in g) for g in groups]\n",
    "    try:\n",
    "        # correct signature is translate_batch(batch=…\n",
    "        auto_translations = translator.translate_batch(batch=originals)\n",
    "    except TypeError:\n",
    "        # fallback if older version\n",
    "        auto_translations = [translator.translate(text=o) for o in originals]\n",
    "\n",
    "    # 5) Write out review file\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Pre-Silence:**, **Post-Silence:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "        for idx, (grp, auto_tr) in enumerate(zip(groups, auto_translations), start=1):\n",
    "            start_s = grp[0].start.ordinal / 1000\n",
    "            end_s   = grp[-1].end.ordinal   / 1000\n",
    "            original = \" \".join(item.text for item in grp)\n",
    "\n",
    "            f.write(f\"Segment {idx} (start: {start_s:.2f}s, end: {end_s:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Voice Speed:** +0%\\n\")\n",
    "            f.write(f\"**Pre-Silence:** 0\\n\")\n",
    "            f.write(f\"**Post-Silence:** 100\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    print(f\"✅ Review file created at: {review_file_path}  (split into {len(groups)} segments)\")\n",
    "    if pause_for_review:\n",
    "        input(\"Type 'Y' when ready to continue: \")\n",
    "    return groups\n",
    "\n",
    "\n",
    "\n",
    "# ============== Main ==============\n",
    "async def main():\n",
    "    print(\"1️⃣ Extracting audio…\")\n",
    "    wav = extract_audio()\n",
    "    print(\"2️⃣ Transcribing…\")\n",
    "    lang, segs = await transcribe(wav)\n",
    "    print(\"3️⃣ Writing SRT…\")\n",
    "    generate_subtitles(segs, subtitle_file)\n",
    "    print(\"4️⃣ Preparing translation review…\")\n",
    "    # review file will pause here for your edits\n",
    "    await asyncio.to_thread(generate_translation_review_file, subtitle_file, review_file, lang, 'fr')\n",
    "    print(\"5️⃣ Generating translated audio…\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(\n",
    "        subtitle_file, translated_audio, debug_log_file, review_file\n",
    "    )\n",
    "    print(\"6️⃣ Merging with video…\")\n",
    "    merge_audio_video(input_video, translated_audio, output_video)\n",
    "    print(f\"✅ Done: {output_video}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a51d3",
   "metadata": {},
   "source": [
    "\"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version we rely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "import re\n",
    "import pysrt\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def split_long_groups(groups, max_group_duration_secs):\n",
    "    \"\"\"\n",
    "    For each group (a list of SubRipItems), if its span (end - start)\n",
    "    exceeds max_group_duration_secs, break it at the last subtitle\n",
    "    in that group which ends in .,!? (if possible), otherwise cut as is.\n",
    "    \"\"\"\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    new_groups = []\n",
    "    for group in groups:\n",
    "        start_time = group[0].start.ordinal / 1000.0\n",
    "        temp, last_safe = [], None\n",
    "\n",
    "        for i, item in enumerate(group):\n",
    "            temp.append(item)\n",
    "            # mark safe cut point\n",
    "            if safe_re.search(item.text.strip()):\n",
    "                last_safe = i\n",
    "\n",
    "            elapsed = (item.end.ordinal / 1000.0) - start_time\n",
    "            if elapsed >= max_group_duration_secs:\n",
    "                # split here\n",
    "                if last_safe is not None and last_safe < len(temp)-1:\n",
    "                    # cut at last safe boundary\n",
    "                    new_groups.append(temp[: last_safe+1])\n",
    "                    temp = temp[last_safe+1:]\n",
    "                else:\n",
    "                    new_groups.append(temp)\n",
    "                    temp = []\n",
    "                # reset for remainder\n",
    "                if temp:\n",
    "                    start_time = temp[0].start.ordinal / 1000.0\n",
    "                last_safe = None\n",
    "\n",
    "        if temp:\n",
    "            new_groups.append(temp)\n",
    "    return new_groups\n",
    "\n",
    "def enforce_punctuation_boundaries(groups):\n",
    "    \"\"\"\n",
    "    Ensure each group's last subtitle ends in .,!? or comma.\n",
    "    If not, merge it into the next group until it does.\n",
    "    \"\"\"\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        if not safe_re.search(g[-1].text.strip()) and (i + 1) < len(groups):\n",
    "            # merge into the next group\n",
    "            groups[i+1] = g + groups[i+1]\n",
    "        else:\n",
    "            fixed.append(g)\n",
    "            i += 1\n",
    "    return fixed\n",
    "\n",
    "def generate_translation_review_file(\n",
    "    source_path, review_file_path,\n",
    "    from_lang=\"en\", to_lang=\"fr\",\n",
    "    max_group_duration_secs: float = 15.0\n",
    "):\n",
    "    \"\"\"\n",
    "    1. Translates and groups by sentence.\n",
    "    2. Splits any group longer than max_group_duration_secs\n",
    "       into shorter chunks at subtitle-item boundaries.\n",
    "    3. Enforces that every group ends on .,!? or comma.\n",
    "    4. Writes the review file: one block per (sub-)group.\n",
    "    \"\"\"\n",
    "    # load and initial sentence‐based grouping\n",
    "    subs       = pysrt.open(source_path)\n",
    "    sentence_end = re.compile(r\"[.!?]\\s*$\")\n",
    "    groups, cur = [], []\n",
    "    for s in subs:\n",
    "        cur.append(s)\n",
    "        if sentence_end.search(s.text):\n",
    "            groups.append(cur)\n",
    "            cur = []\n",
    "    if cur:\n",
    "        groups.append(cur)\n",
    "\n",
    "    # split too‐long groups\n",
    "    groups = split_long_groups(groups, max_group_duration_secs)\n",
    "    # enforce safe punctuation at end\n",
    "    groups = enforce_punctuation_boundaries(groups)\n",
    "\n",
    "    # translate & write review template\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Silence Duration:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "        for i, grp in enumerate(groups, 1):\n",
    "            start_s = grp[0].start.ordinal / 1000\n",
    "            end_s   = grp[-1].end.ordinal   / 1000\n",
    "            orig    = \" \".join(s.text for s in grp)\n",
    "            auto_tr = translator.translate(text=orig)\n",
    "\n",
    "            f.write(f\"Segment {i} (start: {start_s:.2f}s, end: {end_s:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {orig}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Voice Speed:** +0%\\n\")\n",
    "            f.write(f\"**Silence Duration:** 100\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "    print(f\"✅ Review file created at: {review_file_path}  (split into {len(groups)} segments)\")\n",
    "    input(\"Type 'Y' when ready to continue: \")\n",
    "    return groups\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    \"\"\"\n",
    "    Parse **Final Translation**, **Voice Speed**, **Pre‑Silence**, **Post‑Silence**.\n",
    "    Returns a list of dicts, one per segment.\n",
    "    \"\"\"\n",
    "    overrides = []\n",
    "    text = open(review_file_path, \"r\", encoding=\"utf-8\").read()\n",
    "    blocks = [b.strip() for b in text.split(\"----------------------------------------------------------------\") if b.strip()]\n",
    "\n",
    "    for blk in blocks:\n",
    "        ft = vs = None\n",
    "        pre_ms = 0.0\n",
    "        post_ms = 100.0\n",
    "\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                ft = line.split(\"**Final Translation:**\",1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                vs = line.split(\"**Voice Speed:**\",1)[1].strip()\n",
    "            elif line.startswith(\"**Pre‑Silence:**\"):\n",
    "                try:\n",
    "                    pre_ms = float(line.split(\"**Pre‑Silence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    pre_ms = 0.0\n",
    "            elif line.startswith(\"**Post‑Silence:**\"):\n",
    "                try:\n",
    "                    post_ms = float(line.split(\"**Post‑Silence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    post_ms = 100.0\n",
    "\n",
    "        if ft is not None and vs is not None:\n",
    "            overrides.append({\n",
    "                \"final_translation\": ft,\n",
    "                \"voice_speed\":      vs,\n",
    "                \"pre_silence\":      pre_ms,\n",
    "                \"post_silence\":     post_ms\n",
    "            })\n",
    "\n",
    "    print(\"Parsed review overrides:\")\n",
    "    for idx, o in enumerate(overrides, 1):\n",
    "        print(f\"  Segment {idx}: pre={o['pre_silence']}ms, post={o['post_silence']}ms, speed={o['voice_speed']}\")\n",
    "    return overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text)\n",
    "    return [phrase.strip() for phrase in phrases if phrase.strip()]\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    Note: In Edge TTS v7.0.0 the 'session' parameter is not supported.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session for each attempt.\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate\n",
    "                )\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_reviewOLD(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "\n",
    "        print(f\"[Debug] Segment {idx+1} final translation: {final_translation}\")\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            try:\n",
    "                audio = AudioSegment.from_mp3(temp_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Unable to load audio from {temp_path}: {e}. Skipping this phrase.\")\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "                continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"[Debug] Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def async_generate_translated_audio_with_sync_using_review(\n",
    "    subtitle_source_path, output_audio_path,\n",
    "    debug_log_path, review_file_path\n",
    "):\n",
    "    # 1) Build/write review file & parse overrides\n",
    "    groups    = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "\n",
    "    subs          = pysrt.open(subtitle_source_path)\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines    = []\n",
    "    offset_threshold = 0.05  # sec\n",
    "\n",
    "    for idx, group in enumerate(groups):\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        seg_dur = end_s - start_s\n",
    "\n",
    "        orig = \" \".join(s.text for s in group)\n",
    "        ovr  = overrides[idx]\n",
    "        fr_text = ovr[\"final_translation\"]\n",
    "        rate    = ovr[\"voice_speed\"]\n",
    "        pre_ms  = ovr[\"pre_silence\"]\n",
    "        post_ms = ovr[\"post_silence\"]\n",
    "        total_ms = int(seg_dur * 1000)\n",
    "\n",
    "        # allocate content time (subtract pre & post)\n",
    "        content_ms = max(0, total_ms - int(pre_ms) - int(post_ms))\n",
    "\n",
    "        # split into phrases & weights\n",
    "        phrases = split_french_phrases(fr_text)\n",
    "        weights = calculate_phrase_weights(orig, phrases)\n",
    "\n",
    "        # synth & adjust each phrase\n",
    "        phrase_audios = []\n",
    "        for i, ph in enumerate(phrases):\n",
    "            dur = content_ms * weights[i] / 1000.0\n",
    "            tmp = os.path.join(tempfile.gettempdir(), f\"tmp_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(ph, tmp, voice=\"fr-FR-DeniseNeural\", rate=rate)\n",
    "                aud = AudioSegment.from_mp3(tmp)\n",
    "                aud = adjust_audio_duration(aud, dur)\n",
    "                phrase_audios.append(aud)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] phrase {i} failed: {e}\")\n",
    "            finally:\n",
    "                if os.path.exists(tmp):\n",
    "                    os.remove(tmp)\n",
    "\n",
    "        # assemble with pre & post silence\n",
    "        seg_audio = AudioSegment.silent(duration=pre_ms)\n",
    "        for aud in phrase_audios:\n",
    "            seg_audio += aud\n",
    "        seg_audio += AudioSegment.silent(duration=post_ms)\n",
    "\n",
    "        # trim/pad to exactly total_ms\n",
    "        seg_audio = seg_audio[:total_ms]\n",
    "\n",
    "        # if needed, apply global speed adjustment\n",
    "        gen_dur = seg_audio.duration_seconds\n",
    "        diff = seg_dur - gen_dur\n",
    "        if abs(diff) > offset_threshold:\n",
    "            factor = seg_dur / gen_dur\n",
    "            seg_audio = change_playback_speed(seg_audio, factor)\n",
    "\n",
    "        # place at the correct start in the combined track\n",
    "        start_ms = int(start_s * 1000)\n",
    "        if len(combined_audio) < start_ms:\n",
    "            combined_audio += AudioSegment.silent(duration=start_ms - len(combined_audio))\n",
    "        combined_audio += seg_audio\n",
    "\n",
    "        # log\n",
    "        debug_lines.append(\n",
    "            f\"Segment {idx+1} ({start_s:.2f}-{end_s:.2f}s): \"\n",
    "            f\"pre={pre_ms}ms, post={post_ms}ms, speed={rate}, phrases={phrases}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # write debug log & export\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as df:\n",
    "        df.write(\"Translation Debug Log\\n\\n\")\n",
    "        df.writelines(debug_lines)\n",
    "\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "\n",
    "    print(\"Transcribing audio (this may take a while)...\")\n",
    "    # Offload the blocking work to a thread:\n",
    "    language, segments = await asyncio.to_thread(transcribe, audio_path)\n",
    "\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Extracting audio…\")\n",
    "    audio_path = extract_audio()\n",
    "\n",
    "    print(\"Transcribing audio…\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "\n",
    "    print(\"Generating subtitles…\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "\n",
    "    print(\"Generating TTS & merging…\")\n",
    "    # <-- no args here\n",
    "    asyncio.run(async_main())\n",
    "\n",
    "    print(f\"Done! Output is {output_video}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be21aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8fea592",
   "metadata": {},
   "source": [
    "TESTING SSML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c856f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSML to be synthesized:\n",
      " <?xml version=\"1.0\" encoding=\"UTF-8\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"120%\">Bonjour, comment allez-vous?</prosody><break time=\"300ms\"/><prosody rate=\"+0%\">Je suis ravi de vous voir.</prosody></speak>\n",
      "SSML synthesis complete. Check the output file: test_ssml_output.mp3\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import edge_tts\n",
    "\n",
    "async def test_ssml():\n",
    "    # Create a well-formed SSML string.\n",
    "    ssml_text = (\n",
    "        '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n",
    "        '<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\">'\n",
    "        '<prosody rate=\"120%\">Bonjour, comment allez-vous?</prosody>'\n",
    "        '<break time=\"300ms\"/>'\n",
    "        '<prosody rate=\"+0%\">Je suis ravi de vous voir.</prosody>'\n",
    "        '</speak>'\n",
    "    )\n",
    "    output_file = \"test_ssml_output.mp3\"\n",
    "    print(\"SSML to be synthesized:\\n\", ssml_text)\n",
    "    \n",
    "    # Create the Communicate object with the SSML text.\n",
    "    communicate = edge_tts.Communicate(text=ssml_text, voice=\"fr-FR-DeniseNeural\")\n",
    "    \n",
    "    # Call save() without any ssml parameter.\n",
    "    await communicate.save(output_file)\n",
    "    print(f\"SSML synthesis complete. Check the output file: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(test_ssml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5be3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1086d6d3",
   "metadata": {},
   "source": [
    "WITH WORDS PAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada634b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f4d98cf",
   "metadata": {},
   "source": [
    "4.2.3_La création de rapports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db12b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n",
      "Detected language: en\n",
      "Generating English subtitles...\n",
      "Generating French audio with synchronization and manual overrides...\n",
      "Review file created at: 4.2.3_La création de rapports_run_20250415_181829\\translation_review.txt\n",
      "Please review and update the final translations as needed.\n",
      "Parsed review file overrides:\n",
      "  Segment 1 final translation: Dans cette démo, nous explorerons comment créer un rapport de dépenses par entité couvrant différents scénarios pendant plusieurs années.\n",
      "  Segment 2 final translation: Comment créer un résumé des dépenses pour toutes les unités commerciales d'une organisation avec différentes mesures contre les scénarios et l'exercice.\n",
      "  Segment 3 final translation: Comment créer un rapport avec des sections de revenus et de dépenses regroupées par des entités.\n",
      "  Segment 4 final translation: Comment modifier un rapport et ajouter une nouvelle dimension de présentation de données.\n",
      "  Segment 5 final translation: De plus, nous explorerons les rapports narratifs qui sont un outil de reporting extraordinaire avec un récit et une gouvernance utilisés pour les processus de soumission budgétaire annuels, trimestriels ou mensuels entre les différents départements et en créant un rapport de dépenses par une entité couvrant différents scénarios pendant plusieurs années.\n",
      "  Segment 6 final translation: À partir de la page d'accueil, cliquez sur la carte de rapports en haut à droite.\n",
      "  Segment 7 final translation: En cliquant sur le rapport, ouvrira une grille de rapports, nous avons vu les propriétés de la grille de rapport.\n",
      "  Segment 8 final translation: En cliquant sur l'icône du crayon sur la grille, ouvrira une puissance, je vais sélectionner EPBCS OEPFS.\n",
      "  Segment 9 final translation: Et c'est la sélection de la grille où nous devons sélectionner pour chaque dimension et nous pouvons aligner chaque dimension en cliquant sur la disposition de la dimension.\n",
      "  Segment 10 final translation: Cliquez sur ceci nous permettra de déplacer les dimensions de POV aux colonnes et vous verrez les options pour sélectionner différents nombres pour cette dimension particulière.\n",
      "  Segment 11 final translation: J'ai créé plusieurs colonnes dans une grille.\n",
      "  Segment 12 final translation: Je peux voir différentes options.\n",
      "  Segment 13 final translation: Vous pouvez voir que cliquer sur qui définit son vrai ou faux.\n",
      "  Segment 14 final translation: C'est pour les colonnes, c'est pour la ligne, je peux voir les propriétés de la ligne.\n",
      "  Segment 15 final translation: Si je sélectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est à trier et je peux définir des conditions sur la façon dont je veux voir les données.\n",
      "  Segment 16 final translation: Je peux ajouter des suppressions si je souhaite supprimer des données et vous pouvez voir comment nous avons les colonnes et en fonction de la mise en forme conditionnelle, nous avons les données affichées.\n",
      "  Segment 17 final translation: Nous avons également la possibilité d'élargir les données au niveau de la période et nous pouvons analyser et voir les données.\n",
      "  Segment 18 final translation: Ainsi, comment créer un rapport de résumé pour les dépenses en cliquant sur la carte de rapports dans toute la page.\n",
      "  Segment 19 final translation: En cliquant sur l'icône Créer un rapport, je voudrais donner un nom à ce rapport.\n",
      "  Segment 20 final translation: Je pense donc qu'une zone de texte vous permettra d'ajouter comme des en-têtes de texte supplémentaires.\n",
      "  Segment 21 final translation: Nous pouvons avoir des pieds de page.\n",
      "  Segment 22 final translation: Nous avons des fonctions sur ce que nous voulons voir.\n",
      "  Segment 23 final translation: Nous pouvons dire signaler une description et je vais ajouter une description et si je clique juste, j'ai fait les sélections sur la grille et nous pouvons faire des sélections supplémentaires en allant à cela actuellement, nous avons des dépenses totales, le numéro inférieur des enfants, des descendants, des parents et nous créerons une invite.\n",
      "  Segment 24 final translation: Lorsque nous exécutons, nous obtiendrons une fenêtre contextuelle, nous pouvons également pré-supporter les options en fonction du numéro récent et nous pouvons sélectionner les variables de substitution.\n",
      "  Segment 25 final translation: Tout le niveau récapitulatif se développe et s'il est étendu, nous devrions pouvoir voir et explorer le niveau inférieur et nous pouvons également percer le niveau de l'entité et nous explorerons un peu le formatage conditionnel.\n",
      "  Segment 26 final translation: Je vais aller au formatage conditionnel et je vais sélectionner cela.\n",
      "  Segment 27 final translation: Ainsi, le format, si la valeur est supérieure à celle-ci, elle devrait mettre en évidence en rouge.\n",
      "  Segment 28 final translation: De même, si la valeur est inférieure à 30 000, elle doit être mise en évidence en vert.\n",
      "  Segment 29 final translation: Nous devrions être en mesure de voir l'en-tête que nous avons ajouté et nous devrions être en mesure de voir du niveau de résumé au niveau inférieur.\n",
      "  Segment 30 final translation: Les deux nous avons une fonctionnalité vraiment cool pour générer du texte basé sur l'IA.\n",
      "  Segment 31 final translation: J'ai réglé un formatage conditionnel que si la cellule contient moins de moins de 40 000, cela devrait me donner des descriptions générées par AI.\n",
      "  Segment 32 final translation: Mettez à jour cette condition pour dire que toute information ci-dessous moins 51 000 doit être affichée.\n",
      "  Segment 33 final translation: Ainsi, vous pouvez voir toutes les données uniquement moins 216 000 se situent dans cette plage et nous pouvons voir le texte généré.\n",
      "  Segment 34 final translation: Comment créer un rapport avec des sections de revenus et de dépenses regroupées par entité.\n",
      "  Segment 35 final translation: Alors maintenant, au lieu de créer un rapport, je vais créer une copie d'un rapport existant et cliquer sur OKE, je vais modifier ce rapport.\n",
      "  Segment 36 final translation: Je vais créer une ligne de données et ce sont nos détails de dépenses.\n",
      "  Segment 37 final translation: J'ai mes détails de revenus en vertu du compte de revenus.\n",
      "  Segment 38 final translation: Je peux voir différentes fonctions et je vais sélectionner nos descendants de compte de revenus.\n",
      "  Segment 39 final translation: Et si je clique sur l'exécution, je pourrai d'abord voir le niveau détaillé pour les dépenses, puis pour les revenus.\n",
      "  Segment 40 final translation: J'ai ajouté une colonne supplémentaire en ajoutant des commentaires pour la variance entre les prévisions et la fonction de revenus et de dépenses.\n",
      "  Segment 41 final translation: Cela me raconte le détail de la raison pour laquelle nous avons la variance.\n",
      "  Segment 42 final translation: Vous verrez comment modifier un rapport existant et ajouter une nouvelle présentation de données.\n",
      "  Segment 43 final translation: Permettez-moi de sélectionner ce rapport de dépenses et pour ajouter une présentation de données, j'ajouterai une nouvelle page et je peux voir diverses options.\n",
      "  Segment 44 final translation: Je cliquerai sur Graphic et cela me donnera une grille graphique et je peux modifier.\n",
      "  Segment 45 final translation: Je vais sélectionner une grille existante et elle va faire référence à la grille de dépenses qui existe déjà et vous pouvez voir comment je peux voir la présentation des données et nous avons différentes options pour sélectionner le type de la façon dont nous voulons voir s'il s'agit d'un graphique à tarte, allons-y et exécutons cela.\n",
      "  Segment 46 final translation: Une fois le rapport chargé, nous voyons la grille habituelle et ci-dessous que nous avons le graphique à tarte que nous venons de créer sur la base des données du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entité et quel est le montant.\n",
      "  Segment 47 final translation: Explorons les rapports narratifs, l'outil EPM d'Oracle utilisé à des fins de rapports extraordinaires avec des récits et une gouvernance. Explorons-le.\n",
      "  Segment 48 final translation: J'ai créé cette carte en ajoutant l'URL de rapport narrative à l'outil de navigation. Cliquez sur ceci ouvrira l'instance de rapport narrative dans l'instance EPBCS existante et j'irai dans le package de rapports. Je vais ouvrir le rapport avec Montréal.\n",
      "  Segment 49 final translation: Une fois que nous ouvrons le rapport, nous serons sur la page du package de rapport. Nous pouvons ajouter des auteurs qui peuvent éditer ce rapport et ajouter des récits et des explications et une fois qu'ils ont ajouté les récits, ils peuvent le soumettre pour examen aux examinateurs qui pourraient être un chef de département ou un manager. Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.\n",
      "  Segment 50 final translation: Nous avons différentes sections en expansion, nous pouvons voir divers fichiers au sein des sections responsables, qui est l'auteur et s'il y a un tumulte. Je vais cliquer sur l'aperçu et c'est un rapport de soumission budgétaire et comment nous pouvons avoir le signe des ministres et les ministres adjoints. Nous pouvons voir les rapports pour les dépenses. Nous pouvons également voir l'interface graphique et nous pouvons ajouter des explications pour lesquelles nous voyons ces données et celles-ci sont entrées par les auteurs.\n",
      "  Segment 51 final translation: Nous pouvons avoir plusieurs rapports dans un package de rapport, ils peuvent également accéder à ce rapport depuis Smart. Nous sommes le Montréal que nous travaillions et je peux voir exactement les mêmes dossiers et cliquer dessus. Je peux voir des commentaires supplémentaires. Je peux ajouter des commentaires supplémentaires en vérifiant et nous pouvons vérifier et télécharger. Et si je reviens au package du rapport et cliquez sur Aperçu, je devrais pouvoir voir le commentaire. J'ai ajouté des numéros mis à jour. Ces rapports peuvent être utilisés pour les soumissions mensuelles trimestriellement et annuellement et je vais ouvrir un rapport PPT et je vais vous montrer comment nous pouvons faire créer les variables. C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport téléchargez-le comme un PDF et cliquer sur Exécuter enverra immédiatement un e-mail à l'utilisateur respectif.\n",
      "  Segment 52 final translation: J'ai plusieurs e-mails et j'ai la possibilité de télécharger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confronté ou les visages de révision ont commencé les utilisateurs respectifs du groupe recevront des notifications par e-mail. Ils peuvent également voir des notifications sur la page d'accueil. Les messages et cliquer sur cela les amèneront directement au package de rapport. Nous pouvons également voir la tâche à laquelle l'utilisateur a été attribué et il montre des détails supplémentaires qui est responsable quelle est la date et cliquer sur la tâche me montrera exactement ce que je dois faire et où. Alors ouvrez ce rapport du PPT. Nous pouvons voir la représentation visuelle du rapport dans le PPT. Nous avons également les options pour extraire des informations ad hoc et je vais extraire certaines données. Je veux voir les données de dépenses au niveau de l'entité et je vais copier ceci et je peux avoir ceci ici sous un smartphone ici et vous pouvez voir comment il dit que les besoins doivent être rafraîchis.\n",
      "  Segment 53 final translation: Si je clique sur Refresh, je devrais être en mesure de voir les numéros 3474 et tous ces clics sur l'actualisation me donne le numéro une fois la face de l'auteur terminée et vous pouvez voir comment le visage de l'auteur dit est terminé et nous pouvons créer une base d'examen. Une icône de revue est activée en surbrillance sur la tâche permettra à la section des commentaires d'ajouter des commentaires et de publier et il est livré avec le nom qui a fait le commentaire et nous pouvons également joindre des fichiers avec le nom et il pourrait y avoir plusieurs commentaires et discussions. Une fois que la face du signataire est créée, nous pouvons voir une icône supplémentaire pour le signe et le signataire peut prendre des mesures requises.\n",
      "  Segment 54 final translation: Ils peuvent cliquer sur le point de soumettre et nous pouvons voir ou non approuvés, ce qui est entré, ce qui signifie que le processus de soumission du budget est complètement approuvé et ceux-ci peuvent être publiés dans différents départements et qu'ils peuvent avoir une copie finale téléchargée dans leur système local et ils peuvent consulter comme un PDF une fois signé avec tous les commentaires et mises à jour effectués.\n",
      "  Segment 55 final translation: Nous pouvons également voir les mises à jour que nous avons faites aux commentaires.\n",
      "[Debug] Segment 1 final translation: Dans cette démo, nous explorerons comment créer un rapport de dépenses par entité couvrant différents scénarios pendant plusieurs années.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans cette démo, nous explorerons comment créer un rapport de dépenses par entité couvrant différents scénarios pendant plusieurs années.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_0_0.mp3\n",
      "[Debug] Segment 2 final translation: Comment créer un résumé des dépenses pour toutes les unités commerciales d'une organisation avec différentes mesures contre les scénarios et l'exercice.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment créer un résumé des dépenses pour toutes les unités commerciales d'une organisation avec différentes mesures contre les scénarios et l'exercice.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_1_0.mp3\n",
      "[Debug] Segment 3 final translation: Comment créer un rapport avec des sections de revenus et de dépenses regroupées par des entités.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment créer un rapport avec des sections de revenus et de dépenses regroupées par des entités.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Comment créer un rapport avec des sections de revenus et de dépenses regroupées par des entités.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3410> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.04 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Comment créer un rapport avec des sections de revenus et de dépenses regroupées par des entités.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_2_0.mp3\n",
      "[Debug] Segment 4 final translation: Comment modifier un rapport et ajouter une nouvelle dimension de présentation de données.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment modifier un rapport et ajouter une nouvelle dimension de présentation de données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_3_0.mp3\n",
      "[Debug] Segment 5 final translation: De plus, nous explorerons les rapports narratifs qui sont un outil de reporting extraordinaire avec un récit et une gouvernance utilisés pour les processus de soumission budgétaire annuels, trimestriels ou mensuels entre les différents départements et en créant un rapport de dépenses par une entité couvrant différents scénarios pendant plusieurs années.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'De plus, nous explorerons les rapports narratifs qui sont un outil de reporting extraordinaire avec un récit et une gouvernance utilisés pour les processus de soumission budgétaire annuels, trimestriels ou mensuels entre les différents départements et en créant un rapport de dépenses par une entité couvrant différents scénarios pendant plusieurs années.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_4_0.mp3\n",
      "[Debug] Segment 6 final translation: À partir de la page d'accueil, cliquez sur la carte de rapports en haut à droite.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'À partir de la page d'accueil, cliquez sur la carte de rapports en haut à droite.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_5_0.mp3\n",
      "[Debug] Segment 7 final translation: En cliquant sur le rapport, ouvrira une grille de rapports, nous avons vu les propriétés de la grille de rapport.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En cliquant sur le rapport, ouvrira une grille de rapports, nous avons vu les propriétés de la grille de rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_6_0.mp3\n",
      "[Debug] Segment 8 final translation: En cliquant sur l'icône du crayon sur la grille, ouvrira une puissance, je vais sélectionner EPBCS OEPFS.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En cliquant sur l'icône du crayon sur la grille, ouvrira une puissance, je vais sélectionner EPBCS OEPFS.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_7_0.mp3\n",
      "[Debug] Segment 9 final translation: Et c'est la sélection de la grille où nous devons sélectionner pour chaque dimension et nous pouvons aligner chaque dimension en cliquant sur la disposition de la dimension.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et c'est la sélection de la grille où nous devons sélectionner pour chaque dimension et nous pouvons aligner chaque dimension en cliquant sur la disposition de la dimension.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_8_0.mp3\n",
      "[Debug] Segment 10 final translation: Cliquez sur ceci nous permettra de déplacer les dimensions de POV aux colonnes et vous verrez les options pour sélectionner différents nombres pour cette dimension particulière.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cliquez sur ceci nous permettra de déplacer les dimensions de POV aux colonnes et vous verrez les options pour sélectionner différents nombres pour cette dimension particulière.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Cliquez sur ceci nous permettra de déplacer les dimensions de POV aux colonnes et vous verrez les options pour sélectionner différents nombres pour cette dimension particulière.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3C80> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.69 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Cliquez sur ceci nous permettra de déplacer les dimensions de POV aux colonnes et vous verrez les options pour sélectionner différents nombres pour cette dimension particulière.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_9_0.mp3\n",
      "[Debug] Segment 11 final translation: J'ai créé plusieurs colonnes dans une grille.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai créé plusieurs colonnes dans une grille.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_10_0.mp3\n",
      "[Debug] Segment 12 final translation: Je peux voir différentes options.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux voir différentes options.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je peux voir différentes options.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB3C050> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.44 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je peux voir différentes options.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Je peux voir différentes options.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB3C320> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.20 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Je peux voir différentes options.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_11_0.mp3\n",
      "[Debug] Segment 13 final translation: Vous pouvez voir que cliquer sur qui définit son vrai ou faux.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous pouvez voir que cliquer sur qui définit son vrai ou faux.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_12_0.mp3\n",
      "[Debug] Segment 14 final translation: C'est pour les colonnes, c'est pour la ligne, je peux voir les propriétés de la ligne.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propriétés de la ligne.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propriétés de la ligne.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3800> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.45 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propriétés de la ligne.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propriétés de la ligne.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA39B0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.16 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propriétés de la ligne.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_13_0.mp3\n",
      "[Debug] Segment 15 final translation: Si je sélectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est à trier et je peux définir des conditions sur la façon dont je veux voir les données.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Si je sélectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est à trier et je peux définir des conditions sur la façon dont je veux voir les données.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Si je sélectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est à trier et je peux définir des conditions sur la façon dont je veux voir les données.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3DA0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.07 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Si je sélectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est à trier et je peux définir des conditions sur la façon dont je veux voir les données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_14_0.mp3\n",
      "[Debug] Segment 16 final translation: Je peux ajouter des suppressions si je souhaite supprimer des données et vous pouvez voir comment nous avons les colonnes et en fonction de la mise en forme conditionnelle, nous avons les données affichées.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux ajouter des suppressions si je souhaite supprimer des données et vous pouvez voir comment nous avons les colonnes et en fonction de la mise en forme conditionnelle, nous avons les données affichées.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_15_0.mp3\n",
      "[Debug] Segment 17 final translation: Nous avons également la possibilité d'élargir les données au niveau de la période et nous pouvons analyser et voir les données.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons également la possibilité d'élargir les données au niveau de la période et nous pouvons analyser et voir les données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_16_0.mp3\n",
      "[Debug] Segment 18 final translation: Ainsi, comment créer un rapport de résumé pour les dépenses en cliquant sur la carte de rapports dans toute la page.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, comment créer un rapport de résumé pour les dépenses en cliquant sur la carte de rapports dans toute la page.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_17_0.mp3\n",
      "[Debug] Segment 19 final translation: En cliquant sur l'icône Créer un rapport, je voudrais donner un nom à ce rapport.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En cliquant sur l'icône Créer un rapport, je voudrais donner un nom à ce rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_18_0.mp3\n",
      "[Debug] Segment 20 final translation: Je pense donc qu'une zone de texte vous permettra d'ajouter comme des en-têtes de texte supplémentaires.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je pense donc qu'une zone de texte vous permettra d'ajouter comme des en-têtes de texte supplémentaires.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_19_0.mp3\n",
      "[Debug] Segment 21 final translation: Nous pouvons avoir des pieds de page.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons avoir des pieds de page.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons avoir des pieds de page.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA35C0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.95 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons avoir des pieds de page.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_20_0.mp3\n",
      "[Debug] Segment 22 final translation: Nous avons des fonctions sur ce que nous voulons voir.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons des fonctions sur ce que nous voulons voir.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous avons des fonctions sur ce que nous voulons voir.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3800> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.69 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous avons des fonctions sur ce que nous voulons voir.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_21_0.mp3\n",
      "[Debug] Segment 23 final translation: Nous pouvons dire signaler une description et je vais ajouter une description et si je clique juste, j'ai fait les sélections sur la grille et nous pouvons faire des sélections supplémentaires en allant à cela actuellement, nous avons des dépenses totales, le numéro inférieur des enfants, des descendants, des parents et nous créerons une invite.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons dire signaler une description et je vais ajouter une description et si je clique juste, j'ai fait les sélections sur la grille et nous pouvons faire des sélections supplémentaires en allant à cela actuellement, nous avons des dépenses totales, le numéro inférieur des enfants, des descendants, des parents et nous créerons une invite.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_22_0.mp3\n",
      "[Debug] Segment 24 final translation: Lorsque nous exécutons, nous obtiendrons une fenêtre contextuelle, nous pouvons également pré-supporter les options en fonction du numéro récent et nous pouvons sélectionner les variables de substitution.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Lorsque nous exécutons, nous obtiendrons une fenêtre contextuelle, nous pouvons également pré-supporter les options en fonction du numéro récent et nous pouvons sélectionner les variables de substitution.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_23_0.mp3\n",
      "[Debug] Segment 25 final translation: Tout le niveau récapitulatif se développe et s'il est étendu, nous devrions pouvoir voir et explorer le niveau inférieur et nous pouvons également percer le niveau de l'entité et nous explorerons un peu le formatage conditionnel.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Tout le niveau récapitulatif se développe et s'il est étendu, nous devrions pouvoir voir et explorer le niveau inférieur et nous pouvons également percer le niveau de l'entité et nous explorerons un peu le formatage conditionnel.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_24_0.mp3\n",
      "[Debug] Segment 26 final translation: Je vais aller au formatage conditionnel et je vais sélectionner cela.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais aller au formatage conditionnel et je vais sélectionner cela.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_25_0.mp3\n",
      "[Debug] Segment 27 final translation: Ainsi, le format, si la valeur est supérieure à celle-ci, elle devrait mettre en évidence en rouge.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, le format, si la valeur est supérieure à celle-ci, elle devrait mettre en évidence en rouge.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_26_0.mp3\n",
      "[Debug] Segment 28 final translation: De même, si la valeur est inférieure à 30 000, elle doit être mise en évidence en vert.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'De même, si la valeur est inférieure à 30 000, elle doit être mise en évidence en vert.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_27_0.mp3\n",
      "[Debug] Segment 29 final translation: Nous devrions être en mesure de voir l'en-tête que nous avons ajouté et nous devrions être en mesure de voir du niveau de résumé au niveau inférieur.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devrions être en mesure de voir l'en-tête que nous avons ajouté et nous devrions être en mesure de voir du niveau de résumé au niveau inférieur.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous devrions être en mesure de voir l'en-tête que nous avons ajouté et nous devrions être en mesure de voir du niveau de résumé au niveau inférieur.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3530> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.82 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous devrions être en mesure de voir l'en-tête que nous avons ajouté et nous devrions être en mesure de voir du niveau de résumé au niveau inférieur.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous devrions être en mesure de voir l'en-tête que nous avons ajouté et nous devrions être en mesure de voir du niveau de résumé au niveau inférieur.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3BF0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.10 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous devrions être en mesure de voir l'en-tête que nous avons ajouté et nous devrions être en mesure de voir du niveau de résumé au niveau inférieur.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_28_0.mp3\n",
      "[Debug] Segment 30 final translation: Les deux nous avons une fonctionnalité vraiment cool pour générer du texte basé sur l'IA.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les deux nous avons une fonctionnalité vraiment cool pour générer du texte basé sur l'IA.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_29_0.mp3\n",
      "[Debug] Segment 31 final translation: J'ai réglé un formatage conditionnel que si la cellule contient moins de moins de 40 000, cela devrait me donner des descriptions générées par AI.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai réglé un formatage conditionnel que si la cellule contient moins de moins de 40 000, cela devrait me donner des descriptions générées par AI.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_30_0.mp3\n",
      "[Debug] Segment 32 final translation: Mettez à jour cette condition pour dire que toute information ci-dessous moins 51 000 doit être affichée.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Mettez à jour cette condition pour dire que toute information ci-dessous moins 51 000 doit être affichée.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_31_0.mp3\n",
      "[Debug] Segment 33 final translation: Ainsi, vous pouvez voir toutes les données uniquement moins 216 000 se situent dans cette plage et nous pouvons voir le texte généré.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, vous pouvez voir toutes les données uniquement moins 216 000 se situent dans cette plage et nous pouvons voir le texte généré.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_32_0.mp3\n",
      "[Debug] Segment 34 final translation: Comment créer un rapport avec des sections de revenus et de dépenses regroupées par entité.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment créer un rapport avec des sections de revenus et de dépenses regroupées par entité.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_33_0.mp3\n",
      "[Debug] Segment 35 final translation: Alors maintenant, au lieu de créer un rapport, je vais créer une copie d'un rapport existant et cliquer sur OKE, je vais modifier ce rapport.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Alors maintenant, au lieu de créer un rapport, je vais créer une copie d'un rapport existant et cliquer sur OKE, je vais modifier ce rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_34_0.mp3\n",
      "[Debug] Segment 36 final translation: Je vais créer une ligne de données et ce sont nos détails de dépenses.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais créer une ligne de données et ce sont nos détails de dépenses.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_35_0.mp3\n",
      "[Debug] Segment 37 final translation: J'ai mes détails de revenus en vertu du compte de revenus.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai mes détails de revenus en vertu du compte de revenus.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai mes détails de revenus en vertu du compte de revenus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA31D0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.16 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai mes détails de revenus en vertu du compte de revenus.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'J'ai mes détails de revenus en vertu du compte de revenus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3EC0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.61 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'J'ai mes détails de revenus en vertu du compte de revenus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_36_0.mp3\n",
      "[Debug] Segment 38 final translation: Je peux voir différentes fonctions et je vais sélectionner nos descendants de compte de revenus.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux voir différentes fonctions et je vais sélectionner nos descendants de compte de revenus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_37_0.mp3\n",
      "[Debug] Segment 39 final translation: Et si je clique sur l'exécution, je pourrai d'abord voir le niveau détaillé pour les dépenses, puis pour les revenus.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et si je clique sur l'exécution, je pourrai d'abord voir le niveau détaillé pour les dépenses, puis pour les revenus.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Et si je clique sur l'exécution, je pourrai d'abord voir le niveau détaillé pour les dépenses, puis pour les revenus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA39B0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.03 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Et si je clique sur l'exécution, je pourrai d'abord voir le niveau détaillé pour les dépenses, puis pour les revenus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_38_0.mp3\n",
      "[Debug] Segment 40 final translation: J'ai ajouté une colonne supplémentaire en ajoutant des commentaires pour la variance entre les prévisions et la fonction de revenus et de dépenses.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai ajouté une colonne supplémentaire en ajoutant des commentaires pour la variance entre les prévisions et la fonction de revenus et de dépenses.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_39_0.mp3\n",
      "[Debug] Segment 41 final translation: Cela me raconte le détail de la raison pour laquelle nous avons la variance.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cela me raconte le détail de la raison pour laquelle nous avons la variance.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_40_0.mp3\n",
      "[Debug] Segment 42 final translation: Vous verrez comment modifier un rapport existant et ajouter une nouvelle présentation de données.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous verrez comment modifier un rapport existant et ajouter une nouvelle présentation de données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_41_0.mp3\n",
      "[Debug] Segment 43 final translation: Permettez-moi de sélectionner ce rapport de dépenses et pour ajouter une présentation de données, j'ajouterai une nouvelle page et je peux voir diverses options.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Permettez-moi de sélectionner ce rapport de dépenses et pour ajouter une présentation de données, j'ajouterai une nouvelle page et je peux voir diverses options.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_42_0.mp3\n",
      "[Debug] Segment 44 final translation: Je cliquerai sur Graphic et cela me donnera une grille graphique et je peux modifier.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je cliquerai sur Graphic et cela me donnera une grille graphique et je peux modifier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_43_0.mp3\n",
      "[Debug] Segment 45 final translation: Je vais sélectionner une grille existante et elle va faire référence à la grille de dépenses qui existe déjà et vous pouvez voir comment je peux voir la présentation des données et nous avons différentes options pour sélectionner le type de la façon dont nous voulons voir s'il s'agit d'un graphique à tarte, allons-y et exécutons cela.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais sélectionner une grille existante et elle va faire référence à la grille de dépenses qui existe déjà et vous pouvez voir comment je peux voir la présentation des données et nous avons différentes options pour sélectionner le type de la façon dont nous voulons voir s'il s'agit d'un graphique à tarte, allons-y et exécutons cela.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_44_0.mp3\n",
      "[Debug] Segment 46 final translation: Une fois le rapport chargé, nous voyons la grille habituelle et ci-dessous que nous avons le graphique à tarte que nous venons de créer sur la base des données du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entité et quel est le montant.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois le rapport chargé, nous voyons la grille habituelle et ci-dessous que nous avons le graphique à tarte que nous venons de créer sur la base des données du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entité et quel est le montant.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois le rapport chargé, nous voyons la grille habituelle et ci-dessous que nous avons le graphique à tarte que nous venons de créer sur la base des données du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entité et quel est le montant.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3380> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.32 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois le rapport chargé, nous voyons la grille habituelle et ci-dessous que nous avons le graphique à tarte que nous venons de créer sur la base des données du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entité et quel est le montant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_45_0.mp3\n",
      "[Debug] Segment 47 final translation: Explorons les rapports narratifs, l'outil EPM d'Oracle utilisé à des fins de rapports extraordinaires avec des récits et une gouvernance. Explorons-le.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Explorons les rapports narratifs, l'outil EPM d'Oracle utilisé à des fins de rapports extraordinaires avec des récits et une gouvernance.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Explorons les rapports narratifs, l'outil EPM d'Oracle utilisé à des fins de rapports extraordinaires avec des récits et une gouvernance.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA05F0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.33 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Explorons les rapports narratifs, l'outil EPM d'Oracle utilisé à des fins de rapports extraordinaires avec des récits et une gouvernance.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_46_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Explorons-le.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_46_1.mp3\n",
      "[Debug] Segment 48 final translation: J'ai créé cette carte en ajoutant l'URL de rapport narrative à l'outil de navigation. Cliquez sur ceci ouvrira l'instance de rapport narrative dans l'instance EPBCS existante et j'irai dans le package de rapports. Je vais ouvrir le rapport avec Montréal.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai créé cette carte en ajoutant l'URL de rapport narrative à l'outil de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_47_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cliquez sur ceci ouvrira l'instance de rapport narrative dans l'instance EPBCS existante et j'irai dans le package de rapports.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_47_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais ouvrir le rapport avec Montréal.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_47_2.mp3\n",
      "[Debug] Segment 49 final translation: Une fois que nous ouvrons le rapport, nous serons sur la page du package de rapport. Nous pouvons ajouter des auteurs qui peuvent éditer ce rapport et ajouter des récits et des explications et une fois qu'ils ont ajouté les récits, ils peuvent le soumettre pour examen aux examinateurs qui pourraient être un chef de département ou un manager. Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que nous ouvrons le rapport, nous serons sur la page du package de rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_48_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons ajouter des auteurs qui peuvent éditer ce rapport et ajouter des récits et des explications et une fois qu'ils ont ajouté les récits, ils peuvent le soumettre pour examen aux examinateurs qui pourraient être un chef de département ou un manager.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_48_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA39B0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.92 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3650> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.77 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Error] Attempt 3/5 failed for phrase: 'Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3F50> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 4.50 seconds...\n",
      "[Debug] Attempt 4: Synthesizing phrase: 'Une fois que le réviseur a terminé l'examen, il peut soumettre le rapport à un signataire qui pourrait être un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_48_2.mp3\n",
      "[Debug] Segment 50 final translation: Nous avons différentes sections en expansion, nous pouvons voir divers fichiers au sein des sections responsables, qui est l'auteur et s'il y a un tumulte. Je vais cliquer sur l'aperçu et c'est un rapport de soumission budgétaire et comment nous pouvons avoir le signe des ministres et les ministres adjoints. Nous pouvons voir les rapports pour les dépenses. Nous pouvons également voir l'interface graphique et nous pouvons ajouter des explications pour lesquelles nous voyons ces données et celles-ci sont entrées par les auteurs.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons différentes sections en expansion, nous pouvons voir divers fichiers au sein des sections responsables, qui est l'auteur et s'il y a un tumulte.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur l'aperçu et c'est un rapport de soumission budgétaire et comment nous pouvons avoir le signe des ministres et les ministres adjoints.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons voir les rapports pour les dépenses.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également voir l'interface graphique et nous pouvons ajouter des explications pour lesquelles nous voyons ces données et celles-ci sont entrées par les auteurs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_3.mp3\n",
      "[Debug] Segment 51 final translation: Nous pouvons avoir plusieurs rapports dans un package de rapport, ils peuvent également accéder à ce rapport depuis Smart. Nous sommes le Montréal que nous travaillions et je peux voir exactement les mêmes dossiers et cliquer dessus. Je peux voir des commentaires supplémentaires. Je peux ajouter des commentaires supplémentaires en vérifiant et nous pouvons vérifier et télécharger. Et si je reviens au package du rapport et cliquez sur Aperçu, je devrais pouvoir voir le commentaire. J'ai ajouté des numéros mis à jour. Ces rapports peuvent être utilisés pour les soumissions mensuelles trimestriellement et annuellement et je vais ouvrir un rapport PPT et je vais vous montrer comment nous pouvons faire créer les variables. C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport téléchargez-le comme un PDF et cliquer sur Exécuter enverra immédiatement un e-mail à l'utilisateur respectif.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons avoir plusieurs rapports dans un package de rapport, ils peuvent également accéder à ce rapport depuis Smart.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous sommes le Montréal que nous travaillions et je peux voir exactement les mêmes dossiers et cliquer dessus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux voir des commentaires supplémentaires.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux ajouter des commentaires supplémentaires en vérifiant et nous pouvons vérifier et télécharger.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et si je reviens au package du rapport et cliquez sur Aperçu, je devrais pouvoir voir le commentaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai ajouté des numéros mis à jour.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai ajouté des numéros mis à jour.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB44200> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.70 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai ajouté des numéros mis à jour.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ces rapports peuvent être utilisés pour les soumissions mensuelles trimestriellement et annuellement et je vais ouvrir un rapport PPT et je vais vous montrer comment nous pouvons faire créer les variables.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport téléchargez-le comme un PDF et cliquer sur Exécuter enverra immédiatement un e-mail à l'utilisateur respectif.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport téléchargez-le comme un PDF et cliquer sur Exécuter enverra immédiatement un e-mail à l'utilisateur respectif.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3C80> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.77 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport téléchargez-le comme un PDF et cliquer sur Exécuter enverra immédiatement un e-mail à l'utilisateur respectif.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_7.mp3\n",
      "[Debug] Segment 52 final translation: J'ai plusieurs e-mails et j'ai la possibilité de télécharger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confronté ou les visages de révision ont commencé les utilisateurs respectifs du groupe recevront des notifications par e-mail. Ils peuvent également voir des notifications sur la page d'accueil. Les messages et cliquer sur cela les amèneront directement au package de rapport. Nous pouvons également voir la tâche à laquelle l'utilisateur a été attribué et il montre des détails supplémentaires qui est responsable quelle est la date et cliquer sur la tâche me montrera exactement ce que je dois faire et où. Alors ouvrez ce rapport du PPT. Nous pouvons voir la représentation visuelle du rapport dans le PPT. Nous avons également les options pour extraire des informations ad hoc et je vais extraire certaines données. Je veux voir les données de dépenses au niveau de l'entité et je vais copier ceci et je peux avoir ceci ici sous un smartphone ici et vous pouvez voir comment il dit que les besoins doivent être rafraîchis.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai plusieurs e-mails et j'ai la possibilité de télécharger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confronté ou les visages de révision ont commencé les utilisateurs respectifs du groupe recevront des notifications par e-mail.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai plusieurs e-mails et j'ai la possibilité de télécharger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confronté ou les visages de révision ont commencé les utilisateurs respectifs du groupe recevront des notifications par e-mail.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA31D0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.88 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai plusieurs e-mails et j'ai la possibilité de télécharger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confronté ou les visages de révision ont commencé les utilisateurs respectifs du groupe recevront des notifications par e-mail.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'J'ai plusieurs e-mails et j'ai la possibilité de télécharger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confronté ou les visages de révision ont commencé les utilisateurs respectifs du groupe recevront des notifications par e-mail.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA32F0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.91 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'J'ai plusieurs e-mails et j'ai la possibilité de télécharger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confronté ou les visages de révision ont commencé les utilisateurs respectifs du groupe recevront des notifications par e-mail.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ils peuvent également voir des notifications sur la page d'accueil.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les messages et cliquer sur cela les amèneront directement au package de rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également voir la tâche à laquelle l'utilisateur a été attribué et il montre des détails supplémentaires qui est responsable quelle est la date et cliquer sur la tâche me montrera exactement ce que je dois faire et où.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Alors ouvrez ce rapport du PPT.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons voir la représentation visuelle du rapport dans le PPT.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons également les options pour extraire des informations ad hoc et je vais extraire certaines données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je veux voir les données de dépenses au niveau de l'entité et je vais copier ceci et je peux avoir ceci ici sous un smartphone ici et vous pouvez voir comment il dit que les besoins doivent être rafraîchis.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_7.mp3\n",
      "[Debug] Segment 53 final translation: Si je clique sur Refresh, je devrais être en mesure de voir les numéros 3474 et tous ces clics sur l'actualisation me donne le numéro une fois la face de l'auteur terminée et vous pouvez voir comment le visage de l'auteur dit est terminé et nous pouvons créer une base d'examen. Une icône de revue est activée en surbrillance sur la tâche permettra à la section des commentaires d'ajouter des commentaires et de publier et il est livré avec le nom qui a fait le commentaire et nous pouvons également joindre des fichiers avec le nom et il pourrait y avoir plusieurs commentaires et discussions. Une fois que la face du signataire est créée, nous pouvons voir une icône supplémentaire pour le signe et le signataire peut prendre des mesures requises.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Si je clique sur Refresh, je devrais être en mesure de voir les numéros 3474 et tous ces clics sur l'actualisation me donne le numéro une fois la face de l'auteur terminée et vous pouvez voir comment le visage de l'auteur dit est terminé et nous pouvons créer une base d'examen.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_52_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une icône de revue est activée en surbrillance sur la tâche permettra à la section des commentaires d'ajouter des commentaires et de publier et il est livré avec le nom qui a fait le commentaire et nous pouvons également joindre des fichiers avec le nom et il pourrait y avoir plusieurs commentaires et discussions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_52_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que la face du signataire est créée, nous pouvons voir une icône supplémentaire pour le signe et le signataire peut prendre des mesures requises.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que la face du signataire est créée, nous pouvons voir une icône supplémentaire pour le signe et le signataire peut prendre des mesures requises.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB6C320> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.59 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que la face du signataire est créée, nous pouvons voir une icône supplémentaire pour le signe et le signataire peut prendre des mesures requises.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_52_2.mp3\n",
      "[Debug] Segment 54 final translation: Ils peuvent cliquer sur le point de soumettre et nous pouvons voir ou non approuvés, ce qui est entré, ce qui signifie que le processus de soumission du budget est complètement approuvé et ceux-ci peuvent être publiés dans différents départements et qu'ils peuvent avoir une copie finale téléchargée dans leur système local et ils peuvent consulter comme un PDF une fois signé avec tous les commentaires et mises à jour effectués.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ils peuvent cliquer sur le point de soumettre et nous pouvons voir ou non approuvés, ce qui est entré, ce qui signifie que le processus de soumission du budget est complètement approuvé et ceux-ci peuvent être publiés dans différents départements et qu'ils peuvent avoir une copie finale téléchargée dans leur système local et ils peuvent consulter comme un PDF une fois signé avec tous les commentaires et mises à jour effectués.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_53_0.mp3\n",
      "[Debug] Segment 55 final translation: Nous pouvons également voir les mises à jour que nous avons faites aux commentaires.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons également voir les mises à jour que nous avons faites aux commentaires.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_54_0.mp3\n",
      "✅ Translated audio saved to: 4.2.3_La création de rapports_run_20250415_181829\\4.2.3_La création de rapports-french.wav\n",
      "📝 Debug log saved to: 4.2.3_La création de rapports_run_20250415_181829\\translation_debug_log.txt\n",
      "Merging audio and video...\n",
      "Moviepy - Building video 4.2.3_La création de rapports_run_20250415_181829\\4.2.3_La création de rapports-french.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video 4.2.3_La création de rapports_run_20250415_181829\\4.2.3_La création de rapports-french.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 4.2.3_La création de rapports_run_20250415_181829\\4.2.3_La création de rapports-french.mp4\n",
      "Process completed! Output video: 4.2.3_La création de rapports_run_20250415_181829\\4.2.3_La création de rapports-french.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.3_La création de rapports.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version we rely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Silence Duration:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"----------------------------------------------------------------\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # default ms\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    print(\"Parsed review file overrides:\")\n",
    "    for idx, override in enumerate(segments_overrides, 1):\n",
    "        print(f\"  Segment {idx} final translation: {override['final_translation']}\")\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text)\n",
    "    return [phrase.strip() for phrase in phrases if phrase.strip()]\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    Note: In Edge TTS v7.0.0 the 'session' parameter is not supported.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session for each attempt.\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate\n",
    "                )\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "\n",
    "        print(f\"[Debug] Segment {idx+1} final translation: {final_translation}\")\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            try:\n",
    "                audio = AudioSegment.from_mp3(temp_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Unable to load audio from {temp_path}: {e}. Skipping this phrase.\")\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "                continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"[Debug] Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "print(edge_tts.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285235e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "from aiohttp import ClientConnectorError\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.3_La création de rapports.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split('---') if blk.strip()]\n",
    "    \n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== Robust TTS Function with Retry and Jitter ==============\n",
    "async def robust_synthesize_phrase(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    connector: aiohttp.TCPConnector,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\",\n",
    "    max_retries: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Synthesize speech for a given phrase using Edge TTS with robust retry logic.\n",
    "    Uses exponential backoff with random jitter to mitigate transient connection issues.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session using the shared persistent connector.\n",
    "            async with aiohttp.ClientSession(connector=connector, timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate,\n",
    "                    connector=connector\n",
    "                )\n",
    "                await communicate.save(output_path)\n",
    "                return\n",
    "        except (ClientConnectorError, ConnectionResetError) as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Connection error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "# ============== TTS Functions Wrapper ==============\n",
    "# For backward compatibility, if you want to call the function by its former name.\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, connector, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Persistent Connector Creation ==============\n",
    "def create_persistent_connector():\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context, limit=10)\n",
    "    return connector\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path, persistent_connector):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    offset_threshold = 0.05\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await robust_synthesize_phrase(\n",
    "                    phrase, temp_path, connector=persistent_connector, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override\n",
    "                )\n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        \n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function (unchanged) ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    persistent_connector = create_persistent_connector()  # Create the persistent connector\n",
    "    try:\n",
    "        print(\"Extracting audio...\")\n",
    "        audio_path = extract_audio()\n",
    "    \n",
    "        print(\"Transcribing audio...\")\n",
    "        language, segments = transcribe(audio_path)\n",
    "    \n",
    "        print(\"Generating English subtitles...\")\n",
    "        generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "        print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "        await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file, persistent_connector)\n",
    "    \n",
    "        print(\"Merging audio and video...\")\n",
    "        merge_audio_video()\n",
    "    \n",
    "        print(f\"Process completed! Output video: {output_video}\")\n",
    "    finally:\n",
    "        await persistent_connector.close()  # Close the persistent connector\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio, datetime\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import tempfile\n",
    "import sys  # Import the sys module\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "subtitle_file_fr = os.path.join(output_dir, f\"{input_video_name}-french.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "\n",
    "# ============== Helper Functions ==============\n",
    "\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    original_texts = []\n",
    "\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            original_texts.append(original_text)\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            final_translation = auto_translated\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {final_translation}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations in the file as needed.\")\n",
    "\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "\n",
    "    return groups, original_texts\n",
    "\n",
    "def parse_final_translations(review_file_path):\n",
    "    final_translations = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    segments = content.strip().split('---')\n",
    "    for seg in segments:\n",
    "        if seg.strip() == \"\" or \"Final Translation:\" not in seg:\n",
    "            continue\n",
    "        match = re.search(r'\\*\\*Final Translation:\\*\\*\\s*(.*)', seg)\n",
    "        if match:\n",
    "            final_translation = match.group(1).strip()\n",
    "            final_translations.append(final_translation)\n",
    "    return final_translations\n",
    "\n",
    "def validate_review_with_retranslation(review_file_path, groups, original_texts, from_lang, to_lang):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "\n",
    "    while True:\n",
    "        current_originals = []\n",
    "        updated_segments = []\n",
    "\n",
    "        with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        segments = content.strip().split('---')\n",
    "        seg_index = 0\n",
    "        for i, seg in enumerate(segments):\n",
    "            if not seg.strip() or \"Segment\" not in seg:\n",
    "                continue\n",
    "\n",
    "            if seg_index < len(original_texts) and \"Original:\" in seg:\n",
    "                original_match = re.search(r'\\*\\*Original:\\*\\*\\s*(.*)', seg)\n",
    "                current_original = original_match.group(1).strip() if original_match else \"\"\n",
    "                current_originals.append(current_original)\n",
    "\n",
    "                if current_original != original_texts[seg_index]:\n",
    "                    updated_segments.append(seg_index)\n",
    "            else:\n",
    "                current_originals.append(\"\")\n",
    "\n",
    "            seg_index += 1\n",
    "\n",
    "        if updated_segments:\n",
    "            print(f\"⚠️  Detected changes in {len(updated_segments)} original segments. Retranslating...\")\n",
    "            new_content = []\n",
    "            seg_index = 0\n",
    "\n",
    "            for seg in segments:\n",
    "                if not seg.strip() or \"Segment\" not in seg:\n",
    "                    new_content.append(seg)\n",
    "                    continue\n",
    "\n",
    "                if seg_index in updated_segments:\n",
    "                    new_translation = translator.translate(text=current_originals[seg_index])\n",
    "\n",
    "                    seg = re.sub(\n",
    "                        r'(\\*\\*Auto Translated:\\*\\*)(.*?)(\\n\\*\\*Final Translation:\\*\\*)',\n",
    "                        f'\\\\1 {new_translation}\\\\3 {new_translation}',\n",
    "                        seg,\n",
    "                        flags=re.DOTALL\n",
    "                    )\n",
    "\n",
    "                new_content.append(seg)\n",
    "                seg_index += 1\n",
    "\n",
    "            with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write('---'.join(new_content))\n",
    "\n",
    "            print(\"Updated translations written. Please review changes.\")\n",
    "            while True:\n",
    "                user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "                if user_confirmation == \"y\":\n",
    "                    break\n",
    "            original_texts = current_originals\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return parse_final_translations(review_file_path)\n",
    "\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        adjusted_audio = audio + silence\n",
    "        return adjusted_audio\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        adjusted_audio = audio[:-int(trim_duration_ms)]\n",
    "        return adjusted_audio\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "\n",
    "def synthesize_phrase_edge(text, output_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"):\n",
    "    \"\"\"Synthesize the given phrase using edge-tts, using shell=True for Windows compatibility.\"\"\"\n",
    "    command = [\n",
    "        \"edge-tts\",\n",
    "        \"--voice\", voice,\n",
    "        \"--text\", text,\n",
    "        \"--write-media\", output_path,\n",
    "        \"--rate\", rate\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        process = asyncio.create_subprocess_exec(\n",
    "            *command,\n",
    "            stdin=asyncio.subprocess.PIPE,\n",
    "            stdout=asyncio.subprocess.PIPE,\n",
    "            stderr=asyncio.subprocess.PIPE,\n",
    "            shell=True  # Enable shell execution\n",
    "        )\n",
    "\n",
    "        async def run_process():\n",
    "            proc = await process\n",
    "            stdout, stderr = await proc.communicate()\n",
    "\n",
    "            if proc.returncode != 0:\n",
    "                print(f\"Error executing edge-tts: {stderr.decode()}\")\n",
    "            else:\n",
    "                print(f\"Successfully synthesized phrase: {text[:50]}... to {output_path}\")\n",
    "                return output_path\n",
    "\n",
    "        return asyncio.run(run_process())\n",
    "\n",
    "    except NotImplementedError as e:\n",
    "        print(f\"NotImplementedError: {e}. This might be due to asyncio subprocess issues on Windows.\")\n",
    "        print(\"Trying a different approach using os.system (less robust)...\")\n",
    "        \n",
    "        # Fallback to os.system (less robust, but might work on Windows)\n",
    "        command_str = \" \".join(command)\n",
    "        return_code = os.system(command_str)\n",
    "        \n",
    "        if return_code == 0:\n",
    "            print(f\"Successfully synthesized phrase (using os.system): {text[:50]}... to {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            print(f\"Error executing edge-tts (using os.system): Return code {return_code}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "\n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "\n",
    "def generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups, original_texts = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    final_translations = validate_review_with_retranslation(review_file_path, groups, original_texts, \"en\", \"fr\")\n",
    "\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "\n",
    "    offset_threshold = 0.05\n",
    "\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = final_translations[idx]\n",
    "\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "\n",
    "            audio_file = synthesize_phrase_edge(\n",
    "                phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"\n",
    "            )\n",
    "\n",
    "            if audio_file and os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                try:\n",
    "                    audio = AudioSegment.from_mp3(temp_path)\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Audio corrompu ignoré : {temp_path}. Erreur: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Fichier manquant ou invalide: {temp_path}\")\n",
    "\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=100)\n",
    "\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : ajustement de vitesse appliqué, facteur={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "\n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration avant ajustement:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "\n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio = audio + extra_silence\n",
    "    \n",
    "    new_video = video.set_audio(audio)\n",
    "    new_video.write_videofile(output_video, codec=\"libx264\", audio_codec=\"aac\", temp_audiofile='temp-audio.m4a', remove_temp=True)\n",
    "    return output_video\n",
    "\n",
    "\n",
    "# ============== Main Flow ==============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if running on Windows\n",
    "    if os.name == 'nt':\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "    # 1. Extract Audio\n",
    "    print(\"Extracting audio...\")\n",
    "    extracted_audio = extract_audio()\n",
    "\n",
    "    # 2. Transcribe Audio\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, transcript_segments = transcribe(extracted_audio)\n",
    "\n",
    "    # 3. Generate English Subtitle File\n",
    "    print(\"Generating English subtitle file...\")\n",
    "    subtitle_file_en = generate_subtitle_file(transcript_segments, subtitle_file_en)\n",
    "\n",
    "    # 4. Generate Translation Review File\n",
    "    print(\"Generating translation review file...\")\n",
    "    groups, original_texts = generate_translation_review_file(subtitle_file_en, review_file)\n",
    "\n",
    "    # 5. NEW: Validate Review and Retranslate if Originals Changed\n",
    "    print(\"Validating and applying translations from review file...\")\n",
    "    final_translations = validate_review_with_retranslation(\n",
    "        review_file, groups, original_texts, \"en\", \"fr\"\n",
    "    )\n",
    "\n",
    "    # 6. Generate Translated Audio\n",
    "    print(\"Generating translated audio...\")\n",
    "    translated_audio = generate_translated_audio_with_sync_using_review(\n",
    "        subtitle_file_en, translated_audio, debug_log_file, review_file\n",
    "    )\n",
    "\n",
    "    # 7. Merge Audio and Video\n",
    "    print(\"Merging audio and video...\")\n",
    "    output_video = merge_audio_video()\n",
    "\n",
    "    print(f\"✅ Final video saved to: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdadfe",
   "metadata": {},
   "source": [
    "4.2.2_Flux de navigation_Avr_08_Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime   \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.3_La création de rapports.mp4\"  # Path to your input video\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]  # e.g. \"4.2.4_Configuration de la solution_Avr_10_Latest\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")            # e.g. \"20250414_173015\"\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"        # Whisper model size (tiny, base, small, medium, large)\n",
    "update_existing = True      # Set to True to allow interactive review/edit of translations\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "subtitle_file_fr = os.path.join(output_dir, f\"{input_video_name}-french.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "\n",
    "# ============== Helper Functions ==============\n",
    "\n",
    "def extract_audio():\n",
    "    \"\"\"Extract audio from video using ffmpeg\"\"\"\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)  # mono and 16kHz\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    \"\"\"Transcribe audio using faster-whisper.\"\"\"\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    \"\"\"Convert seconds to SubRipTime format\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    \"\"\"Generate subtitle file (SRT) from segments.\"\"\"\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    \"\"\"Generate a review file that lists each segment's original and auto translated text.\n",
    "    \n",
    "    The review file is written in a format that allows the user to update the final translation.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    # Group subtitles by sentence using a simple punctuation detection.\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    # Write the review file using the grouping information.\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            # Concatenate original texts.\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            # Auto-translate the concatenated text.\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            # Start with auto translation as the default final translation.\n",
    "            final_translation = auto_translated\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {final_translation}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations in the file as needed.\")\n",
    "    # Wait for user confirmation.\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_final_translations(review_file_path):\n",
    "    \"\"\"Parse the updated review file to extract the final translations for each segment group.\n",
    "    \n",
    "    This function expects that each segment block includes a line starting with \n",
    "    '**Final Translation:**' and returns a list of final translations (in the same order as groups).\n",
    "    \"\"\"\n",
    "    final_translations = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    # Split by segments based on the separator.\n",
    "    segments = content.strip().split('---')\n",
    "    for seg in segments:\n",
    "        if seg.strip() == \"\" or \"Final Translation:\" not in seg:\n",
    "            continue\n",
    "        # Extract the line that starts with '**Final Translation:**'\n",
    "        match = re.search(r'\\*\\*Final Translation:\\*\\*\\s*(.*)', seg)\n",
    "        if match:\n",
    "            final_translation = match.group(1).strip()\n",
    "            final_translations.append(final_translation)\n",
    "    return final_translations\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    \"\"\"Adjust the audio to match the target duration.\n",
    "    \n",
    "    If audio is too short, append silence; if too long, trim the end.\n",
    "    \"\"\"\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:  # Audio too short: add silence.\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        adjusted_audio = audio + silence\n",
    "        return adjusted_audio\n",
    "    elif difference < -0.1:  # Audio too long: trim the end.\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        adjusted_audio = audio[:-int(trim_duration_ms)]\n",
    "        return adjusted_audio\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "\n",
    "# ============== NEW: French Phrase Alignment Functions ==============\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text into phrases using punctuation aware of French grammar.\"\"\"\n",
    "    # Fixed regex pattern with atomic grouping for French abbreviations\n",
    "    sentence_end = re.compile(\n",
    "        r'(?<!\\bM(?:r|me|s|rs|mes))\\s*([.!?])(?:\\s+|$)'\n",
    "    )\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check for sentence-ending punctuation with French context\n",
    "        if sentence_end.search(word):\n",
    "            # Check if next word starts with uppercase (proper sentence end)\n",
    "            if i+1 < len(words) and words[i+1][0].isupper():\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text at natural phrase boundaries for technical content.\"\"\"\n",
    "    # Focus on sentence-ending punctuation followed by uppercase\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check if word ends with sentence punctuation\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            # Check if next word starts with uppercase or we're at the end\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    \n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    \"\"\"Calculate duration allocation weights for French phrases based solely on their word counts.\"\"\"\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    # Compute each weight as the fraction of the total French words\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "\n",
    "# ============== MODIFIED Audio Generat\n",
    "    \n",
    "  \n",
    "import tempfile\n",
    "\n",
    "# ============== MODIFIED Audio Generation Function ==============\n",
    "\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import tempfile\n",
    "import pysrt\n",
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    \"\"\"Version améliorée avec alignement au niveau des phrases françaises, détection du décalage\n",
    "       et ajustement automatique de la vitesse de lecture pour corriger les écarts.\"\"\"\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    final_translations = parse_final_translations(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    # Seuil pour détecter un décalage notable (en secondes)\n",
    "    offset_threshold = 0.05  # par exemple 50 ms, à ajuster selon vos tests\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = final_translations[idx]\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            # Utiliser une extension .mp3 car edge-tts produit du MP3\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            \n",
    "            try:\n",
    "                asyncio.run(synthesize_phrase_edge(\n",
    "                    phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"\n",
    "                ))\n",
    "                \n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Audio corrompu ignoré : {temp_path}. Erreur: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Fichier manquant ou invalide: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=100)\n",
    "        \n",
    "        # Optionnel : on tronque si la durée dépasse\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        \n",
    "        # Vérifier si le segment audio généré colle exactement aux timings attendus\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        # Si l'écart est significatif, ajuster la vitesse.\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : ajustement de vitesse appliqué, facteur={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration avant ajustement:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "\n",
    "def merge_audio_video():\n",
    "    \"\"\"Merge the newly generated audio with the original video.\"\"\"\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    # If the audio is shorter than video, append silence.\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import edge_tts\n",
    "\n",
    "\n",
    "async def synthesize_phrase_edge(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\"\n",
    "):\n",
    "    communicate = edge_tts.Communicate(\n",
    "        text=phrase,\n",
    "        voice=voice,\n",
    "        rate=rate\n",
    "    )\n",
    "    await communicate.save(output_path)  # Removed format parameter\n",
    "\n",
    "\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    \"\"\"Change la vitesse de lecture de 'sound' par le facteur 'speed'.\"\"\"\n",
    "    # On modifie le frame rate, puis on remet à la normale pour obtenir le nouveau son.\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Main Flow ==============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Extract audio.\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    \n",
    "    # Step 2: Transcribe audio.\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    \n",
    "    # Step 3: Generate English subtitles.\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "    # (Optional) Step 4: Translate subtitles (if needed for other purposes).\n",
    "    # In our flow, we now use the auto translation during review.\n",
    "    # print(\"Translating subtitles...\")\n",
    "    # translate_subtitles(subtitle_file_en, subtitle_file_fr)\n",
    "    \n",
    "    # Step 5: Generate French audio using the review file.\n",
    "    print(\"Generating French audio with synchronization...\")\n",
    "    generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(f\"Debug log written to: {debug_log_file}\")\n",
    "    \n",
    "    # Step 6: Merge audio and video.\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    \n",
    "    print(f\"Process completed! Output video: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime   \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.4_Configuration de la solution_Avr_10_Latest.mp4\" \n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]  # e.g. \"4.2.4_Configuration de la solution_Avr_10_Latest\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")            # e.g. \"20250414_173015\"\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"        # Whisper model size (tiny, base, small, medium, large)\n",
    "update_existing = True      # Set to True to allow interactive review/edit of translations\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "subtitle_file_fr = os.path.join(output_dir, f\"{input_video_name}-french.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "\n",
    "# ============== Helper Functions ==============\n",
    "\n",
    "def extract_audio():\n",
    "    \"\"\"Extract audio from video using ffmpeg\"\"\"\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)  # mono and 16kHz\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    \"\"\"Transcribe audio using faster-whisper.\"\"\"\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    \"\"\"Convert seconds to SubRipTime format\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    \"\"\"Generate subtitle file (SRT) from segments.\"\"\"\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    \"\"\"Generate a review file that lists each segment's original and auto translated text.\n",
    "    \n",
    "    The review file is written in a format that allows the user to update the final translation.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    # Group subtitles by sentence using a simple punctuation detection.\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    # Write the review file using the grouping information.\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            # Concatenate original texts.\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            # Auto-translate the concatenated text.\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            # Start with auto translation as the default final translation.\n",
    "            final_translation = auto_translated\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {final_translation}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations in the file as needed.\")\n",
    "    # Wait for user confirmation.\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_final_translations(review_file_path):\n",
    "    \"\"\"Parse the updated review file to extract the final translations for each segment group.\n",
    "    \n",
    "    This function expects that each segment block includes a line starting with \n",
    "    '**Final Translation:**' and returns a list of final translations (in the same order as groups).\n",
    "    \"\"\"\n",
    "    final_translations = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    # Split by segments based on the separator.\n",
    "    segments = content.strip().split('---')\n",
    "    for seg in segments:\n",
    "        if seg.strip() == \"\" or \"Final Translation:\" not in seg:\n",
    "            continue\n",
    "        # Extract the line that starts with '**Final Translation:**'\n",
    "        match = re.search(r'\\*\\*Final Translation:\\*\\*\\s*(.*)', seg)\n",
    "        if match:\n",
    "            final_translation = match.group(1).strip()\n",
    "            final_translations.append(final_translation)\n",
    "    return final_translations\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    \"\"\"Adjust the audio to match the target duration.\n",
    "    \n",
    "    If audio is too short, append silence; if too long, trim the end.\n",
    "    \"\"\"\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:  # Audio too short: add silence.\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        adjusted_audio = audio + silence\n",
    "        return adjusted_audio\n",
    "    elif difference < -0.1:  # Audio too long: trim the end.\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        adjusted_audio = audio[:-int(trim_duration_ms)]\n",
    "        return adjusted_audio\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "\n",
    "# ============== NEW: French Phrase Alignment Functions ==============\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text into phrases using punctuation aware of French grammar.\"\"\"\n",
    "    # Fixed regex pattern with atomic grouping for French abbreviations\n",
    "    sentence_end = re.compile(\n",
    "        r'(?<!\\bM(?:r|me|s|rs|mes))\\s*([.!?])(?:\\s+|$)'\n",
    "    )\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check for sentence-ending punctuation with French context\n",
    "        if sentence_end.search(word):\n",
    "            # Check if next word starts with uppercase (proper sentence end)\n",
    "            if i+1 < len(words) and words[i+1][0].isupper():\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text at natural phrase boundaries for technical content.\"\"\"\n",
    "    # Focus on sentence-ending punctuation followed by uppercase\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check if word ends with sentence punctuation\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            # Check if next word starts with uppercase or we're at the end\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    \n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    \"\"\"Calculate duration allocation weights for French phrases based solely on their word counts.\"\"\"\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    # Compute each weight as the fraction of the total French words\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "\n",
    "# ============== MODIFIED Audio Generat\n",
    "    \n",
    "  \n",
    "import tempfile\n",
    "\n",
    "# ============== MODIFIED Audio Generation Function ==============\n",
    "\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import tempfile\n",
    "import pysrt\n",
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    \"\"\"Version améliorée avec alignement au niveau des phrases françaises, détection du décalage\n",
    "       et ajustement automatique de la vitesse de lecture pour corriger les écarts.\"\"\"\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    final_translations = parse_final_translations(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    # Seuil pour détecter un décalage notable (en secondes)\n",
    "    offset_threshold = 0.05  # par exemple 50 ms, à ajuster selon vos tests\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = final_translations[idx]\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            # Utiliser une extension .mp3 car edge-tts produit du MP3\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            \n",
    "            try:\n",
    "                asyncio.run(synthesize_phrase_edge(\n",
    "                    phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"\n",
    "                ))\n",
    "                \n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Audio corrompu ignoré : {temp_path}. Erreur: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Fichier manquant ou invalide: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=100)\n",
    "        \n",
    "        # Optionnel : on tronque si la durée dépasse\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        \n",
    "        # Vérifier si le segment audio généré colle exactement aux timings attendus\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        # Si l'écart est significatif, ajuster la vitesse.\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : ajustement de vitesse appliqué, facteur={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration avant ajustement:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "\n",
    "def merge_audio_video():\n",
    "    \"\"\"Merge the newly generated audio with the original video.\"\"\"\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    # If the audio is shorter than video, append silence.\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import edge_tts\n",
    "\n",
    "\n",
    "async def synthesize_phrase_edge(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\"\n",
    "):\n",
    "    communicate = edge_tts.Communicate(\n",
    "        text=phrase,\n",
    "        voice=voice,\n",
    "        rate=rate\n",
    "    )\n",
    "    await communicate.save(output_path)  # Removed format parameter\n",
    "\n",
    "\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    \"\"\"Change la vitesse de lecture de 'sound' par le facteur 'speed'.\"\"\"\n",
    "    # On modifie le frame rate, puis on remet à la normale pour obtenir le nouveau son.\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Main Flow ==============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Extract audio.\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    \n",
    "    # Step 2: Transcribe audio.\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    \n",
    "    # Step 3: Generate English subtitles.\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "    # (Optional) Step 4: Translate subtitles (if needed for other purposes).\n",
    "    # In our flow, we now use the auto translation during review.\n",
    "    # print(\"Translating subtitles...\")\n",
    "    # translate_subtitles(subtitle_file_en, subtitle_file_fr)\n",
    "    \n",
    "    # Step 5: Generate French audio using the review file.\n",
    "    print(\"Generating French audio with synchronization...\")\n",
    "    generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(f\"Debug log written to: {debug_log_file}\")\n",
    "    \n",
    "    # Step 6: Merge audio and video.\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    \n",
    "    print(f\"Process completed! Output video: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef903f90",
   "metadata": {},
   "source": [
    "UPDATE AFTER VIEWING VIDEO : adjust speed and silence\n",
    "Translation Review File\n",
    "You can update the following properties for each segment:\n",
    "  **Final Translation:** Your updated French text\n",
    "  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\n",
    "  **Silence Duration:** Silence (in ms) to append (default 100 ms)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba35835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "from aiohttp import ClientConnectorError\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split('---') if blk.strip()]\n",
    "    \n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions ==============\n",
    "async def synthesize_phrase_edge_hybrid(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    connector: aiohttp.TCPConnector,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\"\n",
    "):\n",
    "    max_retries = 3\n",
    "    delay_seconds = 1\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Each TTS call creates its own session using the shared connector.\n",
    "            async with aiohttp.ClientSession(connector=connector, timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate,\n",
    "                    connector=connector\n",
    "                )\n",
    "                await communicate.save(output_path)\n",
    "                return\n",
    "        except (ClientConnectorError, ConnectionResetError, Exception) as e:\n",
    "            print(f\"[Error] Hybrid TTS synthesis failed for phrase: '{phrase}' on attempt {attempt+1}/{max_retries}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                await asyncio.sleep(delay_seconds)\n",
    "                delay_seconds *= 2\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Persistent Connector Creation ==============\n",
    "def create_persistent_connector():\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context, limit=10)\n",
    "    return connector\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path, persistent_connector):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    offset_threshold = 0.05\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(\n",
    "                    phrase, temp_path, connector=persistent_connector, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override\n",
    "                )\n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        \n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function (unchanged) ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    persistent_connector = create_persistent_connector()  # Create the persistent connector\n",
    "    try:\n",
    "        print(\"Extracting audio...\")\n",
    "        audio_path = extract_audio()\n",
    "    \n",
    "        print(\"Transcribing audio...\")\n",
    "        language, segments = transcribe(audio_path)\n",
    "    \n",
    "        print(\"Generating English subtitles...\")\n",
    "        generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "        print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "        await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file, persistent_connector)\n",
    "    \n",
    "        print(\"Merging audio and video...\")\n",
    "        merge_audio_video()\n",
    "    \n",
    "        print(f\"Process completed! Output video: {output_video}\")\n",
    "    finally:\n",
    "        await persistent_connector.close()  # Close the persistent connector\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a54ae",
   "metadata": {},
   "source": [
    "UPDATE AFTER VIEWING VIDEO : adjust speed and silence per words or phrases\n",
    "Translation Review File\n",
    "You can update the following properties for each segment:\n",
    "  **Final Translation:** Your updated French text\n",
    "  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\n",
    "  **Silence Duration:** Silence (in ms) to append (default 100 ms)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b798c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n",
      "Detected language: en\n",
      "Generating English subtitles...\n",
      "Generating French audio with synchronization and manual overrides...\n",
      "Review file created at: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\translation_review.txt\n",
      "Please review and update the final translations as needed.\n",
      "Parsed review file overrides:\n",
      "  Segment 1 final translation: Dans cette démo, nous explorerons comment créer un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.\n",
      "  Segment 2 final translation: Le flux de navigation améliore l'expérience utilisateur avec des voies structurées intuitives pour la navigation sans effort à travers les modules et les tâches.\n",
      "  Segment 3 final translation: Permet une petite transition entre la saisie des données, les rapports et la gestion des processus, l'optimisation de l'efficacité avec les flux de travail de planification et d'analyse.\n",
      "  Segment 4 final translation: L'utilisateur s'est connecté à l'application de planification EPM. Ils verront cette page de destination.\n",
      "  Segment 5 final translation: En cliquant sur l'icône du sélecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.\n",
      "  Segment 6 final translation: La planification EPM est livrée avec le flux de navigation par défaut. Vous pouvez basculer vers un flux de navigation différent simplement en cliquant dessus.\n",
      "  Segment 7 final translation: Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activées pour ce flux de navigation particulier.\n",
      "  Segment 8 final translation: Revenons maintenant à EPM Flow.\n",
      "  Segment 9 final translation: Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans différents modules sans perte de données.\n",
      "  Segment 10 final translation: Cliquez sur l'icône Navigator pour voir plus d'options. Cliquez sur la carte de données et ouvrirons un formulaire de dépenses dans le dossier de démonstration.\n",
      "  Segment 11 final translation: Je vais étendre l'année totale et je peux voir les quarts et je vais saisir certaines données.\n",
      "  Segment 12 final translation: C'était donc 9000 et entrant dans un 6000 et enregistrons ceci.\n",
      "  Segment 13 final translation: Vous pouvez voir comment les données sont reflétées et nous pouvons voir un 15000 maintenant.\n",
      "  Segment 14 final translation: Je vais cliquer sur la page d'accueil et ouvrir un rapport.\n",
      "  Segment 15 final translation: Je vais rechercher un rapport et cela montre les résultats de tous les rapports et je vais ouvrir le rapport du dossier de démonstration.\n",
      "  Segment 16 final translation: Je ferai ce rapport. Je vais cliquer sur la page d'accueil.\n",
      "  Segment 17 final translation: Je peux également cliquer sur la carte de données de la page d'accueil.\n",
      "  Segment 18 final translation: Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.\n",
      "  Segment 19 final translation: Dans cette page de destination, nous pouvons voir 7 icônes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.\n",
      "  Segment 20 final translation: Nous allons désactiver la modélisation stratégique et nous allons activer une nouvelle modélisation financière de carte dans cette démo.\n",
      "  Segment 21 final translation: Pour configurer le flux de navigation, un utilisateur doit avoir un accès d'administration de service.\n",
      "  Segment 22 final translation: Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.\n",
      "  Segment 23 final translation: Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.\n",
      "  Segment 24 final translation: Vous pouvez sélectionner le flux de navigation et cliquer sur l'icône de l'engrenage pour voir diverses options.\n",
      "  Segment 25 final translation: Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.\n",
      "  Segment 26 final translation: Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.\n",
      "  Segment 27 final translation: Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.\n",
      "  Segment 28 final translation: Cliquez sur le nom du flux de navigation pour commencer à apporter des modifications.\n",
      "  Segment 29 final translation: Chaque élément est désigné un type, un cluster ou une carte, un état de visibilité, désactivé, activé.\n",
      "  Segment 30 final translation: Option pour réorganiser et supprimer.\n",
      "  Segment 31 final translation: Pour cette démo, nous allons activer le cluster financier qui est désactivé ici en haut et nous allons désactiver la modélisation stratégique.\n",
      "  Segment 32 final translation: Dans le cluster financier, nous allons réorganiser en déplaçant les revenus en haut.\n",
      "  Segment 33 final translation: J'ai également les options pour créer un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.\n",
      "  Segment 34 final translation: J'ai également les options pour attribuer des autorisations aux groupes d'utilisateurs ou des rôles attribués à ce flux de navigation particulier.\n",
      "  Segment 35 final translation: Et je vais économiser et fermer ce flux de navigation.\n",
      "  Segment 36 final translation: Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.\n",
      "  Segment 37 final translation: En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la modélisation stratégique et que nous ne voyons pas encore le cluster de modélisation financière.\n",
      "  Segment 38 final translation: Pour actualiser le flux de navigation, ouvrez l'icône du sélecteur de flux de navigation et cliquez sur Actualiser.\n",
      "  Segment 39 final translation: La page recharge avec le cluster financier et nous ne voyons plus le cluster de modélisation stratégique.\n",
      "  Segment 40 final translation: Cliquer sur le cluster financier montre les revenus au premier tel que nous avons réorganisé.\n",
      "  Segment 41 final translation: Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.\n",
      "  Segment 42 final translation: Ici, il s'agit d'une données de travail pour votre FY23.\n",
      "  Segment 43 final translation: Sur planant sur ces icônes nous jettera des informations détaillées dans ce tableau de bord particulier.\n",
      "  Segment 44 final translation: Nous pouvons obtenir plus de détails en les survolant.\n",
      "  Segment 45 final translation: Nous pouvons également naviguer vers différents onglets et voir plus d'informations.\n",
      "  Segment 46 final translation: Nous avons également des onglets en bas et en haut.\n",
      "  Segment 47 final translation: Nous pouvons voir toutes les dernières tendances pour l'année particulière et nous pouvons survoler les plus d'informations.\n",
      "  Segment 48 final translation: Dans cette démo, nous avons exploré notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux rôles.\n",
      "[Debug] Segment 1 final translation: Dans cette démo, nous explorerons comment créer un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.\n",
      "[Debug] Generated SSML for segment 1: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans cette démo, nous explorerons comment créer un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans cette démo, nous explorerons comment créer un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Dans cette démo, nous explorerons comment créer un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837D5B0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.62 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Dans cette démo, nous explorerons comment créer un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_0.mp3\n",
      "[Debug] Segment 2 final translation: Le flux de navigation améliore l'expérience utilisateur avec des voies structurées intuitives pour la navigation sans effort à travers les modules et les tâches.\n",
      "[Debug] Generated SSML for segment 2: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"-10%\">Le flux de navigation améliore l'expérience utilisateur avec des voies structurées intuitives pour la navigation sans effort à travers les modules et les tâches.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Le flux de navigation améliore l'expérience utilisateur avec des voies structurées intuitives pour la navigation sans effort à travers les modules et les tâches.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_1.mp3\n",
      "[Debug] Segment 3 final translation: Permet une petite transition entre la saisie des données, les rapports et la gestion des processus, l'optimisation de l'efficacité avec les flux de travail de planification et d'analyse.\n",
      "[Debug] Generated SSML for segment 3: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Permet une petite transition entre la saisie des données, les rapports et la gestion des processus, l'optimisation de l'efficacité avec les flux de travail de planification et d'analyse.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Permet une petite transition entre la saisie des données, les rapports et la gestion des processus, l'optimisation de l'efficacité avec les flux de travail de planification et d'analyse.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_2.mp3\n",
      "[Debug] Segment 4 final translation: L'utilisateur s'est connecté à l'application de planification EPM. Ils verront cette page de destination.\n",
      "[Debug] Generated SSML for segment 4: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">L'utilisateur s'est connecté à l'application de planification EPM. Ils verront cette page de destination.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'L'utilisateur s'est connecté à l'application de planification EPM. Ils verront cette page de destination.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_3.mp3\n",
      "[Debug] Segment 5 final translation: En cliquant sur l'icône du sélecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.\n",
      "[Debug] Generated SSML for segment 5: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">En cliquant sur l'icône du sélecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'En cliquant sur l'icône du sélecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_4.mp3\n",
      "[Debug] Segment 6 final translation: La planification EPM est livrée avec le flux de navigation par défaut. Vous pouvez basculer vers un flux de navigation différent simplement en cliquant dessus.\n",
      "[Debug] Generated SSML for segment 6: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">La planification EPM est livrée avec le flux de navigation par défaut. Vous pouvez basculer vers un flux de navigation différent simplement en cliquant dessus.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'La planification EPM est livrée avec le flux de navigation par défaut. Vous pouvez basculer vers un flux de navigation différent simplement en cliquant dessus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_5.mp3\n",
      "[Debug] Segment 7 final translation: Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activées pour ce flux de navigation particulier.\n",
      "[Debug] Generated SSML for segment 7: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activées pour ce flux de navigation particulier.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activées pour ce flux de navigation particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_6.mp3\n",
      "[Debug] Segment 8 final translation: Revenons maintenant à EPM Flow.\n",
      "[Debug] Generated SSML for segment 8: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Revenons maintenant à EPM Flow.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Revenons maintenant à EPM Flow.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Revenons maintenant à EPM Flow.'. Exception: No audio was received. Please verify that your parameters are correct.\n",
      "[Debug] Retrying in 1.67 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Revenons maintenant à EPM Flow.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Revenons maintenant à EPM Flow.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837E450> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.94 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase using SSML: 'Revenons maintenant à EPM Flow.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_7.mp3\n",
      "[Debug] Segment 9 final translation: Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans différents modules sans perte de données.\n",
      "[Debug] Generated SSML for segment 9: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans différents modules sans perte de données.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans différents modules sans perte de données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_8.mp3\n",
      "[Debug] Segment 10 final translation: Cliquez sur l'icône Navigator pour voir plus d'options. Cliquez sur la carte de données et ouvrirons un formulaire de dépenses dans le dossier de démonstration.\n",
      "[Debug] Generated SSML for segment 10: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur l'icône Navigator pour voir plus d'options. Cliquez sur la carte de données et ouvrirons un formulaire de dépenses dans le dossier de démonstration.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur l'icône Navigator pour voir plus d'options. Cliquez sur la carte de données et ouvrirons un formulaire de dépenses dans le dossier de démonstration.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_9.mp3\n",
      "[Debug] Segment 11 final translation: Je vais étendre l'année totale et je peux voir les quarts et je vais saisir certaines données.\n",
      "[Debug] Generated SSML for segment 11: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je vais étendre l'année totale et je peux voir les quarts et je vais saisir certaines données.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je vais étendre l'année totale et je peux voir les quarts et je vais saisir certaines données.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_10.mp3\n",
      "[Debug] Segment 12 final translation: C'était donc 9000 et entrant dans un 6000 et enregistrons ceci.\n",
      "[Debug] Generated SSML for segment 12: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">C'était donc 9000 et entrant dans un 6000 et enregistrons ceci.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'C'était donc 9000 et entrant dans un 6000 et enregistrons ceci.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_11.mp3\n",
      "[Debug] Segment 13 final translation: Vous pouvez voir comment les données sont reflétées et nous pouvons voir un 15000 maintenant.\n",
      "[Debug] Generated SSML for segment 13: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Vous pouvez voir comment les données sont reflétées et nous pouvons voir un 15000 maintenant.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Vous pouvez voir comment les données sont reflétées et nous pouvons voir un 15000 maintenant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_12.mp3\n",
      "[Debug] Segment 14 final translation: Je vais cliquer sur la page d'accueil et ouvrir un rapport.\n",
      "[Debug] Generated SSML for segment 14: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je vais cliquer sur la page d'accueil et ouvrir un rapport.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je vais cliquer sur la page d'accueil et ouvrir un rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_13.mp3\n",
      "[Debug] Segment 15 final translation: Je vais rechercher un rapport et cela montre les résultats de tous les rapports et je vais ouvrir le rapport du dossier de démonstration.\n",
      "[Debug] Generated SSML for segment 15: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je vais rechercher un rapport et cela montre les résultats de tous les rapports et je vais ouvrir le rapport du dossier de démonstration.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je vais rechercher un rapport et cela montre les résultats de tous les rapports et je vais ouvrir le rapport du dossier de démonstration.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_14.mp3\n",
      "[Debug] Segment 16 final translation: Je ferai ce rapport. Je vais cliquer sur la page d'accueil.\n",
      "[Debug] Generated SSML for segment 16: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je ferai ce rapport. Je vais cliquer sur la page d'accueil.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je ferai ce rapport. Je vais cliquer sur la page d'accueil.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je ferai ce rapport. Je vais cliquer sur la page d'accueil.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837EA80> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.22 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Je ferai ce rapport. Je vais cliquer sur la page d'accueil.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_15.mp3\n",
      "[Debug] Segment 17 final translation: Je peux également cliquer sur la carte de données de la page d'accueil.\n",
      "[Debug] Generated SSML for segment 17: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je peux également cliquer sur la carte de données de la page d'accueil.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je peux également cliquer sur la carte de données de la page d'accueil.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_16.mp3\n",
      "[Debug] Segment 18 final translation: Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.\n",
      "[Debug] Generated SSML for segment 18: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837D9A0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.76 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837E3C0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 2.17 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase using SSML: 'Et c'est pour montrer comment nous sommes revenus au formulaire de données où nous avons entré les données et cela ne nous amène pas à la session photo et nous pouvons reprendre la session d'où nous sommes partis.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_17.mp3\n",
      "[Debug] Segment 19 final translation: Dans cette page de destination, nous pouvons voir 7 icônes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.\n",
      "[Debug] Generated SSML for segment 19: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans cette page de destination, nous pouvons voir 7 icônes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans cette page de destination, nous pouvons voir 7 icônes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_18.mp3\n",
      "[Debug] Segment 20 final translation: Nous allons désactiver la modélisation stratégique et nous allons activer une nouvelle modélisation financière de carte dans cette démo.\n",
      "[Debug] Generated SSML for segment 20: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous allons désactiver la modélisation stratégique et nous allons activer une nouvelle modélisation financière de carte dans cette démo.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous allons désactiver la modélisation stratégique et nous allons activer une nouvelle modélisation financière de carte dans cette démo.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_19.mp3\n",
      "[Debug] Segment 21 final translation: Pour configurer le flux de navigation, un utilisateur doit avoir un accès d'administration de service.\n",
      "[Debug] Generated SSML for segment 21: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Pour configurer le flux de navigation, un utilisateur doit avoir un accès d'administration de service.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Pour configurer le flux de navigation, un utilisateur doit avoir un accès d'administration de service.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_20.mp3\n",
      "[Debug] Segment 22 final translation: Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.\n",
      "[Debug] Generated SSML for segment 22: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_21.mp3\n",
      "[Debug] Segment 23 final translation: Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.\n",
      "[Debug] Generated SSML for segment 23: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_22.mp3\n",
      "[Debug] Segment 24 final translation: Vous pouvez sélectionner le flux de navigation et cliquer sur l'icône de l'engrenage pour voir diverses options.\n",
      "[Debug] Generated SSML for segment 24: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Vous pouvez sélectionner le flux de navigation et cliquer sur l'icône de l'engrenage pour voir diverses options.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Vous pouvez sélectionner le flux de navigation et cliquer sur l'icône de l'engrenage pour voir diverses options.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_23.mp3\n",
      "[Debug] Segment 25 final translation: Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.\n",
      "[Debug] Generated SSML for segment 25: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_24.mp3\n",
      "[Debug] Segment 26 final translation: Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.\n",
      "[Debug] Generated SSML for segment 26: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_25.mp3\n",
      "[Debug] Segment 27 final translation: Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.\n",
      "[Debug] Generated SSML for segment 27: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_26.mp3\n",
      "[Debug] Segment 28 final translation: Cliquez sur le nom du flux de navigation pour commencer à apporter des modifications.\n",
      "[Debug] Generated SSML for segment 28: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur le nom du flux de navigation pour commencer à apporter des modifications.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur le nom du flux de navigation pour commencer à apporter des modifications.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_27.mp3\n",
      "[Debug] Segment 29 final translation: Chaque élément est désigné un type, un cluster ou une carte, un état de visibilité, désactivé, activé.\n",
      "[Debug] Generated SSML for segment 29: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Chaque élément est désigné un type, un cluster ou une carte, un état de visibilité, désactivé, activé.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Chaque élément est désigné un type, un cluster ou une carte, un état de visibilité, désactivé, activé.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_28.mp3\n",
      "[Debug] Segment 30 final translation: Option pour réorganiser et supprimer.\n",
      "[Debug] Generated SSML for segment 30: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Option pour réorganiser et supprimer.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Option pour réorganiser et supprimer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_29.mp3\n",
      "[Debug] Segment 31 final translation: Pour cette démo, nous allons activer le cluster financier qui est désactivé ici en haut et nous allons désactiver la modélisation stratégique.\n",
      "[Debug] Generated SSML for segment 31: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Pour cette démo, nous allons activer le cluster financier qui est désactivé ici en haut et nous allons désactiver la modélisation stratégique.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Pour cette démo, nous allons activer le cluster financier qui est désactivé ici en haut et nous allons désactiver la modélisation stratégique.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_30.mp3\n",
      "[Debug] Segment 32 final translation: Dans le cluster financier, nous allons réorganiser en déplaçant les revenus en haut.\n",
      "[Debug] Generated SSML for segment 32: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans le cluster financier, nous allons réorganiser en déplaçant les revenus en haut.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans le cluster financier, nous allons réorganiser en déplaçant les revenus en haut.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_31.mp3\n",
      "[Debug] Segment 33 final translation: J'ai également les options pour créer un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.\n",
      "[Debug] Generated SSML for segment 33: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">J'ai également les options pour créer un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'J'ai également les options pour créer un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_32.mp3\n",
      "[Debug] Segment 34 final translation: J'ai également les options pour attribuer des autorisations aux groupes d'utilisateurs ou des rôles attribués à ce flux de navigation particulier.\n",
      "[Debug] Generated SSML for segment 34: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">J'ai également les options pour attribuer des autorisations aux groupes d'utilisateurs ou des rôles attribués à ce flux de navigation particulier.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'J'ai également les options pour attribuer des autorisations aux groupes d'utilisateurs ou des rôles attribués à ce flux de navigation particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_33.mp3\n",
      "[Debug] Segment 35 final translation: Et je vais économiser et fermer ce flux de navigation.\n",
      "[Debug] Generated SSML for segment 35: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Et je vais économiser et fermer ce flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Et je vais économiser et fermer ce flux de navigation.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Et je vais économiser et fermer ce flux de navigation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837DE20> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.97 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Et je vais économiser et fermer ce flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_34.mp3\n",
      "[Debug] Segment 36 final translation: Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.\n",
      "[Debug] Generated SSML for segment 36: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_35.mp3\n",
      "[Debug] Segment 37 final translation: En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la modélisation stratégique et que nous ne voyons pas encore le cluster de modélisation financière.\n",
      "[Debug] Generated SSML for segment 37: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la modélisation stratégique et que nous ne voyons pas encore le cluster de modélisation financière.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la modélisation stratégique et que nous ne voyons pas encore le cluster de modélisation financière.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_36.mp3\n",
      "[Debug] Segment 38 final translation: Pour actualiser le flux de navigation, ouvrez l'icône du sélecteur de flux de navigation et cliquez sur Actualiser.\n",
      "[Debug] Generated SSML for segment 38: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Pour actualiser le flux de navigation, ouvrez l'icône du sélecteur de flux de navigation et cliquez sur Actualiser.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Pour actualiser le flux de navigation, ouvrez l'icône du sélecteur de flux de navigation et cliquez sur Actualiser.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_37.mp3\n",
      "[Debug] Segment 39 final translation: La page recharge avec le cluster financier et nous ne voyons plus le cluster de modélisation stratégique.\n",
      "[Debug] Generated SSML for segment 39: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">La page recharge avec le cluster financier et nous ne voyons plus le cluster de modélisation stratégique.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'La page recharge avec le cluster financier et nous ne voyons plus le cluster de modélisation stratégique.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_38.mp3\n",
      "[Debug] Segment 40 final translation: Cliquer sur le cluster financier montre les revenus au premier tel que nous avons réorganisé.\n",
      "[Debug] Generated SSML for segment 40: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquer sur le cluster financier montre les revenus au premier tel que nous avons réorganisé.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquer sur le cluster financier montre les revenus au premier tel que nous avons réorganisé.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_39.mp3\n",
      "[Debug] Segment 41 final translation: Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.\n",
      "[Debug] Generated SSML for segment 41: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_40.mp3\n",
      "[Debug] Segment 42 final translation: Ici, il s'agit d'une données de travail pour votre FY23.\n",
      "[Debug] Generated SSML for segment 42: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Ici, il s'agit d'une données de travail pour votre FY23.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Ici, il s'agit d'une données de travail pour votre FY23.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_41.mp3\n",
      "[Debug] Segment 43 final translation: Sur planant sur ces icônes nous jettera des informations détaillées dans ce tableau de bord particulier.\n",
      "[Debug] Generated SSML for segment 43: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Sur planant sur ces icônes nous jettera des informations détaillées dans ce tableau de bord particulier.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Sur planant sur ces icônes nous jettera des informations détaillées dans ce tableau de bord particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_42.mp3\n",
      "[Debug] Segment 44 final translation: Nous pouvons obtenir plus de détails en les survolant.\n",
      "[Debug] Generated SSML for segment 44: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous pouvons obtenir plus de détails en les survolant.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous pouvons obtenir plus de détails en les survolant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_43.mp3\n",
      "[Debug] Segment 45 final translation: Nous pouvons également naviguer vers différents onglets et voir plus d'informations.\n",
      "[Debug] Generated SSML for segment 45: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous pouvons également naviguer vers différents onglets et voir plus d'informations.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous pouvons également naviguer vers différents onglets et voir plus d'informations.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_44.mp3\n",
      "[Debug] Segment 46 final translation: Nous avons également des onglets en bas et en haut.\n",
      "[Debug] Generated SSML for segment 46: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous avons également des onglets en bas et en haut.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous avons également des onglets en bas et en haut.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_45.mp3\n",
      "[Debug] Segment 47 final translation: Nous pouvons voir toutes les dernières tendances pour l'année particulière et nous pouvons survoler les plus d'informations.\n",
      "[Debug] Generated SSML for segment 47: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous pouvons voir toutes les dernières tendances pour l'année particulière et nous pouvons survoler les plus d'informations.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous pouvons voir toutes les dernières tendances pour l'année particulière et nous pouvons survoler les plus d'informations.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons voir toutes les dernières tendances pour l'année particulière et nous pouvons survoler les plus d'informations.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837EDE0> [Une connexion existante a dû être fermée par l’hôte distant]\n",
      "[Debug] Retrying in 1.73 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Nous pouvons voir toutes les dernières tendances pour l'année particulière et nous pouvons survoler les plus d'informations.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_46.mp3\n",
      "[Debug] Segment 48 final translation: Dans cette démo, nous avons exploré notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux rôles.\n",
      "[Debug] Generated SSML for segment 48: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans cette démo, nous avons exploré notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux rôles.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans cette démo, nous avons exploré notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux rôles.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_47.mp3\n",
      "✅ Translated audio saved to: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.wav\n",
      "📝 Debug log saved to: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\translation_debug_log.txt\n",
      "Merging audio and video...\n",
      "Moviepy - Building video 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4\n",
      "Process completed! Output video: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "import concurrent.futures\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"✅ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.2_Flux de navigation_Avr_08_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# We rely solely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Silence Duration:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"----------------------------------------------------------------\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # default in ms\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    print(\"Parsed review file overrides:\")\n",
    "    for idx, override in enumerate(segments_overrides, 1):\n",
    "        print(f\"  Segment {idx} final translation: {override['final_translation']}\")\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== Inline Tag Parsing and SSML Generation ==============\n",
    "def parse_segment_with_tags(text: str):\n",
    "    \"\"\"\n",
    "    Parse a text segment containing inline tags.\n",
    "    Supported custom tags:\n",
    "      - <speed value=\"120%\"> ... </speed> or <speed value=\"120%\"/> (both accepted)\n",
    "      - <pause duration=\"300ms\"/> (self-closing)\n",
    "    Returns a list of tuples (text, options) where options is a dict.\n",
    "    \"\"\"\n",
    "    tag_pattern = re.compile(r\"\"\"\n",
    "        (?P<pre_text>.*?)                              # text before the tag\n",
    "        (?:\n",
    "            <speed\\s+value=[\"'](?P<speed>[\\d.+%-]+)[\"']>  # speed tag opening\n",
    "            (?P<speed_text>.+?)(?:</speed>|<speed\\s*/>)    # speed tag content and closing\n",
    "          |\n",
    "            <pause\\s+duration=[\"'](?P<pause>[\\d.]+ms)[\"']\\s*/>  # self-closing pause tag\n",
    "        )\n",
    "    \"\"\", re.VERBOSE | re.DOTALL)\n",
    "    \n",
    "    results = []\n",
    "    pos = 0\n",
    "    while pos < len(text):\n",
    "        match = tag_pattern.search(text, pos)\n",
    "        if not match:\n",
    "            remaining = text[pos:]\n",
    "            if remaining:\n",
    "                results.append((remaining, {}))\n",
    "            break\n",
    "        if match.group(\"pre_text\"):\n",
    "            results.append((match.group(\"pre_text\"), {}))\n",
    "        if match.group(\"speed\"):\n",
    "            results.append((match.group(\"speed_text\"), {\"speed\": match.group(\"speed\").strip()}))\n",
    "        elif match.group(\"pause\"):\n",
    "            results.append((\"\", {\"pause\": match.group(\"pause\").strip()}))\n",
    "        pos = match.end()\n",
    "    return results\n",
    "\n",
    "def generate_ssml_for_phrase(text: str, default_speed: str, default_pause: int) -> str:\n",
    "    \"\"\"\n",
    "    Generates an SSML string from a text segment that may include inline tags.\n",
    "    Replaces custom tags with valid SSML instructions and wraps the result in <speak> tags.\n",
    "    An XML declaration is also prepended to ensure proper SSML processing.\n",
    "    \"\"\"\n",
    "    segments = parse_segment_with_tags(text)\n",
    "    ssml_parts = []\n",
    "    for seg_text, options in segments:\n",
    "        if \"pause\" in options:\n",
    "            ssml_parts.append(f'<break time=\"{options[\"pause\"]}\"/>')\n",
    "        elif \"speed\" in options:\n",
    "            spd = options[\"speed\"]\n",
    "            ssml_parts.append(f'<prosody rate=\"{spd}\">{seg_text}</prosody>')\n",
    "        else:\n",
    "            ssml_parts.append(f'<prosody rate=\"{default_speed}\">{seg_text}</prosody>')\n",
    "    full_ssml = \"\".join(ssml_parts) + f'<break time=\"{default_pause}ms\"/>'\n",
    "    # Prepend XML declaration and wrap in speak element.\n",
    "    return f'<?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\">{full_ssml}</speak>'\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", ssml: str = None, max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    If an SSML string is provided, it is passed as the text parameter.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                if ssml is not None:\n",
    "                    communicate = edge_tts.Communicate(text=ssml, voice=voice)\n",
    "                else:\n",
    "                    communicate = edge_tts.Communicate(text=phrase, voice=voice, rate=rate)\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase using {'SSML' if ssml else 'plain text'}: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", ssml: str = None):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate, ssml)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", ssml: str = None):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate, ssml)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_file, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        seg_voice_speed = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        seg_silence_duration = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "\n",
    "        print(f\"[Debug] Segment {idx+1} final translation: {final_translation}\")\n",
    "        # Generate SSML including inline tags.\n",
    "        ssml = generate_ssml_for_phrase(final_translation, default_speed=seg_voice_speed, default_pause=seg_silence_duration)\n",
    "        print(f\"[Debug] Generated SSML for segment {idx+1}: {ssml}\")\n",
    "        temp_segment_path = os.path.join(tempfile.gettempdir(), f\"temp_segment_{idx}.mp3\")\n",
    "        try:\n",
    "            await synthesize_phrase_edge_hybrid(final_translation, temp_segment_path, voice=\"fr-FR-DeniseNeural\", ssml=ssml)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Synthesis failed for segment {idx+1}: {e}. Skipping this segment.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            segment_audio = AudioSegment.from_mp3(temp_segment_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Unable to load audio from {temp_segment_path}: {e}. Skipping this segment.\")\n",
    "            if os.path.exists(temp_segment_path):\n",
    "                os.remove(temp_segment_path)\n",
    "            continue\n",
    "\n",
    "        segment_audio = adjust_audio_duration(segment_audio, target_duration)\n",
    "        combined_audio += AudioSegment.silent(duration=int(group_start * 1000) - len(combined_audio))\n",
    "        combined_audio += segment_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed (segment):** {seg_voice_speed}\\n\"\n",
    "            f\"**Silence Duration (segment):** {seg_silence_duration} ms\\n\"\n",
    "            f\"**Generated SSML:** {ssml}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "        if os.path.exists(temp_segment_path):\n",
    "            os.remove(temp_segment_path)\n",
    "\n",
    "    with open(debug_log_file, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"✅ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"📝 Debug log saved to: {debug_log_file}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd834a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
