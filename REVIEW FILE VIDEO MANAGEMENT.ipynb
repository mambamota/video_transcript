{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356e59f7",
   "metadata": {},
   "source": [
    "ATO MIASA MI COPIER REVIEW FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5191b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated translation review file has been saved as to translate/translation_review_updated.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_segments(content):\n",
    "    \"\"\"\n",
    "    Parse the content into segments based on the segment header.\n",
    "    Returns a dictionary with segment numbers (as integers) as keys and the full segment text as values.\n",
    "    \"\"\"\n",
    "    segments = {}\n",
    "    # The pattern finds segments that start with \"Segment <number>\" until the next segment or end of file.\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, content, re.DOTALL | re.MULTILINE)\n",
    "    for full_seg, seg_no in matches:\n",
    "        segments[int(seg_no)] = full_seg\n",
    "    return segments\n",
    "\n",
    "def get_field_text(segment_text, field_name):\n",
    "    \"\"\"\n",
    "    Extract the text following a given field marker (e.g., **Original:**, **Auto Translated:**, **Final Translation:**)\n",
    "    from the segment text. Returns the text stripped of leading/trailing spaces.\n",
    "    \"\"\"\n",
    "    # Using a regex pattern that stops at the end of the line.\n",
    "    pattern = r\"\\*\\*\" + re.escape(field_name) + r\":\\*\\*\\s*(.*)\"\n",
    "    match = re.search(pattern, segment_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def update_segment_fields(review_segment, updated_segment, fields):\n",
    "    \"\"\"\n",
    "    Replace the specified fields in the review_segment with the ones extracted\n",
    "    from the updated_segment.\n",
    "    \n",
    "    fields should be a list of field names such as [\"Original\", \"Auto Translated\", \"Final Translation\"].\n",
    "    \"\"\"\n",
    "    updated_seg = review_segment\n",
    "    for field in fields:\n",
    "        new_text = get_field_text(updated_segment, field)\n",
    "        if new_text is not None:\n",
    "            # Replace the entire line for the field in the review segment.\n",
    "            # The regex captures the marker and then replaces what follows.\n",
    "            pattern = r\"(\\*\\*\" + re.escape(field) + r\":\\*\\*\\s*).*$\"\n",
    "            replacement = r\"\\1\" + new_text\n",
    "            updated_seg = re.sub(pattern, replacement, updated_seg, flags=re.MULTILINE)\n",
    "    return updated_seg\n",
    "\n",
    "def update_translation_review(review_content, updated_segments, fields):\n",
    "    \"\"\"\n",
    "    For each segment in review_content, replace the specified fields with those from the updated segments.\n",
    "    \"\"\"\n",
    "    # Find the segments in review content using the same segmentation parser.\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, review_content, re.DOTALL | re.MULTILINE)\n",
    "\n",
    "    updated_content = review_content  # Work on a copy to allow replacements.\n",
    "\n",
    "    for full_seg, seg_no in matches:\n",
    "        seg_no_int = int(seg_no)\n",
    "        if seg_no_int in updated_segments:\n",
    "            # Replace the fields (Original, Auto Translated, Final Translation) based on updated segments.\n",
    "            new_seg = update_segment_fields(full_seg, updated_segments[seg_no_int],\n",
    "                                            fields)\n",
    "            # Replace the old segment in the overall content with the updated segment.\n",
    "            updated_content = updated_content.replace(full_seg, new_seg)\n",
    "    return updated_content\n",
    "\n",
    "def main():\n",
    "    # Define the file paths (adjust these paths as needed)\n",
    "    updated_file_path = \"to translate/translation_review_modifs ad 05.08 (2).txt\"\n",
    "    review_file_path = \"to translate/translation_review.txt\"\n",
    "    \n",
    "    # Read the updated file content\n",
    "    with open(updated_file_path, encoding='utf-8') as f:\n",
    "        updated_content = f.read()\n",
    "    \n",
    "    # Read the review file content\n",
    "    with open(review_file_path, encoding='utf-8') as f:\n",
    "        review_content = f.read()\n",
    "    \n",
    "    # Parse segments from the updated file content\n",
    "    updated_segments = parse_segments(updated_content)\n",
    "    \n",
    "    # Define the list of fields to update.\n",
    "    fields_to_update = [\"Original\", \"Auto Translated\", \"Final Translation\"]\n",
    "    \n",
    "    # Replace the fields in the review content using the updated segments\n",
    "    new_review_content = update_translation_review(review_content, updated_segments,\n",
    "                                                   fields_to_update)\n",
    "    \n",
    "    # Write the updated content to a new file (or overwrite the original file if desired)\n",
    "    output_file_path = \"to translate/translation_review_updated.txt\"\n",
    "    with open(output_file_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(new_review_content)\n",
    "    \n",
    "    print(f\"Updated translation review file has been saved as {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9cab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated translation review file has been saved as to translate/translation_review_updated.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_segments(content):\n",
    "    \"\"\"\n",
    "    Parse the content into segments using a regular expression that captures each segment.\n",
    "    Returns a dictionary with segment numbers (as integers) as keys and the full segment text as values.\n",
    "    \"\"\"\n",
    "    segments = {}\n",
    "    # This pattern finds segments that start with \"Segment <number>\" and goes until the next segment or end of file.\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, content, re.DOTALL | re.MULTILINE)\n",
    "    for full_seg, seg_no in matches:\n",
    "        segments[int(seg_no)] = full_seg\n",
    "    return segments\n",
    "\n",
    "def get_final_translation(segment_text):\n",
    "    \"\"\"\n",
    "    Extracts the final translation text from a segment.\n",
    "    It looks for the pattern **Final Translation:** followed by any text.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\*\\*Final Translation:\\*\\*\\s*(.*)\", segment_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def update_translation_review(review_content, updated_segments):\n",
    "    \"\"\"\n",
    "    For each segment in the review file's content, replaces the **Final Translation:** text\n",
    "    with the one from the updated segments.\n",
    "    \"\"\"\n",
    "    # Parse the review content into segments using the same parser\n",
    "    review_segments = {}\n",
    "    pattern = r\"(Segment\\s+(\\d+).*?)(?=^Segment\\s+\\d+|\\Z)\"\n",
    "    matches = re.findall(pattern, review_content, re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    updated_content = review_content  # Work on a copy of the content\n",
    "\n",
    "    for full_seg, seg_no in matches:\n",
    "        seg_no_int = int(seg_no)\n",
    "        if seg_no_int in updated_segments:\n",
    "            updated_final = get_final_translation(updated_segments[seg_no_int])\n",
    "            if updated_final is not None:\n",
    "                # Replace the **Final Translation:** line in this segment with the new translation.\n",
    "                # This regex pattern matches the '**Final Translation:**' line and captures the prefix.\n",
    "                new_seg = re.sub(\n",
    "                    r\"(\\*\\*Final Translation:\\*\\*\\s*).*\",  # match the line starting with **Final Translation:**\n",
    "                    r\"\\1\" + updated_final,  # replace with the captured prefix plus the updated text\n",
    "                    full_seg\n",
    "                )\n",
    "                # Replace the old segment in the content with the updated segment.\n",
    "                updated_content = updated_content.replace(full_seg, new_seg)\n",
    "\n",
    "    return updated_content\n",
    "\n",
    "def main():\n",
    "    # Define file paths (make sure these paths are correct)\n",
    "    updated_file_path = \"to translate/translation_review_farany.txt\"\n",
    "    review_file_path = \"to translate/translation_review.txt\"\n",
    "    \n",
    "    # Read updated file content\n",
    "    with open(updated_file_path, encoding='utf-8') as f:\n",
    "        updated_content = f.read()\n",
    "    \n",
    "    # Read review file content\n",
    "    with open(review_file_path, encoding='utf-8') as f:\n",
    "        review_content = f.read()\n",
    "    \n",
    "    # Parse segments from the updated content\n",
    "    updated_segments = parse_segments(updated_content)\n",
    "    \n",
    "    # Replace the **Final Translation:** values in the review content\n",
    "    new_review_content = update_translation_review(review_content, updated_segments)\n",
    "    \n",
    "    # Write the updated content to a new file (or overwrite the original file if desired)\n",
    "    output_file_path = \"to translate/translation_review_updated.txt\"\n",
    "    with open(output_file_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(new_review_content)\n",
    "    \n",
    "    print(f\"Updated translation review file has been saved as {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61940deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1921' coro=<async_main() done, defined at C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py:401> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py\", line 419, in <module>\n",
      "    asyncio.run(async_main())\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py\", line 407, in async_main\n",
      "    language, segments = transcribe(audio_path)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\061181CA8\\AppData\\Local\\Temp\\ipykernel_16532\\2572477427.py\", line 70, in transcribe\n",
      "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py\", line 900, in transcribe\n",
      "    ) = self.detect_language(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py\", line 1777, in detect_language\n",
      "    encoder_output = self.encode(\n",
      "                     ^^^^^^^^^^^^\n",
      "  File \"c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py\", line 1358, in encode\n",
      "    return self.model.encode(features, to_cpu=to_cpu)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 419\u001b[39m\n\u001b[32m    416\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m persistent_connector.close()\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\nest_asyncio.py:133\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m curr_task = curr_tasks.pop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[43mhandle\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py:84\u001b[39m, in \u001b[36mHandle._run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 407\u001b[39m, in \u001b[36masync_main\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    405\u001b[39m audio_path = extract_audio()\n\u001b[32m    406\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTranscribing audio...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m language, segments = \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating English subtitles...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    409\u001b[39m generate_subtitle_file(segments, subtitle_file_en)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mtranscribe\u001b[39m\u001b[34m(audio_path)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDetected language: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m transcript_segments = []\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtranscript_segments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstart\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m language, transcript_segments\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py:1148\u001b[39m, in \u001b[36mWhisperModel.generate_segments\u001b[39m\u001b[34m(self, features, tokenizer, options, log_progress, encoder_output)\u001b[39m\n\u001b[32m   1145\u001b[39m previous_tokens = all_tokens[prompt_reset_since:]\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seek > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m encoder_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1148\u001b[39m     encoder_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m options.multilingual:\n\u001b[32m   1151\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.model.detect_language(encoder_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\faster_whisper\\transcribe.py:1358\u001b[39m, in \u001b[36mWhisperModel.encode\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m   1355\u001b[39m     features = np.expand_dims(features, \u001b[32m0\u001b[39m)\n\u001b[32m   1356\u001b[39m features = get_ctranslate2_storage(features)\n\u001b[32m-> \u001b[39m\u001b[32m1358\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "from aiohttp import ClientConnectorError\n",
    "import random\n",
    "import concurrent.futures\n",
    "import pyttsx3\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.2_Flux de navigation_Avr_08_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Choose which TTS engine to use by default:\n",
    "# If USE_PYTTSX3 is True then offline pyttsx3 will be used,\n",
    "# otherwise robust Edge TTS (cloud-based) is used.\n",
    "USE_PYTTSX3 = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"---\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r\"[.!?]$\", word):\n",
    "            if (i == len(words) - 1) or (words[i + 1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Robust Edge TTS and Offline pyttsx3 Fallback ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Uses exponential backoff with jitter.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(connector=connector, timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate,\n",
    "                    connector=connector\n",
    "                )\n",
    "                await communicate.save(output_path)\n",
    "                return\n",
    "        except (ClientConnectorError, ConnectionResetError) as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Connection error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "def synthesize_phrase_pyttsx3(phrase: str, output_path: str, voice: str = None, rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Synthesize speech using offline pyttsx3.\n",
    "    Saves the output as a WAV file.\n",
    "    \"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    if voice is not None:\n",
    "        engine.setProperty(\"voice\", voice)\n",
    "    base_rate = engine.getProperty(\"rate\")\n",
    "    try:\n",
    "        modifier = int(rate.strip(\" %+\"))\n",
    "    except Exception:\n",
    "        modifier = 0\n",
    "    new_rate = base_rate + modifier\n",
    "    engine.setProperty(\"rate\", new_rate)\n",
    "    # Save to file (WAV format)\n",
    "    engine.save_to_file(phrase, output_path)\n",
    "    engine.runAndWait()\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Wrapper function to choose the TTS engine.\n",
    "    If USE_PYTTSX3 is True, use the offline pyttsx3 engine (runs in executor);\n",
    "    otherwise, use robust Edge TTS.\n",
    "    \"\"\"\n",
    "    if USE_PYTTSX3:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        with concurrent.futures.ThreadPoolExecutor() as pool:\n",
    "            await loop.run_in_executor(pool, synthesize_phrase_pyttsx3, phrase, output_path, voice, rate)\n",
    "    else:\n",
    "        await robust_synthesize_phrase(phrase, output_path, connector, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, connector, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Persistent Connector Creation ==============\n",
    "def create_persistent_connector():\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context, limit=10)\n",
    "    return connector\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path, persistent_connector):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(\n",
    "                    phrase, temp_path, connector=persistent_connector, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            # Now try to load the file; if decoding fails, fallback to pyttsx3\n",
    "            try:\n",
    "                audio = AudioSegment.from_mp3(temp_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Decoding failed for file {temp_path}: {e}. Falling back to offline pyttsx3.\")\n",
    "                fallback_path = temp_path.replace(\".mp3\", \".wav\")\n",
    "                try:\n",
    "                    synthesize_phrase_pyttsx3(phrase, fallback_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "                    audio = AudioSegment.from_file(fallback_path, format=\"wav\")\n",
    "                    os.remove(fallback_path)\n",
    "                except Exception as ex:\n",
    "                    print(f\"[Warning] Offline fallback failed for phrase '{phrase}': {ex}. Skipping this phrase.\")\n",
    "                    continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    persistent_connector = create_persistent_connector()\n",
    "    try:\n",
    "        print(\"Extracting audio...\")\n",
    "        audio_path = extract_audio()\n",
    "        print(\"Transcribing audio...\")\n",
    "        language, segments = transcribe(audio_path)\n",
    "        print(\"Generating English subtitles...\")\n",
    "        generate_subtitle_file(segments, subtitle_file_en)\n",
    "        print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "        await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file, persistent_connector)\n",
    "        print(\"Merging audio and video...\")\n",
    "        merge_audio_video()\n",
    "        print(f\"Process completed! Output video: {output_video}\")\n",
    "    finally:\n",
    "        await persistent_connector.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import random\n",
    "import concurrent.futures\n",
    "import pyttsx3\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version, we use only offline pyttsx3.\n",
    "USE_PYTTSX3 = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"---\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r\"[.!?]$\", word):\n",
    "            if (i == len(words) - 1) or (words[i + 1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Offline pyttsx3 Only ==============\n",
    "def synthesize_phrase_pyttsx3(phrase: str, output_path: str, voice: str = None, rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Synthesize speech using offline pyttsx3.\n",
    "    Saves the output as a WAV file.\n",
    "    \"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    # Optionally set the voice if available on your system.\n",
    "    if voice is not None:\n",
    "        engine.setProperty(\"voice\", voice)\n",
    "    base_rate = engine.getProperty(\"rate\")\n",
    "    try:\n",
    "        modifier = int(rate.strip(\" %+\"))\n",
    "    except Exception:\n",
    "        modifier = 0\n",
    "    new_rate = base_rate + modifier\n",
    "    engine.setProperty(\"rate\", new_rate)\n",
    "    engine.save_to_file(phrase, output_path)\n",
    "    engine.runAndWait()\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    \"\"\"\n",
    "    Asynchronous wrapper for pyttsx3 synthesis.\n",
    "    Runs the blocking pyttsx3 call inside an executor.\n",
    "    \"\"\"\n",
    "    loop = asyncio.get_event_loop()\n",
    "    with concurrent.futures.ThreadPoolExecutor() as pool:\n",
    "        await loop.run_in_executor(pool, synthesize_phrase_pyttsx3, phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.wav\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            try:\n",
    "                audio = AudioSegment.from_file(temp_path, format=\"wav\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Unable to load audio from {temp_path}: {e}. Skipping this phrase.\")\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "                continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94202637",
   "metadata": {},
   "source": [
    "testa hanova voix -ATO NDRAY MIASA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e5ec9",
   "metadata": {},
   "source": [
    "to translate/4.2.2_Flux de navigation_Avr_08_Latest.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n",
      "Detected language: en\n",
      "Generating English subtitles...\n",
      "Generating French audio with synchronization and manual overrides...\n",
      "‚úÖ Review file created at: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\translation_review.txt  (split into 28 segments)\n",
      "Parsed review overrides:\n",
      "  Segment 1: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 2: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 3: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 4: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 5: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 6: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 7: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 8: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 9: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 10: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 11: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 12: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 13: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 14: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 15: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 16: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 17: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 18: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 19: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 20: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 21: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 22: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 23: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 24: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 25: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "  Segment 26: pre=0.0ms, post=100.0ms, speed=-10%\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous allons voir les configurations de l'application EPM.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous verrons comment cr√©er une r√®gle m√©tier ou une formule de membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous verrons comment la s√©curit√© fonctionne dans l'application EPM et nous couvrirons comment cr√©er et configurer des formulaires de donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La s√©curit√© dans EPM comprendra la s√©curit√© dimensionnelle, la s√©curit√© des artefacts, la s√©curit√© par t√¢ches ou le flux de travail, la s√©curit√© des r√®gles m√©tier et la s√©curit√© des donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_0_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: '√Ä partir de la page d'accueil, cliquez sur le navigateur et acc√©dez aux dimensions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Maintenant, je vais s√©lectionner le cube et pour la dimension du compte, je vais rechercher le membre pour lequel je souhaite mettre √† jour la formule du membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que le membre est mis en √©vidence, nous pouvons modifier les propri√©t√©s de formule de membres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons s√©lectionner le cube pour voir la formule du membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La formule des membres est utilis√©e n'importe o√π dans l'application.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ici, le mat√©riel OFS sera divis√© par le volume OFS.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que nous avons la formule des membres, nous pouvons la valider et nous pouvons voir qu'elle est valid√©e avec succ√®s.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que nous avons la formule des membres, nous pouvons la valider et nous pouvons voir qu'elle est valid√©e avec succ√®s.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B2F0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.18 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que nous avons la formule des membres, nous pouvons la valider et nous pouvons voir qu'elle est valid√©e avec succ√®s.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons enregistrer, r√©initialiser ou annuler.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais annuler dans ce cas.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je vais annuler dans ce cas.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B800> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.23 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je vais annuler dans ce cas.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Je vais annuler dans ce cas.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BA40> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.19 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Je vais annuler dans ce cas.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_1_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour voir une r√®gle m√©tier, cliquer sur l'ic√¥ne Navigateur et cliquer sur R√®gles.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ceci ouvrira la fen√™tre de Calculation Manager qui est √©galement appel√© r√®gles m√©tier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous pouvez voir l'application EPM Cloud et l'expansion nous montrera l'EPBCS et nous allons cr√©er la r√®gle sous OEP FS.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Vous pouvez voir l'application EPM Cloud et l'expansion nous montrera l'EPBCS et nous allons cr√©er la r√®gle sous OEP FS.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AF90> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.50 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Vous pouvez voir l'application EPM Cloud et l'expansion nous montrera l'EPBCS et nous allons cr√©er la r√®gle sous OEP FS.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Permettez-moi de s√©lectionner OEP FS et sous des actions, je peux soit cr√©er une nouvelle r√®gle, script, formule, je peux importer, je peux voir les propri√©t√©s.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans cette d√©mo, je vais cr√©er une r√®gle.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comme j'ai s√©lectionn√© le cube et l'application, toutes ces informations sont pr√©popul√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais s√©lectionner R√®gles en cr√©ant une formule de membre avec ce nom et je vais cliquer sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Il dira que la r√®gle a √©t√© cr√©√© et si nous voulons apporter des modifications.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais dire oui et une fois que nous avons cr√©√©, ceci est la premi√®re page que nous allons voir et surtout les administrateurs utilisent la vue de concepteur et il y a aussi une vue de script.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais s√©lectionner la vue du script.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons toutes les dimensions requises dont nous avons besoin ici et je vais actuellement copier les donn√©es de FY24 pour le sc√©nario plan, working de la contrepartie de l'allocation d'entit√© au plan FY23, working, contrepartie de l'allocation d'entit√©.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous avons toutes les dimensions requises dont nous avons besoin ici et je vais actuellement copier les donn√©es de FY24 pour le sc√©nario plan, working de la contrepartie de l'allocation d'entit√© au plan FY23, working, contrepartie de l'allocation d'entit√©.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B800> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.91 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous avons toutes les dimensions requises dont nous avons besoin ici et je vais actuellement copier les donn√©es de FY24 pour le sc√©nario plan, working de la contrepartie de l'allocation d'entit√© au plan FY23, working, contrepartie de l'allocation d'entit√©.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_10.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Il s'agit d'une r√®gle m√©tier de base.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Il s'agit d'une r√®gle m√©tier de base.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B0B0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.39 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Il s'agit d'une r√®gle m√©tier de base.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_11.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons avoir des r√®gles m√©tier pour des sc√©narios complexes et toutes ces r√®gles m√©tiers s'ex√©cutent en quelques secondes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_12.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais donc le valider et le sauver.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_2_13.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que je l'ai enregistr√©, je peux la d√©ployer.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que je l'ai enregistr√©, je peux la d√©ployer.'. Exception: No audio was received. Please verify that your parameters are correct.\n",
      "[Debug] Retrying in 1.34 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que je l'ai enregistr√©, je peux la d√©ployer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_3_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Maintenant, je vais ouvrir un formulaire de donn√©es pour montrer comment fonctionne cette r√®gle m√©tier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_4_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai d√©j√† un formulaire ici et comme vous pouvez le voir, c'est FY23-24 et j'ai des donn√©es dans FY24 pour tous les trimestres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_5_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour FY23, je n'ai pas de donn√©es pour cette intersection.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_5_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour copier des donn√©es, nous devons simplement ex√©cuter la r√®gle m√©tier et il copiera les donn√©es de FY24 √† FY23 une fois que j'ai ex√©cut√© la r√®gle.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais aller √† ma r√®gle et cliquer sur ce bouton, lance la r√®gle m√©tier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais la lancer.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je vais la lancer.'. Exception: No audio was received. Please verify that your parameters are correct.\n",
      "[Debug] Retrying in 1.31 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je vais la lancer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons faire lancer cette r√®gle m√©tier √† partir d'ici ou nous pouvons joindre cette r√®gle m√©tier √† tout autre art√©fact comme les formulaires de donn√©es ou tableau de bord.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur Actualiser.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous voyez comment les donn√©es sont copi√©es et elles sont remplies dans ce formulaire.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Vous voyez comment les donn√©es sont copi√©es et elles sont remplies dans ce formulaire.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B5C0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.08 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Vous voyez comment les donn√©es sont copi√©es et elles sont remplies dans ce formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'L'ex√©cuter √† partir du calculation manager, je peux joindre la r√®gle m√©tier directement au formulaire et v√©rifier les options comme ex√©cuter √† l'enregistrement, ex√©cuter au chargement.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cela nous aide donc √† ex√©cuter les r√®gles une fois que nous avons cliqu√© sur le bouton Enregistrer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement c√©duler la r√®gle m√©tier dans nos automations et g√©rer dans le cadre des travaux quotidiens d'automatisation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La s√©curit√© peut √™tre appliqu√©e aux r√®gles m√©tiers qui permettront de restreindre les utilisateurs et ceci peut √™tre fait en utilisant la s√©curit√© des r√®gles m√©tier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_6_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour en savoir plus sur la s√©curit√©, cliquez sur Outils et acc√©dez au contr√¥le d'acc√®s o√π nous pouvons cr√©er des groupes pour g√©rer les utilisateurs au sein de ces groupes et nous avons des groupes d√©finis par d√©faut qui d√©finissent les administrateurs syst√®me, les super utilisateurs, les utilisateurs et les utilisateurs en lecture seule.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons voir la liste des utilisateurs ici.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons voir la liste des utilisateurs ici.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AF90> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.86 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons voir la liste des utilisateurs ici.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous pouvons voir la liste des utilisateurs ici.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B410> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.25 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous pouvons voir la liste des utilisateurs ici.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons attribuer diff√©rents r√¥les √† ces utilisateurs, ce qui les aidera √† effectuer plusieurs t√¢ches.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons attribuer des r√¥les suppl√©mentaires aux groupes ou √† l'utilisateur qui les aideront √† cr√©er ou √† ex√©cuter des int√©grations, √† g√©rer ou √† approuver les gestionnaires de t√¢ches, √† cr√©er et √† utiliser des formulaires ad hoc.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons exporter √† partir de n'importe quelle instance et importer un format CSV avec la liste des utilisateurs et des groupes √† partir de toute instance diff√©rente dans cette instance particuli√®re.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_7_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais montrer plus de d√©tails sur la fa√ßon dont la s√©curit√© joue un r√¥le majeur dans EPM.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Regardons la s√©curit√© dimensionnelle.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour cette dimension particuli√®re, nous avons des r√¥les de s√©curit√© affect√©s √† chaque niveau de membre, ce qui donnera acc√®s seulement √† des utilisateurs particuliers ou √† des groupes assign√©s.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons cr√©er ou ajouter des utilisateurs et nous pouvons attribuer des acc√®s en lecture, √©criture ou sans acc√®s, ainsi que des fonctions comme les membres, les enfants du membre, ou les descendants du membre.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La s√©curit√© attribue la s√©curit√© des niveaux d'artefacts comme les formulaires de donn√©es, les rapports, les tableaux de bord, les t√¢ches, les flux.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Voyons comment nous pouvons attribuer la s√©curit√© pour un formulaire de donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais aller dans le dossier D√©mo et j'ai un formulaire et en cliquant sur ceci, je vais ajouter un groupe et donc le groupe Account Recon, lecture, si je l'ajoute et leur donne les fonctions requises, ils pourront acc√©der √† ce formulaire de donn√©es particulier et il sera limit√© pour les autres utilisateurs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_8_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous allons maintenant regarder la s√©curit√© au niveau des donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les intersections valides peuvent vous aider √† contr√¥ler la saisie des donn√©es en d√©finissant des combinaisons valides des membres de la dimension pour √©viter les entr√©es de donn√©es non valides.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Les intersections valides peuvent vous aider √† contr√¥ler la saisie des donn√©es en d√©finissant des combinaisons valides des membres de la dimension pour √©viter les entr√©es de donn√©es non valides.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B6F2240E0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.52 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Les intersections valides peuvent vous aider √† contr√¥ler la saisie des donn√©es en d√©finissant des combinaisons valides des membres de la dimension pour √©viter les entr√©es de donn√©es non valides.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devons simplement d√©finir les combinaisons et l'enregistrer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons √©galement une s√©curit√© au niveau des cellules qui contr√¥le l'acc√®s aux cellules individuelles en fonction des dimensions et des s√©lections de membres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons cr√©er une nouvelle ou faire une importation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Voyons comment cr√©er et configurer un formulaire de donn√©es. √Ä partir de la page d'accueil cliquez sur la carte Donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Sous actions, nous pouvons cr√©er un ad hoc ou cr√©er un formulaire.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Sous actions, nous pouvons cr√©er un ad hoc ou cr√©er un formulaire.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B4A0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.65 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Sous actions, nous pouvons cr√©er un ad hoc ou cr√©er un formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur Cr√©er un formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devons entrer le nom.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devrons s√©lectionner le cube.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous aurons toutes les dimensions ici.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_10.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devons faire glisser les dimensions sur les lignes et colonnes respectives.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_11.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement avoir des dimensions sur les pages.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_12.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devrons s√©lectionner les membres en cons√©quence.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_13.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cliquer sur l'ic√¥ne me donnera le s√©lecteur de membres et je peux ajouter le membre requis.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Cliquer sur l'ic√¥ne me donnera le s√©lecteur de membres et je peux ajouter le membre requis.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B380> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.84 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Cliquer sur l'ic√¥ne me donnera le s√©lecteur de membres et je peux ajouter le membre requis.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_14.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai la possibilit√© de personnaliser en fonction de la fa√ßon dont je veux voir les donn√©es si j'ai besoin de menus.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai la possibilit√© de personnaliser en fonction de la fa√ßon dont je veux voir les donn√©es si j'ai besoin de menus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BB60> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.56 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai la possibilit√© de personnaliser en fonction de la fa√ßon dont je veux voir les donn√©es si j'ai besoin de menus.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'J'ai la possibilit√© de personnaliser en fonction de la fa√ßon dont je veux voir les donn√©es si j'ai besoin de menus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.55 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'J'ai la possibilit√© de personnaliser en fonction de la fa√ßon dont je veux voir les donn√©es si j'ai besoin de menus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_9_15.mp3\n",
      "[Debug] Segment 10: adjusting speed factor=1.001\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les menus nous aident √† passer d'un formulaire √† un autre juste en cliquant avec le bouton droit sur le formulaire de donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'C'est l√† que nous pouvons ajouter une r√®gle m√©tier que nous avons cr√©√©e pour cette application.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'C'est l√† que nous pouvons ajouter une r√®gle m√©tier que nous avons cr√©√©e pour cette application.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B020> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.01 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'C'est l√† que nous pouvons ajouter une r√®gle m√©tier que nous avons cr√©√©e pour cette application.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons dire comment nous voulons g√©rer cette r√®gle m√©tier.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons dire comment nous voulons g√©rer cette r√®gle m√©tier.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AF00> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.75 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons dire comment nous voulons g√©rer cette r√®gle m√©tier.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous pouvons dire comment nous voulons g√©rer cette r√®gle m√©tier.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BEC0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.21 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous pouvons dire comment nous voulons g√©rer cette r√®gle m√©tier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans la disposition, nous pouvons voir diff√©rentes options si nous voulons supprimer les donn√©es, supprimer les lignes, supprimer les colonnes.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Dans la disposition, nous pouvons voir diff√©rentes options si nous voulons supprimer les donn√©es, supprimer les lignes, supprimer les colonnes.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.57 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Dans la disposition, nous pouvons voir diff√©rentes options si nous voulons supprimer les donn√©es, supprimer les lignes, supprimer les colonnes.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Dans la disposition, nous pouvons voir diff√©rentes options si nous voulons supprimer les donn√©es, supprimer les lignes, supprimer les colonnes.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B260> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.17 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Dans la disposition, nous pouvons voir diff√©rentes options si nous voulons supprimer les donn√©es, supprimer les lignes, supprimer les colonnes.'\n",
      "[Error] Attempt 3/5 failed for phrase: 'Dans la disposition, nous pouvons voir diff√©rentes options si nous voulons supprimer les donn√©es, supprimer les lignes, supprimer les colonnes.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B2F0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 4.01 seconds...\n",
      "[Debug] Attempt 4: Synthesizing phrase: 'Dans la disposition, nous pouvons voir diff√©rentes options si nous voulons supprimer les donn√©es, supprimer les lignes, supprimer les colonnes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons d√©finir des propri√©t√©s pour les dimensions si nous voulons voir l'alias du membre au lieu du nom du membre, masquer le membre, voir la description.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement d√©finir les propri√©t√©s de segment qui est une propri√©t√© de ligne et la propri√©t√© de colonne et ce que nous voulons voir.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons √©galement d√©finir les propri√©t√©s de segment qui est une propri√©t√© de ligne et la propri√©t√© de colonne et ce que nous voulons voir.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.07 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons √©galement d√©finir les propri√©t√©s de segment qui est une propri√©t√© de ligne et la propri√©t√© de colonne et ce que nous voulons voir.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous pouvons √©galement d√©finir les propri√©t√©s de segment qui est une propri√©t√© de ligne et la propri√©t√© de colonne et ce que nous voulons voir.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9A960> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.36 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous pouvons √©galement d√©finir les propri√©t√©s de segment qui est une propri√©t√© de ligne et la propri√©t√© de colonne et ce que nous voulons voir.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons √©galement diff√©rentes options en termes de fa√ßon de voir les donn√©es sous ce formulaire particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Il y a √©galement des r√®gles pour valider certaines conditions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_7.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai cr√©√© le formulaire de donn√©es en conservant la version, le produit, le march√©, la devise et le type d'usine dans le point de vue et le sc√©nario dans la page.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_8.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans les colonnes, nous avons l'ann√©e, la p√©riode et le compte.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_9.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans les lignes, nous avons l'entit√©.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_10.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai utilis√© une variable de substitution ou une variable utilisateur ici.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_11.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, en s√©lectionnant l'ic√¥ne du s√©lecteur de membres, nous voyons les membres mais aussi nous voyons des variables.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_12.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons d√©finir les variables qui nous aideront √† pr√©parer dynamiquement le formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_13.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai mis une condition ici pour la ligne 3.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_10_14.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Donc, si la valeur de la devise est sup√©rieure √† 6000, la cellule doit √™tre en rouge.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons valider la condition et nous obtiendrons la bo√Æte de dialogue.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous cliquerons sur OK.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous cliquerons sur OK.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B5C0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.87 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous cliquerons sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous cliquerons √† nouveau sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_11_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais enregistrer ce formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais fermer ce formulaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ceci est le formulaire que nous avons modifi√©e.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Ceci est le formulaire que nous avons modifi√©e.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9BAD0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.47 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Ceci est le formulaire que nous avons modifi√©e.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Ceci est le formulaire que nous avons modifi√©e.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AD50> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.18 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Ceci est le formulaire que nous avons modifi√©e.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais l'ouvrir.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En d√©veloppant l'ann√©e, je peux voir que le montant de 6000 a √©t√© mis en √©vidence selon la condition et je peux d√©velopper plus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai √©galement l'option d'ajuster les cellules comme je peux dire que c'est un ajustement de 10%.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_12_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux donc avoir une valeur n√©gative, positive ou un pourcentage.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_13_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur OK.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je vais cliquer sur OK.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B800> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.00 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je vais cliquer sur OK.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_13_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'La cellule est mise √† jour et nous pouvons voir comment la valeur est modifi√©e pour l'ann√©e totale.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_14_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Chaque fois que la cellule est mise √† jour en jaune lorsque nous les enregistrons, les donn√©es sont enregistr√©es imm√©diatement et nous pouvons voir comment les donn√©es sont refl√©t√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_15_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Tout comme Excel, nous pouvons faire glisser des donn√©es et apporter des donn√©es √† toutes ces lignes afin que toutes les donn√©es du trimestre soient mises √† jour avec le total et que je vais les enregistrer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_15_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je veux √©galement refl√©ter ces donn√©es pour tous les autres chiffres.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_16_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Pour celles-ci, je vais augmenter les donn√©es de 20%.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_16_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et pour cela, je vais augmenter les donn√©es de 50%.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_17_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai √©galement la possibilit√© de copier et coller les donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_18_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai √©galement la possibilit√© d'ajuster le niveau de la grille de donn√©es de la fa√ßon dont je souhaite l'ajuster.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_19_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Est-ce un ajustement proportionnel ou un ajustement uniforme?'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_20_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Disons donc pour le troisi√®me trimestre o√π j'ai des donn√©es pour juillet, ao√ªt et septembre, je vais ajuster les donn√©es proportionnellement et faire un ajustement de 1000.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_20_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous pouvez voir comment les donn√©es sont ajust√©es.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Vous pouvez voir comment les donn√©es sont ajust√©es.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B9B0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.24 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Vous pouvez voir comment les donn√©es sont ajust√©es.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Vous pouvez voir comment les donn√©es sont ajust√©es.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B260> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.57 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Vous pouvez voir comment les donn√©es sont ajust√©es.'\n",
      "[Error] Attempt 3/5 failed for phrase: 'Vous pouvez voir comment les donn√©es sont ajust√©es.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9AD50> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 4.08 seconds...\n",
      "[Debug] Attempt 4: Synthesizing phrase: 'Vous pouvez voir comment les donn√©es sont ajust√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_21_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement ajouter des pi√®ces jointes, ajouter des commentaires et joindre les d√©tails de support de nos fichiers locaux et le publier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_22_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'L'utilisateur sera en mesure de voir le nom d'utilisateur, la date √† laquelle le commentaire a √©t√© fait, l'heure et le commentaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_23_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, un utilisateur peut faire des commentaires s'il a acc√®s au formulaire et √† la cellule.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_24_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Lorsqu'un ic√¥ne bleu est visible sur la cellule, ceci signifie que nous avons une pi√®ce jointe ou un commentaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_24_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement d√©finir les pr√©f√©rences √† partir des outils.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons d√©finir la langue et les zones.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons d√©finir la fa√ßon dont nous voulons voir les donn√©es, la pr√©cision, les suppressions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous d√©finirons les variables utilisateur √† partir d'ici en s√©lectionnant le s√©lecteur de membre et en s√©lectionnant le membre respectif et en cliquant sur OK, puis en le enregistrant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_25_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We can also set the preference from the tools.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_26_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We can set the language and the areas.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_26_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We can set how we want to see the data,'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_26_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'the precision, suppressions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_27_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'We will set the user variables from here by selecting the member selector and selecting the respective member and clicking on OK and then saving it.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'We will set the user variables from here by selecting the member selector and selecting the respective member and clicking on OK and then saving it.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000024B4DD9B920> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.70 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'We will set the user variables from here by selecting the member selector and selecting the respective member and clicking on OK and then saving it.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\tmp_27_1.mp3\n",
      "‚úÖ Translated audio saved to: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.wav\n",
      "üìù Debug log saved to: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\translation_debug_log.txt\n",
      "Merging audio and video...\n",
      "Moviepy - Building video 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4\n",
      "Process completed! Output video: 4.2.4_Configuration de la solution_Avr_10_Latest_run_20250419_084520\\4.2.4_Configuration de la solution_Avr_10_Latest-french.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version we rely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def split_long_groups(groups, max_group_duration_secs):\n",
    "    \"\"\"\n",
    "    For each group (list of SubRipItems), if its duration > max_group_duration_secs,\n",
    "    split it at the *last* subtitle in that group whose text ends in punctuation\n",
    "    (.,!? or comma) before the duration threshold.\n",
    "    Falls back to a simple split if no such ‚Äúsafe‚Äù break exists.\n",
    "    \"\"\"\n",
    "    new_groups = []\n",
    "    for group in groups:\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        total   = end_s - start_s\n",
    "\n",
    "        # if already shorter than threshold, keep it\n",
    "        if total <= max_group_duration_secs:\n",
    "            new_groups.append(group)\n",
    "            continue\n",
    "\n",
    "        # otherwise walk through, tracking safe_breaks\n",
    "        temp = []\n",
    "        temp_start = start_s\n",
    "        last_safe_idx = None\n",
    "        for idx, item in enumerate(group):\n",
    "            temp.append(item)\n",
    "            # mark this idx if it ends in punctuation or comma\n",
    "            if re.search(r\"[.,!?]$\", item.text.strip()):\n",
    "                last_safe_idx = idx\n",
    "\n",
    "            current_end = item.end.ordinal / 1000\n",
    "            if (current_end - temp_start) >= max_group_duration_secs:\n",
    "                # if we have a safe break before or at idx, split there\n",
    "                if last_safe_idx is not None:\n",
    "                    # emit group up through last_safe_idx\n",
    "                    safe_group = temp[: last_safe_idx+1 ]\n",
    "                    new_groups.append(safe_group)\n",
    "                    # restart temp from the items after safe_idx\n",
    "                    temp = temp[last_safe_idx+1 :]\n",
    "                    temp_start = temp[0].start.ordinal / 1000 if temp else current_end\n",
    "                else:\n",
    "                    # no safe break‚Äîjust split at current idx\n",
    "                    new_groups.append(temp)\n",
    "                    temp = []\n",
    "                    temp_start = current_end\n",
    "\n",
    "                # reset safe marker\n",
    "                last_safe_idx = None\n",
    "\n",
    "        # anything left over\n",
    "        if temp:\n",
    "            new_groups.append(temp)\n",
    "\n",
    "    return new_groups\n",
    "\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    \"\"\"\n",
    "    Parse **Final Translation**, **Voice Speed**, **Pre‚ÄëSilence**, **Post‚ÄëSilence**.\n",
    "    Returns a list of dicts, one per segment.\n",
    "    \"\"\"\n",
    "    overrides = []\n",
    "    text = open(review_file_path, \"r\", encoding=\"utf-8\").read()\n",
    "    blocks = [b.strip() for b in text.split(\"----------------------------------------------------------------\") if b.strip()]\n",
    "\n",
    "    for blk in blocks:\n",
    "        ft = vs = None\n",
    "        pre_ms = 0.0\n",
    "        post_ms = 100.0  # Default to 100ms if not specified\n",
    "\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                ft = line.split(\"**Final Translation:**\",1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                vs = line.split(\"**Voice Speed:**\",1)[1].strip()\n",
    "            # Corrected hyphen in Pre-Silence and Post-Silence\n",
    "            elif line.startswith(\"**Pre-Silence:**\"):\n",
    "                try:\n",
    "                    pre_ms = float(line.split(\"**Pre-Silence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    pre_ms = 0.0\n",
    "            elif line.startswith(\"**Post-Silence:**\"):\n",
    "                try:\n",
    "                    post_ms = float(line.split(\"**Post-Silence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    post_ms = 100.0\n",
    "\n",
    "        if ft is not None and vs is not None:\n",
    "            overrides.append({\n",
    "                \"final_translation\": ft,\n",
    "                \"voice_speed\":      vs,\n",
    "                \"pre_silence\":      pre_ms,\n",
    "                \"post_silence\":     post_ms\n",
    "            })\n",
    "\n",
    "    print(\"Parsed review overrides:\")\n",
    "    for idx, o in enumerate(overrides, 1):\n",
    "        print(f\"  Segment {idx}: pre={o['pre_silence']}ms, post={o['post_silence']}ms, speed={o['voice_speed']}\")\n",
    "    return overrides\n",
    "\n",
    "def generate_translation_review_file(\n",
    "    source_path, review_file_path,\n",
    "    from_lang=\"en\", to_lang=\"fr\",\n",
    "    max_group_duration_secs: float = 25.0  # Increased max duration to reduce splits\n",
    "):\n",
    "    \"\"\"\n",
    "    1. Translates and groups by sentence.\n",
    "    2. Splits any group longer than max_group_duration_secs\n",
    "       into shorter chunks at subtitle-item boundaries.\n",
    "    3. Writes the review file as before, one block per (sub-)group.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "\n",
    "    # 1) Build initial sentence‚Äëbased groups\n",
    "    sentence_end = re.compile(r\"[.!?]\\s*$\")\n",
    "    groups = []\n",
    "    current = []\n",
    "    for sub in subs:\n",
    "        current.append(sub)\n",
    "        if sentence_end.search(sub.text):\n",
    "            groups.append(current)\n",
    "            current = []\n",
    "    if current:\n",
    "        groups.append(current)\n",
    "\n",
    "    # 2) Split any over‚Äëlong groups at safe punctuation boundaries\n",
    "    groups = split_long_groups(groups, max_group_duration_secs)\n",
    "    \n",
    "    # 3) Enforce punctuation boundaries to prevent mid-sentence splits\n",
    "    groups = enforce_punctuation_boundaries(groups)\n",
    "\n",
    "    # 4) Write the review file\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Pre-Silence:**, **Post-Silence:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "        for idx, group in enumerate(groups, 1):\n",
    "            start_s = group[0].start.ordinal / 1000\n",
    "            end_s   = group[-1].end.ordinal   / 1000\n",
    "            original = \" \".join(s.text for s in group)\n",
    "            auto_tr  = translator.translate(text=original)\n",
    "\n",
    "            f.write(f\"Segment {idx} (start: {start_s:.2f}s, end: {end_s:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Voice Speed:** +0%\\n\")\n",
    "            f.write(f\"**Pre-Silence:** 100\\n\")  # Default pre-silence\n",
    "            f.write(f\"**Post-Silence:** 100\\n\")  # Default post-silence\n",
    "            f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Review file created at: {review_file_path}  (split into {len(groups)} segments)\")\n",
    "    input(\"Type 'Y' when ready to continue: \")\n",
    "    return groups\n",
    "\n",
    "\n",
    "def enforce_punctuation_boundariesolf(groups):\n",
    "    \"\"\"\n",
    "    Ensure each group‚Äôs last subtitle ends in .,!? or comma.\n",
    "    If not, merge it with the next group (and repeat) until it does.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    fixed = []\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        # if last line of this group doesn't end in safe punctuation\n",
    "        if not safe_re.search(g[-1].text.strip()):\n",
    "            # and there *is* a next group, merge them\n",
    "            if i + 1 < len(groups):\n",
    "                groups[i+1] = g + groups[i+1]\n",
    "                i += 1\n",
    "                continue\n",
    "        # otherwise it's ‚Äúsafe‚Äù (or no next group to merge), keep it\n",
    "        fixed.append(g)\n",
    "        i += 1\n",
    "    return fixed\n",
    "\n",
    "def enforce_punctuation_boundaries(groups):\n",
    "    \"\"\"Ensure groups end with proper punctuation\"\"\"\n",
    "    i = 0\n",
    "    safe_punctuation = r\"[.!?,;:]$\"\n",
    "    while i < len(groups):\n",
    "        last_text = groups[i][-1].text.strip()\n",
    "        if not re.search(safe_punctuation, last_text):\n",
    "            if i+1 < len(groups):\n",
    "                groups[i] += groups.pop(i+1)\n",
    "            else:  # Add artificial pause for final group\n",
    "                groups[i][-1].text += \".\"\n",
    "        else:\n",
    "            i += 1\n",
    "    return groups\n",
    "\n",
    "\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text)\n",
    "    return [phrase.strip() for phrase in phrases if phrase.strip()]\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    Note: In Edge TTS v7.0.0 the 'session' parameter is not supported.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session for each attempt.\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate\n",
    "                )\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "\n",
    "\n",
    "\n",
    "async def async_generate_translated_audio_with_sync_using_review(\n",
    "    subtitle_source_path, output_audio_path,\n",
    "    debug_log_path, review_file_path\n",
    "):\n",
    "    # 1) Build/write review file & parse overrides\n",
    "    groups    = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "\n",
    "    # Pad overrides list so it matches the number of groups\n",
    "    default_override = {\n",
    "        \"final_translation\": None,   # we'll fall back to original text below\n",
    "        \"voice_speed\":      \"+0%\",\n",
    "        \"pre_silence\":      0.0,\n",
    "        \"post_silence\":     100.0\n",
    "    }\n",
    "    while len(overrides) < len(groups):\n",
    "        overrides.append(default_override.copy())\n",
    "\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines    = []\n",
    "    offset_threshold = 0.05  # seconds\n",
    "\n",
    "    for idx, group in enumerate(groups):\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        seg_dur = end_s - start_s\n",
    "\n",
    "        orig = \" \".join(s.text for s in group)\n",
    "        ovr  = overrides[idx]\n",
    "        fr_text = ovr[\"final_translation\"] or orig\n",
    "        rate    = ovr[\"voice_speed\"]\n",
    "        pre_ms  = ovr[\"pre_silence\"]\n",
    "        post_ms = ovr[\"post_silence\"]\n",
    "        total_ms = int(seg_dur * 1000)\n",
    "\n",
    "        # allocate content time (subtract pre & post)\n",
    "        content_ms = max(0, total_ms - int(pre_ms) - int(post_ms))\n",
    "\n",
    "        # split into phrases & weights\n",
    "        phrases = split_french_phrases(fr_text)\n",
    "        weights = calculate_phrase_weights(orig, phrases)\n",
    "\n",
    "        # synth & adjust each phrase\n",
    "        phrase_audios = []\n",
    "        for i, ph in enumerate(phrases):\n",
    "            dur = content_ms * weights[i] / 1000.0\n",
    "            tmp = os.path.join(tempfile.gettempdir(), f\"tmp_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(ph, tmp, voice=\"fr-FR-DeniseNeural\", rate=rate)\n",
    "                aud = AudioSegment.from_mp3(tmp)\n",
    "                aud = adjust_audio_duration(aud, dur)\n",
    "                phrase_audios.append(aud)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] phrase {i} failed: {e}\")\n",
    "            finally:\n",
    "                if os.path.exists(tmp):\n",
    "                    os.remove(tmp)\n",
    "\n",
    "        # assemble with pre & post silence\n",
    "        seg_audio = AudioSegment.silent(duration=pre_ms)\n",
    "        for aud in phrase_audios:\n",
    "            seg_audio += aud\n",
    "        seg_audio += AudioSegment.silent(duration=post_ms)\n",
    "\n",
    "        # trim/pad to exactly total_ms\n",
    "        seg_audio = seg_audio[:total_ms]\n",
    "\n",
    "        # if needed, apply global speed adjustment\n",
    "        gen_dur = seg_audio.duration_seconds\n",
    "        diff = seg_dur - gen_dur\n",
    "        if abs(diff) > offset_threshold:\n",
    "            factor = seg_dur / gen_dur\n",
    "            print(f\"[Debug] Segment {idx+1}: adjusting speed factor={factor:.3f}\")\n",
    "            seg_audio = change_playback_speed(seg_audio, factor)\n",
    "\n",
    "        # place at the correct start in the combined track\n",
    "        start_ms = int(start_s * 1000)\n",
    "        if len(combined_audio) < start_ms:\n",
    "            combined_audio += AudioSegment.silent(duration=start_ms - len(combined_audio))\n",
    "        combined_audio += seg_audio\n",
    "\n",
    "        # log\n",
    "        debug_lines.append(\n",
    "            f\"Segment {idx+1} ({start_s:.2f}-{end_s:.2f}s): \"\n",
    "            f\"pre={pre_ms}ms, post={post_ms}ms, speed={rate}, phrases={phrases}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # write debug log & export\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as df:\n",
    "        df.write(\"Translation Debug Log\\n\\n\")\n",
    "        df.writelines(debug_lines)\n",
    "\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790acbb9",
   "metadata": {},
   "source": [
    "OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad9974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "1Ô∏è‚É£ Extracting audio‚Ä¶\n",
      "2Ô∏è‚É£ Transcribing‚Ä¶\n",
      "Detected language: en\n",
      "3Ô∏è‚É£ Writing SRT‚Ä¶\n",
      "4Ô∏è‚É£ Preparing translation review‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "\n",
    "# Paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "extracted_audio = os.path.join(output_dir, f\"{base_name}-extracted-audio.wav\")\n",
    "subtitle_file = os.path.join(output_dir, f\"{base_name}-english.srt\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{base_name}-french.wav\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "output_video = os.path.join(output_dir, f\"{base_name}-french.mp4\")\n",
    "\n",
    "# ============== Audio extraction & transcription ==============\n",
    "def extract_audio():\n",
    "    \"\"\"\n",
    "    Extracts the audio track from the input video into a 16kHz mono WAV file.\n",
    "    Prints full ffmpeg stderr on failure for easier debugging.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run ffmpeg without capturing stderr so we can see any errors directly\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run()\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        # ffmpeg.Error contains stdout and stderr bytes\n",
    "        print(\"‚ö†Ô∏è ffmpeg failed to extract audio. ffmpeg stderr output below:\")\n",
    "        try:\n",
    "            print(e.stderr.decode('utf-8', errors='replace'))\n",
    "        except Exception:\n",
    "            print(e.stderr)\n",
    "        raise\n",
    "    \n",
    "    # Should never reach here\n",
    "    return None\n",
    "\n",
    "class SubRipTimeConverter:\n",
    "    @staticmethod\n",
    "    def to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "        h = int(seconds // 3600)\n",
    "        seconds %= 3600\n",
    "        m = int(seconds // 60)\n",
    "        s = int(seconds % 60)\n",
    "        ms = int((seconds - s) * 1000)\n",
    "        return pysrt.SubRipTime(hours=h, minutes=m, seconds=s, milliseconds=ms)\n",
    "\n",
    "def generate_subtitles(segments, path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, seg in enumerate(segments, 1):\n",
    "        item = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=SubRipTimeConverter.to_subrip(seg['start']),\n",
    "            end=SubRipTimeConverter.to_subrip(seg['end']),\n",
    "            text=seg['text']\n",
    "        )\n",
    "        subs.append(item)\n",
    "    subs.save(path, encoding='utf-8')\n",
    "    return path\n",
    "\n",
    "async def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    print(f\"Detected language: {info.language}\")\n",
    "    out = []\n",
    "    for s in segments:\n",
    "        out.append({'start': s.start, 'end': s.end, 'text': s.text.strip()})\n",
    "    return info.language, out\n",
    "\n",
    "# ============== Review file grouping & splitting ==============\n",
    "def split_long_groupsO(groups, max_secs):\n",
    "    new = []\n",
    "    safe = re.compile(r\"[.,!?]$\")\n",
    "    for grp in groups:\n",
    "        st = grp[0].start.ordinal/1000\n",
    "        en = grp[-1].end.ordinal/1000\n",
    "        if en-st <= max_secs:\n",
    "            new.append(grp)\n",
    "            continue\n",
    "        temp, ts, last_safe = [], st, None\n",
    "        for i,item in enumerate(grp):\n",
    "            temp.append(item)\n",
    "            if safe.search(item.text.strip()): last_safe = i\n",
    "            now = item.end.ordinal/1000\n",
    "            if now-ts >= max_secs:\n",
    "                if last_safe is not None:\n",
    "                    new.append(temp[:last_safe+1])\n",
    "                    temp = temp[last_safe+1:]\n",
    "                else:\n",
    "                    new.append(temp)\n",
    "                    temp = []\n",
    "                ts = temp[0].start.ordinal/1000 if temp else now\n",
    "                last_safe = None\n",
    "        if temp: new.append(temp)\n",
    "    return new\n",
    "\n",
    "def enforce_punctuation_boundariesO(groups):\n",
    "    safe = re.compile(r\"[.,!?]$\")\n",
    "    out, i = [], 0\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        if not safe.search(g[-1].text.strip()) and i+1 < len(groups):\n",
    "            groups[i+1] = g + groups[i+1]\n",
    "        else:\n",
    "            out.append(g)\n",
    "            i += 1\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def split_long_groups(groups, max_group_duration_secs):\n",
    "    \"\"\"\n",
    "    For each group (list of SubRipItems), if its duration > max_group_duration_secs,\n",
    "    split it at the *last* subtitle in that group whose text ends in punctuation\n",
    "    (.,!? or comma) before the duration threshold.\n",
    "    Falls back to a simple split if no such ‚Äúsafe‚Äù break exists.\n",
    "    \"\"\"\n",
    "    new_groups = []\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    for group in groups:\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        total   = end_s - start_s\n",
    "\n",
    "        if total <= max_group_duration_secs:\n",
    "            new_groups.append(group)\n",
    "            continue\n",
    "\n",
    "        temp = []\n",
    "        temp_start = start_s\n",
    "        last_safe_idx = None\n",
    "        for idx, item in enumerate(group):\n",
    "            temp.append(item)\n",
    "            if safe_re.search(item.text.strip()):\n",
    "                last_safe_idx = idx\n",
    "\n",
    "            current_end = item.end.ordinal / 1000\n",
    "            if (current_end - temp_start) >= max_group_duration_secs:\n",
    "                if last_safe_idx is not None:\n",
    "                    # split at last safe punctuation\n",
    "                    new_groups.append(temp[: last_safe_idx+1])\n",
    "                    temp = temp[last_safe_idx+1 :]\n",
    "                else:\n",
    "                    # no safe break, just split here\n",
    "                    new_groups.append(temp)\n",
    "                    temp = []\n",
    "                temp_start = temp[0].start.ordinal / 1000 if temp else current_end\n",
    "                last_safe_idx = None\n",
    "\n",
    "        if temp:\n",
    "            new_groups.append(temp)\n",
    "\n",
    "    return new_groups\n",
    "\n",
    "def enforce_punctuation_boundaries(groups):\n",
    "    \"\"\"\n",
    "    Ensure each group‚Äôs last subtitle ends in .,!? or comma.\n",
    "    If not, merge it with the next group (and repeat) until it does.\n",
    "    \"\"\"\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        if not safe_re.search(g[-1].text.strip()) and i + 1 < len(groups):\n",
    "            # merge into next\n",
    "            groups[i+1] = g + groups[i+1]\n",
    "        else:\n",
    "            fixed.append(g)\n",
    "            i += 1\n",
    "    return fixed\n",
    "\n",
    "\n",
    "# ============== Parse overrides ==============\n",
    "def parse_review_overrides(review_path):\n",
    "    blocks = [b.strip() for b in open(review_path, 'r', encoding='utf-8').read().split('----------------------------------------------------------------') if b.strip()]\n",
    "    out=[]\n",
    "    for blk in blocks:\n",
    "        ft,vs,pre,post = None,'+0%',0,100\n",
    "        for ln in blk.splitlines():\n",
    "            if ln.startswith('**Final Translation:**'):\n",
    "                ft = ln.split('**Final Translation:**',1)[1].strip()\n",
    "            elif ln.startswith('**Voice Speed:**'):\n",
    "                vs = ln.split('**Voice Speed:**',1)[1].strip()\n",
    "            elif ln.startswith('**Pre-Silence:**'):\n",
    "                pre = float(ln.split('**Pre-Silence:**',1)[1].strip())\n",
    "            elif ln.startswith('**Post-Silence:**'):\n",
    "                post= float(ln.split('**Post-Silence:**',1)[1].strip())\n",
    "        out.append({\n",
    "            'final_translation': ft,\n",
    "            'voice_speed': vs,\n",
    "            'pre_silence': int(pre),\n",
    "            'post_silence':int(post)\n",
    "        })\n",
    "    print(f\"Parsed {len(out)} overrides\")\n",
    "    return out\n",
    "\n",
    "# ============== Phrase splitting & weights ==============\n",
    "def split_french_phrases(text):\n",
    "    return [p.strip() for p in re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text) if p.strip()]\n",
    "\n",
    "def calculate_phrase_weights(orig, phrases):\n",
    "    counts = [len(p.split()) for p in phrases]\n",
    "    total  = sum(counts)\n",
    "    return [c/total if total>0 else 1/len(phrases) for c in counts]\n",
    "\n",
    "# ============== Robust Edge-TTS ==============\n",
    "async def robust_synthesize_phrase(text, output_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\", max_retries=5):\n",
    "    tmp = output_path + \".tmp.mp3\"\n",
    "    for attempt in range(1, max_retries+1):\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as sess:\n",
    "                comm = edge_tts.Communicate(text=text, voice=voice, rate=rate)\n",
    "                print(f\"[TTS] Attempt {attempt}: {text[:30]}‚Ä¶\")\n",
    "                await comm.save(tmp)\n",
    "            seg = AudioSegment.from_mp3(tmp)\n",
    "            seg.export(output_path, format='wav')\n",
    "            os.remove(tmp)\n",
    "            return\n",
    "        except Exception as e:\n",
    "            delay = 2**(attempt-1) + random.random()\n",
    "            print(f\"[TTS] Fail #{attempt}: {e} ‚Äì retry in {delay:.1f}s\")\n",
    "            try: os.remove(tmp)\n",
    "            except: pass\n",
    "            await asyncio.sleep(delay)\n",
    "    # fallback\n",
    "    AudioSegment.silent(duration=1000).export(output_path, format='wav')\n",
    "\n",
    "async def async_generate_translated_audio_with_sync_using_review(\n",
    "    subtitle_srt, out_audio, debug_log, review_txt\n",
    "):\n",
    "    groups    = generate_translation_review_file(subtitle_srt, review_txt)\n",
    "    overrides = parse_review_overrides(review_txt)\n",
    "    default   = {'final_translation':None,'voice_speed':'+0%','pre_silence':0,'post_silence':100}\n",
    "    while len(overrides)<len(groups): overrides.append(default.copy())\n",
    "\n",
    "    combined = AudioSegment.silent(duration=0)\n",
    "    debug    = []\n",
    "    TH       = 0.05\n",
    "\n",
    "    for i,grp in enumerate(groups):\n",
    "        st = grp[0].start.ordinal/1000\n",
    "        en = grp[-1].end.ordinal/1000\n",
    "        dur_ms = int((en-st)*1000)\n",
    "        orig = \" \".join(x.text for x in grp)\n",
    "        ovr  = overrides[i]\n",
    "        fr   = ovr['final_translation'] or orig\n",
    "        rate = ovr['voice_speed']\n",
    "        pre  = ovr['pre_silence']\n",
    "        post = ovr['post_silence']\n",
    "        content_ms = max(0, dur_ms-pre-post)\n",
    "\n",
    "        phrases = split_french_phrases(fr)\n",
    "        weights = calculate_phrase_weights(orig, phrases)\n",
    "\n",
    "        seg_audio = AudioSegment.silent(pre)\n",
    "        for j,ph in enumerate(phrases):\n",
    "            tmp = os.path.join(tempfile.gettempdir(), f\"tts_{i}_{j}.wav\")\n",
    "            await robust_synthesize_phrase(ph, tmp, rate=rate)\n",
    "            part = AudioSegment.from_wav(tmp)\n",
    "            part = adjust_audio_duration(part, content_ms*weights[j]/1000)\n",
    "            seg_audio += part\n",
    "            os.remove(tmp)\n",
    "        seg_audio += AudioSegment.silent(post)\n",
    "        seg_audio = seg_audio[:dur_ms]\n",
    "\n",
    "        # speed adjust\n",
    "        gd = seg_audio.duration_seconds\n",
    "        td = en-st\n",
    "        if abs(td-gd)>TH:\n",
    "            factor = td/gd\n",
    "            seg_audio = change_playback_speed(seg_audio, factor)\n",
    "\n",
    "        offset = int(st*1000)\n",
    "        if len(combined)<offset:\n",
    "            combined += AudioSegment.silent(offset-len(combined))\n",
    "        combined += seg_audio\n",
    "        debug.append(f\"Segment {i+1}: {st:.2f}-{en:.2f}s pre={pre} post={post} rate={rate}\\n\")\n",
    "\n",
    "    combined.export(out_audio, format='wav')\n",
    "    with open(debug_log,'w',encoding='utf-8') as df:\n",
    "        df.write(\"Debug Log\\n\\n\"+\"\".join(debug))\n",
    "\n",
    "# ============== Helpers ==============\n",
    "def adjust_audio_duration(audio, target_dur_s):\n",
    "    cur = audio.duration_seconds\n",
    "    diff= target_dur_s - cur\n",
    "    if diff>0.1:\n",
    "        return audio + AudioSegment.silent(duration=int(diff*1000))\n",
    "    if diff<-0.1:\n",
    "        return audio[:int(target_dur_s*1000)]\n",
    "    return audio\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    fr = int(sound.frame_rate * speed)\n",
    "    sp = sound._spawn(sound.raw_data, overrides={'frame_rate': fr})\n",
    "    return sp.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "def merge_audio_video(video_in, audio_in, video_out):\n",
    "    vid = VideoFileClip(video_in)\n",
    "    aud = AudioFileClip(audio_in)\n",
    "    vid = vid.set_audio(aud)\n",
    "    vid.write_videofile(video_out, codec='libx264', audio_codec='aac')\n",
    "\n",
    "\n",
    "import re\n",
    "import pysrt\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def generate_translation_review_file(\n",
    "    source_path,\n",
    "    review_file_path,\n",
    "    from_lang: str = \"en\",\n",
    "    to_lang:   str = \"fr\",\n",
    "    max_group_duration_secs: float = 15.0,\n",
    "    pause_for_review: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Group by sentence.\n",
    "    2) Split groups longer than max_group_duration_secs at safe punctuation.\n",
    "    3) Enforce that each group ends on .,!? or comma.\n",
    "    4) Batch‚Äëtranslate via GoogleTranslator.translate_batch(batch=‚Ä¶).\n",
    "    5) Write the standard review file template.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs       = pysrt.open(source_path)\n",
    "    sentence_end = re.compile(r\"[.!?]\\s*$\")\n",
    "\n",
    "    # 1) Build initial sentence‚Äëbased groups\n",
    "    groups = []\n",
    "    cur = []\n",
    "    for sub in subs:\n",
    "        cur.append(sub)\n",
    "        if sentence_end.search(sub.text):\n",
    "            groups.append(cur)\n",
    "            cur = []\n",
    "    if cur:\n",
    "        groups.append(cur)\n",
    "\n",
    "    # 2) Split any over‚Äëlong groups\n",
    "    groups = split_long_groups(groups, max_group_duration_secs)\n",
    "\n",
    "    # 3) Enforce natural ending punctuation\n",
    "    groups = enforce_punctuation_boundaries(groups)\n",
    "\n",
    "    # 4) Prepare originals & auto‚Äëtranslate in batch\n",
    "    originals = [\" \".join(item.text for item in g) for g in groups]\n",
    "    try:\n",
    "        # correct signature is translate_batch(batch=‚Ä¶\n",
    "        auto_translations = translator.translate_batch(batch=originals)\n",
    "    except TypeError:\n",
    "        # fallback if older version\n",
    "        auto_translations = [translator.translate(text=o) for o in originals]\n",
    "\n",
    "    # 5) Write out review file\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Pre-Silence:**, **Post-Silence:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "        for idx, (grp, auto_tr) in enumerate(zip(groups, auto_translations), start=1):\n",
    "            start_s = grp[0].start.ordinal / 1000\n",
    "            end_s   = grp[-1].end.ordinal   / 1000\n",
    "            original = \" \".join(item.text for item in grp)\n",
    "\n",
    "            f.write(f\"Segment {idx} (start: {start_s:.2f}s, end: {end_s:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Voice Speed:** +0%\\n\")\n",
    "            f.write(f\"**Pre-Silence:** 0\\n\")\n",
    "            f.write(f\"**Post-Silence:** 100\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Review file created at: {review_file_path}  (split into {len(groups)} segments)\")\n",
    "    if pause_for_review:\n",
    "        input(\"Type 'Y' when ready to continue: \")\n",
    "    return groups\n",
    "\n",
    "\n",
    "\n",
    "# ============== Main ==============\n",
    "async def main():\n",
    "    print(\"1Ô∏è‚É£ Extracting audio‚Ä¶\")\n",
    "    wav = extract_audio()\n",
    "    print(\"2Ô∏è‚É£ Transcribing‚Ä¶\")\n",
    "    lang, segs = await transcribe(wav)\n",
    "    print(\"3Ô∏è‚É£ Writing SRT‚Ä¶\")\n",
    "    generate_subtitles(segs, subtitle_file)\n",
    "    print(\"4Ô∏è‚É£ Preparing translation review‚Ä¶\")\n",
    "    # review file will pause here for your edits\n",
    "    await asyncio.to_thread(generate_translation_review_file, subtitle_file, review_file, lang, 'fr')\n",
    "    print(\"5Ô∏è‚É£ Generating translated audio‚Ä¶\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(\n",
    "        subtitle_file, translated_audio, debug_log_file, review_file\n",
    "    )\n",
    "    print(\"6Ô∏è‚É£ Merging with video‚Ä¶\")\n",
    "    merge_audio_video(input_video, translated_audio, output_video)\n",
    "    print(f\"‚úÖ Done: {output_video}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a51d3",
   "metadata": {},
   "source": [
    "\"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version we rely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "import re\n",
    "import pysrt\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def split_long_groups(groups, max_group_duration_secs):\n",
    "    \"\"\"\n",
    "    For each group (a list of SubRipItems), if its span (end - start)\n",
    "    exceeds max_group_duration_secs, break it at the last subtitle\n",
    "    in that group which ends in .,!? (if possible), otherwise cut as is.\n",
    "    \"\"\"\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    new_groups = []\n",
    "    for group in groups:\n",
    "        start_time = group[0].start.ordinal / 1000.0\n",
    "        temp, last_safe = [], None\n",
    "\n",
    "        for i, item in enumerate(group):\n",
    "            temp.append(item)\n",
    "            # mark safe cut point\n",
    "            if safe_re.search(item.text.strip()):\n",
    "                last_safe = i\n",
    "\n",
    "            elapsed = (item.end.ordinal / 1000.0) - start_time\n",
    "            if elapsed >= max_group_duration_secs:\n",
    "                # split here\n",
    "                if last_safe is not None and last_safe < len(temp)-1:\n",
    "                    # cut at last safe boundary\n",
    "                    new_groups.append(temp[: last_safe+1])\n",
    "                    temp = temp[last_safe+1:]\n",
    "                else:\n",
    "                    new_groups.append(temp)\n",
    "                    temp = []\n",
    "                # reset for remainder\n",
    "                if temp:\n",
    "                    start_time = temp[0].start.ordinal / 1000.0\n",
    "                last_safe = None\n",
    "\n",
    "        if temp:\n",
    "            new_groups.append(temp)\n",
    "    return new_groups\n",
    "\n",
    "def enforce_punctuation_boundaries(groups):\n",
    "    \"\"\"\n",
    "    Ensure each group's last subtitle ends in .,!? or comma.\n",
    "    If not, merge it into the next group until it does.\n",
    "    \"\"\"\n",
    "    safe_re = re.compile(r\"[.,!?]$\")\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    while i < len(groups):\n",
    "        g = groups[i]\n",
    "        if not safe_re.search(g[-1].text.strip()) and (i + 1) < len(groups):\n",
    "            # merge into the next group\n",
    "            groups[i+1] = g + groups[i+1]\n",
    "        else:\n",
    "            fixed.append(g)\n",
    "            i += 1\n",
    "    return fixed\n",
    "\n",
    "def generate_translation_review_file(\n",
    "    source_path, review_file_path,\n",
    "    from_lang=\"en\", to_lang=\"fr\",\n",
    "    max_group_duration_secs: float = 15.0\n",
    "):\n",
    "    \"\"\"\n",
    "    1. Translates and groups by sentence.\n",
    "    2. Splits any group longer than max_group_duration_secs\n",
    "       into shorter chunks at subtitle-item boundaries.\n",
    "    3. Enforces that every group ends on .,!? or comma.\n",
    "    4. Writes the review file: one block per (sub-)group.\n",
    "    \"\"\"\n",
    "    # load and initial sentence‚Äêbased grouping\n",
    "    subs       = pysrt.open(source_path)\n",
    "    sentence_end = re.compile(r\"[.!?]\\s*$\")\n",
    "    groups, cur = [], []\n",
    "    for s in subs:\n",
    "        cur.append(s)\n",
    "        if sentence_end.search(s.text):\n",
    "            groups.append(cur)\n",
    "            cur = []\n",
    "    if cur:\n",
    "        groups.append(cur)\n",
    "\n",
    "    # split too‚Äêlong groups\n",
    "    groups = split_long_groups(groups, max_group_duration_secs)\n",
    "    # enforce safe punctuation at end\n",
    "    groups = enforce_punctuation_boundaries(groups)\n",
    "\n",
    "    # translate & write review template\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Silence Duration:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "        for i, grp in enumerate(groups, 1):\n",
    "            start_s = grp[0].start.ordinal / 1000\n",
    "            end_s   = grp[-1].end.ordinal   / 1000\n",
    "            orig    = \" \".join(s.text for s in grp)\n",
    "            auto_tr = translator.translate(text=orig)\n",
    "\n",
    "            f.write(f\"Segment {i} (start: {start_s:.2f}s, end: {end_s:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {orig}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_tr}\\n\")\n",
    "            f.write(f\"**Voice Speed:** +0%\\n\")\n",
    "            f.write(f\"**Silence Duration:** 100\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Review file created at: {review_file_path}  (split into {len(groups)} segments)\")\n",
    "    input(\"Type 'Y' when ready to continue: \")\n",
    "    return groups\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    \"\"\"\n",
    "    Parse **Final Translation**, **Voice Speed**, **Pre‚ÄëSilence**, **Post‚ÄëSilence**.\n",
    "    Returns a list of dicts, one per segment.\n",
    "    \"\"\"\n",
    "    overrides = []\n",
    "    text = open(review_file_path, \"r\", encoding=\"utf-8\").read()\n",
    "    blocks = [b.strip() for b in text.split(\"----------------------------------------------------------------\") if b.strip()]\n",
    "\n",
    "    for blk in blocks:\n",
    "        ft = vs = None\n",
    "        pre_ms = 0.0\n",
    "        post_ms = 100.0\n",
    "\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                ft = line.split(\"**Final Translation:**\",1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                vs = line.split(\"**Voice Speed:**\",1)[1].strip()\n",
    "            elif line.startswith(\"**Pre‚ÄëSilence:**\"):\n",
    "                try:\n",
    "                    pre_ms = float(line.split(\"**Pre‚ÄëSilence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    pre_ms = 0.0\n",
    "            elif line.startswith(\"**Post‚ÄëSilence:**\"):\n",
    "                try:\n",
    "                    post_ms = float(line.split(\"**Post‚ÄëSilence:**\",1)[1].strip())\n",
    "                except ValueError:\n",
    "                    post_ms = 100.0\n",
    "\n",
    "        if ft is not None and vs is not None:\n",
    "            overrides.append({\n",
    "                \"final_translation\": ft,\n",
    "                \"voice_speed\":      vs,\n",
    "                \"pre_silence\":      pre_ms,\n",
    "                \"post_silence\":     post_ms\n",
    "            })\n",
    "\n",
    "    print(\"Parsed review overrides:\")\n",
    "    for idx, o in enumerate(overrides, 1):\n",
    "        print(f\"  Segment {idx}: pre={o['pre_silence']}ms, post={o['post_silence']}ms, speed={o['voice_speed']}\")\n",
    "    return overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text)\n",
    "    return [phrase.strip() for phrase in phrases if phrase.strip()]\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    Note: In Edge TTS v7.0.0 the 'session' parameter is not supported.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session for each attempt.\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate\n",
    "                )\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_reviewOLD(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "\n",
    "        print(f\"[Debug] Segment {idx+1} final translation: {final_translation}\")\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            try:\n",
    "                audio = AudioSegment.from_mp3(temp_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Unable to load audio from {temp_path}: {e}. Skipping this phrase.\")\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "                continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"[Debug] Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def async_generate_translated_audio_with_sync_using_review(\n",
    "    subtitle_source_path, output_audio_path,\n",
    "    debug_log_path, review_file_path\n",
    "):\n",
    "    # 1) Build/write review file & parse overrides\n",
    "    groups    = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "\n",
    "    subs          = pysrt.open(subtitle_source_path)\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines    = []\n",
    "    offset_threshold = 0.05  # sec\n",
    "\n",
    "    for idx, group in enumerate(groups):\n",
    "        start_s = group[0].start.ordinal / 1000\n",
    "        end_s   = group[-1].end.ordinal   / 1000\n",
    "        seg_dur = end_s - start_s\n",
    "\n",
    "        orig = \" \".join(s.text for s in group)\n",
    "        ovr  = overrides[idx]\n",
    "        fr_text = ovr[\"final_translation\"]\n",
    "        rate    = ovr[\"voice_speed\"]\n",
    "        pre_ms  = ovr[\"pre_silence\"]\n",
    "        post_ms = ovr[\"post_silence\"]\n",
    "        total_ms = int(seg_dur * 1000)\n",
    "\n",
    "        # allocate content time (subtract pre & post)\n",
    "        content_ms = max(0, total_ms - int(pre_ms) - int(post_ms))\n",
    "\n",
    "        # split into phrases & weights\n",
    "        phrases = split_french_phrases(fr_text)\n",
    "        weights = calculate_phrase_weights(orig, phrases)\n",
    "\n",
    "        # synth & adjust each phrase\n",
    "        phrase_audios = []\n",
    "        for i, ph in enumerate(phrases):\n",
    "            dur = content_ms * weights[i] / 1000.0\n",
    "            tmp = os.path.join(tempfile.gettempdir(), f\"tmp_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(ph, tmp, voice=\"fr-FR-DeniseNeural\", rate=rate)\n",
    "                aud = AudioSegment.from_mp3(tmp)\n",
    "                aud = adjust_audio_duration(aud, dur)\n",
    "                phrase_audios.append(aud)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] phrase {i} failed: {e}\")\n",
    "            finally:\n",
    "                if os.path.exists(tmp):\n",
    "                    os.remove(tmp)\n",
    "\n",
    "        # assemble with pre & post silence\n",
    "        seg_audio = AudioSegment.silent(duration=pre_ms)\n",
    "        for aud in phrase_audios:\n",
    "            seg_audio += aud\n",
    "        seg_audio += AudioSegment.silent(duration=post_ms)\n",
    "\n",
    "        # trim/pad to exactly total_ms\n",
    "        seg_audio = seg_audio[:total_ms]\n",
    "\n",
    "        # if needed, apply global speed adjustment\n",
    "        gen_dur = seg_audio.duration_seconds\n",
    "        diff = seg_dur - gen_dur\n",
    "        if abs(diff) > offset_threshold:\n",
    "            factor = seg_dur / gen_dur\n",
    "            seg_audio = change_playback_speed(seg_audio, factor)\n",
    "\n",
    "        # place at the correct start in the combined track\n",
    "        start_ms = int(start_s * 1000)\n",
    "        if len(combined_audio) < start_ms:\n",
    "            combined_audio += AudioSegment.silent(duration=start_ms - len(combined_audio))\n",
    "        combined_audio += seg_audio\n",
    "\n",
    "        # log\n",
    "        debug_lines.append(\n",
    "            f\"Segment {idx+1} ({start_s:.2f}-{end_s:.2f}s): \"\n",
    "            f\"pre={pre_ms}ms, post={post_ms}ms, speed={rate}, phrases={phrases}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # write debug log & export\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as df:\n",
    "        df.write(\"Translation Debug Log\\n\\n\")\n",
    "        df.writelines(debug_lines)\n",
    "\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "\n",
    "    print(\"Transcribing audio (this may take a while)...\")\n",
    "    # Offload the blocking work to a thread:\n",
    "    language, segments = await asyncio.to_thread(transcribe, audio_path)\n",
    "\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Extracting audio‚Ä¶\")\n",
    "    audio_path = extract_audio()\n",
    "\n",
    "    print(\"Transcribing audio‚Ä¶\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "\n",
    "    print(\"Generating subtitles‚Ä¶\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "\n",
    "    print(\"Generating TTS & merging‚Ä¶\")\n",
    "    # <-- no args here\n",
    "    asyncio.run(async_main())\n",
    "\n",
    "    print(f\"Done! Output is {output_video}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be21aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8fea592",
   "metadata": {},
   "source": [
    "TESTING SSML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c856f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSML to be synthesized:\n",
      " <?xml version=\"1.0\" encoding=\"UTF-8\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"120%\">Bonjour, comment allez-vous?</prosody><break time=\"300ms\"/><prosody rate=\"+0%\">Je suis ravi de vous voir.</prosody></speak>\n",
      "SSML synthesis complete. Check the output file: test_ssml_output.mp3\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import edge_tts\n",
    "\n",
    "async def test_ssml():\n",
    "    # Create a well-formed SSML string.\n",
    "    ssml_text = (\n",
    "        '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n",
    "        '<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\">'\n",
    "        '<prosody rate=\"120%\">Bonjour, comment allez-vous?</prosody>'\n",
    "        '<break time=\"300ms\"/>'\n",
    "        '<prosody rate=\"+0%\">Je suis ravi de vous voir.</prosody>'\n",
    "        '</speak>'\n",
    "    )\n",
    "    output_file = \"test_ssml_output.mp3\"\n",
    "    print(\"SSML to be synthesized:\\n\", ssml_text)\n",
    "    \n",
    "    # Create the Communicate object with the SSML text.\n",
    "    communicate = edge_tts.Communicate(text=ssml_text, voice=\"fr-FR-DeniseNeural\")\n",
    "    \n",
    "    # Call save() without any ssml parameter.\n",
    "    await communicate.save(output_file)\n",
    "    print(f\"SSML synthesis complete. Check the output file: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(test_ssml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5be3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1086d6d3",
   "metadata": {},
   "source": [
    "WITH WORDS PAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada634b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f4d98cf",
   "metadata": {},
   "source": [
    "4.2.3_La cr√©ation de rapports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db12b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n",
      "Detected language: en\n",
      "Generating English subtitles...\n",
      "Generating French audio with synchronization and manual overrides...\n",
      "Review file created at: 4.2.3_La cr√©ation de rapports_run_20250415_181829\\translation_review.txt\n",
      "Please review and update the final translations as needed.\n",
      "Parsed review file overrides:\n",
      "  Segment 1 final translation: Dans cette d√©mo, nous explorerons comment cr√©er un rapport de d√©penses par entit√© couvrant diff√©rents sc√©narios pendant plusieurs ann√©es.\n",
      "  Segment 2 final translation: Comment cr√©er un r√©sum√© des d√©penses pour toutes les unit√©s commerciales d'une organisation avec diff√©rentes mesures contre les sc√©narios et l'exercice.\n",
      "  Segment 3 final translation: Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par des entit√©s.\n",
      "  Segment 4 final translation: Comment modifier un rapport et ajouter une nouvelle dimension de pr√©sentation de donn√©es.\n",
      "  Segment 5 final translation: De plus, nous explorerons les rapports narratifs qui sont un outil de reporting extraordinaire avec un r√©cit et une gouvernance utilis√©s pour les processus de soumission budg√©taire annuels, trimestriels ou mensuels entre les diff√©rents d√©partements et en cr√©ant un rapport de d√©penses par une entit√© couvrant diff√©rents sc√©narios pendant plusieurs ann√©es.\n",
      "  Segment 6 final translation: √Ä partir de la page d'accueil, cliquez sur la carte de rapports en haut √† droite.\n",
      "  Segment 7 final translation: En cliquant sur le rapport, ouvrira une grille de rapports, nous avons vu les propri√©t√©s de la grille de rapport.\n",
      "  Segment 8 final translation: En cliquant sur l'ic√¥ne du crayon sur la grille, ouvrira une puissance, je vais s√©lectionner EPBCS OEPFS.\n",
      "  Segment 9 final translation: Et c'est la s√©lection de la grille o√π nous devons s√©lectionner pour chaque dimension et nous pouvons aligner chaque dimension en cliquant sur la disposition de la dimension.\n",
      "  Segment 10 final translation: Cliquez sur ceci nous permettra de d√©placer les dimensions de POV aux colonnes et vous verrez les options pour s√©lectionner diff√©rents nombres pour cette dimension particuli√®re.\n",
      "  Segment 11 final translation: J'ai cr√©√© plusieurs colonnes dans une grille.\n",
      "  Segment 12 final translation: Je peux voir diff√©rentes options.\n",
      "  Segment 13 final translation: Vous pouvez voir que cliquer sur qui d√©finit son vrai ou faux.\n",
      "  Segment 14 final translation: C'est pour les colonnes, c'est pour la ligne, je peux voir les propri√©t√©s de la ligne.\n",
      "  Segment 15 final translation: Si je s√©lectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est √† trier et je peux d√©finir des conditions sur la fa√ßon dont je veux voir les donn√©es.\n",
      "  Segment 16 final translation: Je peux ajouter des suppressions si je souhaite supprimer des donn√©es et vous pouvez voir comment nous avons les colonnes et en fonction de la mise en forme conditionnelle, nous avons les donn√©es affich√©es.\n",
      "  Segment 17 final translation: Nous avons √©galement la possibilit√© d'√©largir les donn√©es au niveau de la p√©riode et nous pouvons analyser et voir les donn√©es.\n",
      "  Segment 18 final translation: Ainsi, comment cr√©er un rapport de r√©sum√© pour les d√©penses en cliquant sur la carte de rapports dans toute la page.\n",
      "  Segment 19 final translation: En cliquant sur l'ic√¥ne Cr√©er un rapport, je voudrais donner un nom √† ce rapport.\n",
      "  Segment 20 final translation: Je pense donc qu'une zone de texte vous permettra d'ajouter comme des en-t√™tes de texte suppl√©mentaires.\n",
      "  Segment 21 final translation: Nous pouvons avoir des pieds de page.\n",
      "  Segment 22 final translation: Nous avons des fonctions sur ce que nous voulons voir.\n",
      "  Segment 23 final translation: Nous pouvons dire signaler une description et je vais ajouter une description et si je clique juste, j'ai fait les s√©lections sur la grille et nous pouvons faire des s√©lections suppl√©mentaires en allant √† cela actuellement, nous avons des d√©penses totales, le num√©ro inf√©rieur des enfants, des descendants, des parents et nous cr√©erons une invite.\n",
      "  Segment 24 final translation: Lorsque nous ex√©cutons, nous obtiendrons une fen√™tre contextuelle, nous pouvons √©galement pr√©-supporter les options en fonction du num√©ro r√©cent et nous pouvons s√©lectionner les variables de substitution.\n",
      "  Segment 25 final translation: Tout le niveau r√©capitulatif se d√©veloppe et s'il est √©tendu, nous devrions pouvoir voir et explorer le niveau inf√©rieur et nous pouvons √©galement percer le niveau de l'entit√© et nous explorerons un peu le formatage conditionnel.\n",
      "  Segment 26 final translation: Je vais aller au formatage conditionnel et je vais s√©lectionner cela.\n",
      "  Segment 27 final translation: Ainsi, le format, si la valeur est sup√©rieure √† celle-ci, elle devrait mettre en √©vidence en rouge.\n",
      "  Segment 28 final translation: De m√™me, si la valeur est inf√©rieure √† 30 000, elle doit √™tre mise en √©vidence en vert.\n",
      "  Segment 29 final translation: Nous devrions √™tre en mesure de voir l'en-t√™te que nous avons ajout√© et nous devrions √™tre en mesure de voir du niveau de r√©sum√© au niveau inf√©rieur.\n",
      "  Segment 30 final translation: Les deux nous avons une fonctionnalit√© vraiment cool pour g√©n√©rer du texte bas√© sur l'IA.\n",
      "  Segment 31 final translation: J'ai r√©gl√© un formatage conditionnel que si la cellule contient moins de moins de 40 000, cela devrait me donner des descriptions g√©n√©r√©es par AI.\n",
      "  Segment 32 final translation: Mettez √† jour cette condition pour dire que toute information ci-dessous moins 51 000 doit √™tre affich√©e.\n",
      "  Segment 33 final translation: Ainsi, vous pouvez voir toutes les donn√©es uniquement moins 216 000 se situent dans cette plage et nous pouvons voir le texte g√©n√©r√©.\n",
      "  Segment 34 final translation: Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par entit√©.\n",
      "  Segment 35 final translation: Alors maintenant, au lieu de cr√©er un rapport, je vais cr√©er une copie d'un rapport existant et cliquer sur OKE, je vais modifier ce rapport.\n",
      "  Segment 36 final translation: Je vais cr√©er une ligne de donn√©es et ce sont nos d√©tails de d√©penses.\n",
      "  Segment 37 final translation: J'ai mes d√©tails de revenus en vertu du compte de revenus.\n",
      "  Segment 38 final translation: Je peux voir diff√©rentes fonctions et je vais s√©lectionner nos descendants de compte de revenus.\n",
      "  Segment 39 final translation: Et si je clique sur l'ex√©cution, je pourrai d'abord voir le niveau d√©taill√© pour les d√©penses, puis pour les revenus.\n",
      "  Segment 40 final translation: J'ai ajout√© une colonne suppl√©mentaire en ajoutant des commentaires pour la variance entre les pr√©visions et la fonction de revenus et de d√©penses.\n",
      "  Segment 41 final translation: Cela me raconte le d√©tail de la raison pour laquelle nous avons la variance.\n",
      "  Segment 42 final translation: Vous verrez comment modifier un rapport existant et ajouter une nouvelle pr√©sentation de donn√©es.\n",
      "  Segment 43 final translation: Permettez-moi de s√©lectionner ce rapport de d√©penses et pour ajouter une pr√©sentation de donn√©es, j'ajouterai une nouvelle page et je peux voir diverses options.\n",
      "  Segment 44 final translation: Je cliquerai sur Graphic et cela me donnera une grille graphique et je peux modifier.\n",
      "  Segment 45 final translation: Je vais s√©lectionner une grille existante et elle va faire r√©f√©rence √† la grille de d√©penses qui existe d√©j√† et vous pouvez voir comment je peux voir la pr√©sentation des donn√©es et nous avons diff√©rentes options pour s√©lectionner le type de la fa√ßon dont nous voulons voir s'il s'agit d'un graphique √† tarte, allons-y et ex√©cutons cela.\n",
      "  Segment 46 final translation: Une fois le rapport charg√©, nous voyons la grille habituelle et ci-dessous que nous avons le graphique √† tarte que nous venons de cr√©er sur la base des donn√©es du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entit√© et quel est le montant.\n",
      "  Segment 47 final translation: Explorons les rapports narratifs, l'outil EPM d'Oracle utilis√© √† des fins de rapports extraordinaires avec des r√©cits et une gouvernance. Explorons-le.\n",
      "  Segment 48 final translation: J'ai cr√©√© cette carte en ajoutant l'URL de rapport narrative √† l'outil de navigation. Cliquez sur ceci ouvrira l'instance de rapport narrative dans l'instance EPBCS existante et j'irai dans le package de rapports. Je vais ouvrir le rapport avec Montr√©al.\n",
      "  Segment 49 final translation: Une fois que nous ouvrons le rapport, nous serons sur la page du package de rapport. Nous pouvons ajouter des auteurs qui peuvent √©diter ce rapport et ajouter des r√©cits et des explications et une fois qu'ils ont ajout√© les r√©cits, ils peuvent le soumettre pour examen aux examinateurs qui pourraient √™tre un chef de d√©partement ou un manager. Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.\n",
      "  Segment 50 final translation: Nous avons diff√©rentes sections en expansion, nous pouvons voir divers fichiers au sein des sections responsables, qui est l'auteur et s'il y a un tumulte. Je vais cliquer sur l'aper√ßu et c'est un rapport de soumission budg√©taire et comment nous pouvons avoir le signe des ministres et les ministres adjoints. Nous pouvons voir les rapports pour les d√©penses. Nous pouvons √©galement voir l'interface graphique et nous pouvons ajouter des explications pour lesquelles nous voyons ces donn√©es et celles-ci sont entr√©es par les auteurs.\n",
      "  Segment 51 final translation: Nous pouvons avoir plusieurs rapports dans un package de rapport, ils peuvent √©galement acc√©der √† ce rapport depuis Smart. Nous sommes le Montr√©al que nous travaillions et je peux voir exactement les m√™mes dossiers et cliquer dessus. Je peux voir des commentaires suppl√©mentaires. Je peux ajouter des commentaires suppl√©mentaires en v√©rifiant et nous pouvons v√©rifier et t√©l√©charger. Et si je reviens au package du rapport et cliquez sur Aper√ßu, je devrais pouvoir voir le commentaire. J'ai ajout√© des num√©ros mis √† jour. Ces rapports peuvent √™tre utilis√©s pour les soumissions mensuelles trimestriellement et annuellement et je vais ouvrir un rapport PPT et je vais vous montrer comment nous pouvons faire cr√©er les variables. C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport t√©l√©chargez-le comme un PDF et cliquer sur Ex√©cuter enverra imm√©diatement un e-mail √† l'utilisateur respectif.\n",
      "  Segment 52 final translation: J'ai plusieurs e-mails et j'ai la possibilit√© de t√©l√©charger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confront√© ou les visages de r√©vision ont commenc√© les utilisateurs respectifs du groupe recevront des notifications par e-mail. Ils peuvent √©galement voir des notifications sur la page d'accueil. Les messages et cliquer sur cela les am√®neront directement au package de rapport. Nous pouvons √©galement voir la t√¢che √† laquelle l'utilisateur a √©t√© attribu√© et il montre des d√©tails suppl√©mentaires qui est responsable quelle est la date et cliquer sur la t√¢che me montrera exactement ce que je dois faire et o√π. Alors ouvrez ce rapport du PPT. Nous pouvons voir la repr√©sentation visuelle du rapport dans le PPT. Nous avons √©galement les options pour extraire des informations ad hoc et je vais extraire certaines donn√©es. Je veux voir les donn√©es de d√©penses au niveau de l'entit√© et je vais copier ceci et je peux avoir ceci ici sous un smartphone ici et vous pouvez voir comment il dit que les besoins doivent √™tre rafra√Æchis.\n",
      "  Segment 53 final translation: Si je clique sur Refresh, je devrais √™tre en mesure de voir les num√©ros 3474 et tous ces clics sur l'actualisation me donne le num√©ro une fois la face de l'auteur termin√©e et vous pouvez voir comment le visage de l'auteur dit est termin√© et nous pouvons cr√©er une base d'examen. Une ic√¥ne de revue est activ√©e en surbrillance sur la t√¢che permettra √† la section des commentaires d'ajouter des commentaires et de publier et il est livr√© avec le nom qui a fait le commentaire et nous pouvons √©galement joindre des fichiers avec le nom et il pourrait y avoir plusieurs commentaires et discussions. Une fois que la face du signataire est cr√©√©e, nous pouvons voir une ic√¥ne suppl√©mentaire pour le signe et le signataire peut prendre des mesures requises.\n",
      "  Segment 54 final translation: Ils peuvent cliquer sur le point de soumettre et nous pouvons voir ou non approuv√©s, ce qui est entr√©, ce qui signifie que le processus de soumission du budget est compl√®tement approuv√© et ceux-ci peuvent √™tre publi√©s dans diff√©rents d√©partements et qu'ils peuvent avoir une copie finale t√©l√©charg√©e dans leur syst√®me local et ils peuvent consulter comme un PDF une fois sign√© avec tous les commentaires et mises √† jour effectu√©s.\n",
      "  Segment 55 final translation: Nous pouvons √©galement voir les mises √† jour que nous avons faites aux commentaires.\n",
      "[Debug] Segment 1 final translation: Dans cette d√©mo, nous explorerons comment cr√©er un rapport de d√©penses par entit√© couvrant diff√©rents sc√©narios pendant plusieurs ann√©es.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Dans cette d√©mo, nous explorerons comment cr√©er un rapport de d√©penses par entit√© couvrant diff√©rents sc√©narios pendant plusieurs ann√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_0_0.mp3\n",
      "[Debug] Segment 2 final translation: Comment cr√©er un r√©sum√© des d√©penses pour toutes les unit√©s commerciales d'une organisation avec diff√©rentes mesures contre les sc√©narios et l'exercice.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment cr√©er un r√©sum√© des d√©penses pour toutes les unit√©s commerciales d'une organisation avec diff√©rentes mesures contre les sc√©narios et l'exercice.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_1_0.mp3\n",
      "[Debug] Segment 3 final translation: Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par des entit√©s.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par des entit√©s.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par des entit√©s.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3410> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.04 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par des entit√©s.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_2_0.mp3\n",
      "[Debug] Segment 4 final translation: Comment modifier un rapport et ajouter une nouvelle dimension de pr√©sentation de donn√©es.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment modifier un rapport et ajouter une nouvelle dimension de pr√©sentation de donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_3_0.mp3\n",
      "[Debug] Segment 5 final translation: De plus, nous explorerons les rapports narratifs qui sont un outil de reporting extraordinaire avec un r√©cit et une gouvernance utilis√©s pour les processus de soumission budg√©taire annuels, trimestriels ou mensuels entre les diff√©rents d√©partements et en cr√©ant un rapport de d√©penses par une entit√© couvrant diff√©rents sc√©narios pendant plusieurs ann√©es.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'De plus, nous explorerons les rapports narratifs qui sont un outil de reporting extraordinaire avec un r√©cit et une gouvernance utilis√©s pour les processus de soumission budg√©taire annuels, trimestriels ou mensuels entre les diff√©rents d√©partements et en cr√©ant un rapport de d√©penses par une entit√© couvrant diff√©rents sc√©narios pendant plusieurs ann√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_4_0.mp3\n",
      "[Debug] Segment 6 final translation: √Ä partir de la page d'accueil, cliquez sur la carte de rapports en haut √† droite.\n",
      "[Debug] Attempt 1: Synthesizing phrase: '√Ä partir de la page d'accueil, cliquez sur la carte de rapports en haut √† droite.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_5_0.mp3\n",
      "[Debug] Segment 7 final translation: En cliquant sur le rapport, ouvrira une grille de rapports, nous avons vu les propri√©t√©s de la grille de rapport.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En cliquant sur le rapport, ouvrira une grille de rapports, nous avons vu les propri√©t√©s de la grille de rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_6_0.mp3\n",
      "[Debug] Segment 8 final translation: En cliquant sur l'ic√¥ne du crayon sur la grille, ouvrira une puissance, je vais s√©lectionner EPBCS OEPFS.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En cliquant sur l'ic√¥ne du crayon sur la grille, ouvrira une puissance, je vais s√©lectionner EPBCS OEPFS.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_7_0.mp3\n",
      "[Debug] Segment 9 final translation: Et c'est la s√©lection de la grille o√π nous devons s√©lectionner pour chaque dimension et nous pouvons aligner chaque dimension en cliquant sur la disposition de la dimension.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et c'est la s√©lection de la grille o√π nous devons s√©lectionner pour chaque dimension et nous pouvons aligner chaque dimension en cliquant sur la disposition de la dimension.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_8_0.mp3\n",
      "[Debug] Segment 10 final translation: Cliquez sur ceci nous permettra de d√©placer les dimensions de POV aux colonnes et vous verrez les options pour s√©lectionner diff√©rents nombres pour cette dimension particuli√®re.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cliquez sur ceci nous permettra de d√©placer les dimensions de POV aux colonnes et vous verrez les options pour s√©lectionner diff√©rents nombres pour cette dimension particuli√®re.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Cliquez sur ceci nous permettra de d√©placer les dimensions de POV aux colonnes et vous verrez les options pour s√©lectionner diff√©rents nombres pour cette dimension particuli√®re.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3C80> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.69 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Cliquez sur ceci nous permettra de d√©placer les dimensions de POV aux colonnes et vous verrez les options pour s√©lectionner diff√©rents nombres pour cette dimension particuli√®re.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_9_0.mp3\n",
      "[Debug] Segment 11 final translation: J'ai cr√©√© plusieurs colonnes dans une grille.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai cr√©√© plusieurs colonnes dans une grille.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_10_0.mp3\n",
      "[Debug] Segment 12 final translation: Je peux voir diff√©rentes options.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux voir diff√©rentes options.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je peux voir diff√©rentes options.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB3C050> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.44 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Je peux voir diff√©rentes options.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Je peux voir diff√©rentes options.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB3C320> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.20 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Je peux voir diff√©rentes options.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_11_0.mp3\n",
      "[Debug] Segment 13 final translation: Vous pouvez voir que cliquer sur qui d√©finit son vrai ou faux.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous pouvez voir que cliquer sur qui d√©finit son vrai ou faux.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_12_0.mp3\n",
      "[Debug] Segment 14 final translation: C'est pour les colonnes, c'est pour la ligne, je peux voir les propri√©t√©s de la ligne.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propri√©t√©s de la ligne.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propri√©t√©s de la ligne.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3800> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.45 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propri√©t√©s de la ligne.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propri√©t√©s de la ligne.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA39B0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.16 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'C'est pour les colonnes, c'est pour la ligne, je peux voir les propri√©t√©s de la ligne.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_13_0.mp3\n",
      "[Debug] Segment 15 final translation: Si je s√©lectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est √† trier et je peux d√©finir des conditions sur la fa√ßon dont je veux voir les donn√©es.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Si je s√©lectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est √† trier et je peux d√©finir des conditions sur la fa√ßon dont je veux voir les donn√©es.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Si je s√©lectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est √† trier et je peux d√©finir des conditions sur la fa√ßon dont je veux voir les donn√©es.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3DA0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.07 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Si je s√©lectionne une cellule, je peux modifier n'importe quelle cellule et apporter des modifications et c'est √† trier et je peux d√©finir des conditions sur la fa√ßon dont je veux voir les donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_14_0.mp3\n",
      "[Debug] Segment 16 final translation: Je peux ajouter des suppressions si je souhaite supprimer des donn√©es et vous pouvez voir comment nous avons les colonnes et en fonction de la mise en forme conditionnelle, nous avons les donn√©es affich√©es.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux ajouter des suppressions si je souhaite supprimer des donn√©es et vous pouvez voir comment nous avons les colonnes et en fonction de la mise en forme conditionnelle, nous avons les donn√©es affich√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_15_0.mp3\n",
      "[Debug] Segment 17 final translation: Nous avons √©galement la possibilit√© d'√©largir les donn√©es au niveau de la p√©riode et nous pouvons analyser et voir les donn√©es.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons √©galement la possibilit√© d'√©largir les donn√©es au niveau de la p√©riode et nous pouvons analyser et voir les donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_16_0.mp3\n",
      "[Debug] Segment 18 final translation: Ainsi, comment cr√©er un rapport de r√©sum√© pour les d√©penses en cliquant sur la carte de rapports dans toute la page.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, comment cr√©er un rapport de r√©sum√© pour les d√©penses en cliquant sur la carte de rapports dans toute la page.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_17_0.mp3\n",
      "[Debug] Segment 19 final translation: En cliquant sur l'ic√¥ne Cr√©er un rapport, je voudrais donner un nom √† ce rapport.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'En cliquant sur l'ic√¥ne Cr√©er un rapport, je voudrais donner un nom √† ce rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_18_0.mp3\n",
      "[Debug] Segment 20 final translation: Je pense donc qu'une zone de texte vous permettra d'ajouter comme des en-t√™tes de texte suppl√©mentaires.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je pense donc qu'une zone de texte vous permettra d'ajouter comme des en-t√™tes de texte suppl√©mentaires.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_19_0.mp3\n",
      "[Debug] Segment 21 final translation: Nous pouvons avoir des pieds de page.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons avoir des pieds de page.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons avoir des pieds de page.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA35C0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.95 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous pouvons avoir des pieds de page.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_20_0.mp3\n",
      "[Debug] Segment 22 final translation: Nous avons des fonctions sur ce que nous voulons voir.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons des fonctions sur ce que nous voulons voir.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous avons des fonctions sur ce que nous voulons voir.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3800> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.69 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous avons des fonctions sur ce que nous voulons voir.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_21_0.mp3\n",
      "[Debug] Segment 23 final translation: Nous pouvons dire signaler une description et je vais ajouter une description et si je clique juste, j'ai fait les s√©lections sur la grille et nous pouvons faire des s√©lections suppl√©mentaires en allant √† cela actuellement, nous avons des d√©penses totales, le num√©ro inf√©rieur des enfants, des descendants, des parents et nous cr√©erons une invite.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons dire signaler une description et je vais ajouter une description et si je clique juste, j'ai fait les s√©lections sur la grille et nous pouvons faire des s√©lections suppl√©mentaires en allant √† cela actuellement, nous avons des d√©penses totales, le num√©ro inf√©rieur des enfants, des descendants, des parents et nous cr√©erons une invite.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_22_0.mp3\n",
      "[Debug] Segment 24 final translation: Lorsque nous ex√©cutons, nous obtiendrons une fen√™tre contextuelle, nous pouvons √©galement pr√©-supporter les options en fonction du num√©ro r√©cent et nous pouvons s√©lectionner les variables de substitution.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Lorsque nous ex√©cutons, nous obtiendrons une fen√™tre contextuelle, nous pouvons √©galement pr√©-supporter les options en fonction du num√©ro r√©cent et nous pouvons s√©lectionner les variables de substitution.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_23_0.mp3\n",
      "[Debug] Segment 25 final translation: Tout le niveau r√©capitulatif se d√©veloppe et s'il est √©tendu, nous devrions pouvoir voir et explorer le niveau inf√©rieur et nous pouvons √©galement percer le niveau de l'entit√© et nous explorerons un peu le formatage conditionnel.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Tout le niveau r√©capitulatif se d√©veloppe et s'il est √©tendu, nous devrions pouvoir voir et explorer le niveau inf√©rieur et nous pouvons √©galement percer le niveau de l'entit√© et nous explorerons un peu le formatage conditionnel.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_24_0.mp3\n",
      "[Debug] Segment 26 final translation: Je vais aller au formatage conditionnel et je vais s√©lectionner cela.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais aller au formatage conditionnel et je vais s√©lectionner cela.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_25_0.mp3\n",
      "[Debug] Segment 27 final translation: Ainsi, le format, si la valeur est sup√©rieure √† celle-ci, elle devrait mettre en √©vidence en rouge.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, le format, si la valeur est sup√©rieure √† celle-ci, elle devrait mettre en √©vidence en rouge.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_26_0.mp3\n",
      "[Debug] Segment 28 final translation: De m√™me, si la valeur est inf√©rieure √† 30 000, elle doit √™tre mise en √©vidence en vert.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'De m√™me, si la valeur est inf√©rieure √† 30 000, elle doit √™tre mise en √©vidence en vert.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_27_0.mp3\n",
      "[Debug] Segment 29 final translation: Nous devrions √™tre en mesure de voir l'en-t√™te que nous avons ajout√© et nous devrions √™tre en mesure de voir du niveau de r√©sum√© au niveau inf√©rieur.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous devrions √™tre en mesure de voir l'en-t√™te que nous avons ajout√© et nous devrions √™tre en mesure de voir du niveau de r√©sum√© au niveau inf√©rieur.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous devrions √™tre en mesure de voir l'en-t√™te que nous avons ajout√© et nous devrions √™tre en mesure de voir du niveau de r√©sum√© au niveau inf√©rieur.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3530> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.82 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Nous devrions √™tre en mesure de voir l'en-t√™te que nous avons ajout√© et nous devrions √™tre en mesure de voir du niveau de r√©sum√© au niveau inf√©rieur.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Nous devrions √™tre en mesure de voir l'en-t√™te que nous avons ajout√© et nous devrions √™tre en mesure de voir du niveau de r√©sum√© au niveau inf√©rieur.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3BF0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.10 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Nous devrions √™tre en mesure de voir l'en-t√™te que nous avons ajout√© et nous devrions √™tre en mesure de voir du niveau de r√©sum√© au niveau inf√©rieur.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_28_0.mp3\n",
      "[Debug] Segment 30 final translation: Les deux nous avons une fonctionnalit√© vraiment cool pour g√©n√©rer du texte bas√© sur l'IA.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les deux nous avons une fonctionnalit√© vraiment cool pour g√©n√©rer du texte bas√© sur l'IA.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_29_0.mp3\n",
      "[Debug] Segment 31 final translation: J'ai r√©gl√© un formatage conditionnel que si la cellule contient moins de moins de 40 000, cela devrait me donner des descriptions g√©n√©r√©es par AI.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai r√©gl√© un formatage conditionnel que si la cellule contient moins de moins de 40 000, cela devrait me donner des descriptions g√©n√©r√©es par AI.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_30_0.mp3\n",
      "[Debug] Segment 32 final translation: Mettez √† jour cette condition pour dire que toute information ci-dessous moins 51 000 doit √™tre affich√©e.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Mettez √† jour cette condition pour dire que toute information ci-dessous moins 51 000 doit √™tre affich√©e.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_31_0.mp3\n",
      "[Debug] Segment 33 final translation: Ainsi, vous pouvez voir toutes les donn√©es uniquement moins 216 000 se situent dans cette plage et nous pouvons voir le texte g√©n√©r√©.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ainsi, vous pouvez voir toutes les donn√©es uniquement moins 216 000 se situent dans cette plage et nous pouvons voir le texte g√©n√©r√©.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_32_0.mp3\n",
      "[Debug] Segment 34 final translation: Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par entit√©.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Comment cr√©er un rapport avec des sections de revenus et de d√©penses regroup√©es par entit√©.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_33_0.mp3\n",
      "[Debug] Segment 35 final translation: Alors maintenant, au lieu de cr√©er un rapport, je vais cr√©er une copie d'un rapport existant et cliquer sur OKE, je vais modifier ce rapport.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Alors maintenant, au lieu de cr√©er un rapport, je vais cr√©er une copie d'un rapport existant et cliquer sur OKE, je vais modifier ce rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_34_0.mp3\n",
      "[Debug] Segment 36 final translation: Je vais cr√©er une ligne de donn√©es et ce sont nos d√©tails de d√©penses.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cr√©er une ligne de donn√©es et ce sont nos d√©tails de d√©penses.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_35_0.mp3\n",
      "[Debug] Segment 37 final translation: J'ai mes d√©tails de revenus en vertu du compte de revenus.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai mes d√©tails de revenus en vertu du compte de revenus.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai mes d√©tails de revenus en vertu du compte de revenus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA31D0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.16 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai mes d√©tails de revenus en vertu du compte de revenus.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'J'ai mes d√©tails de revenus en vertu du compte de revenus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3EC0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.61 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'J'ai mes d√©tails de revenus en vertu du compte de revenus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_36_0.mp3\n",
      "[Debug] Segment 38 final translation: Je peux voir diff√©rentes fonctions et je vais s√©lectionner nos descendants de compte de revenus.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux voir diff√©rentes fonctions et je vais s√©lectionner nos descendants de compte de revenus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_37_0.mp3\n",
      "[Debug] Segment 39 final translation: Et si je clique sur l'ex√©cution, je pourrai d'abord voir le niveau d√©taill√© pour les d√©penses, puis pour les revenus.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et si je clique sur l'ex√©cution, je pourrai d'abord voir le niveau d√©taill√© pour les d√©penses, puis pour les revenus.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Et si je clique sur l'ex√©cution, je pourrai d'abord voir le niveau d√©taill√© pour les d√©penses, puis pour les revenus.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA39B0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.03 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Et si je clique sur l'ex√©cution, je pourrai d'abord voir le niveau d√©taill√© pour les d√©penses, puis pour les revenus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_38_0.mp3\n",
      "[Debug] Segment 40 final translation: J'ai ajout√© une colonne suppl√©mentaire en ajoutant des commentaires pour la variance entre les pr√©visions et la fonction de revenus et de d√©penses.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai ajout√© une colonne suppl√©mentaire en ajoutant des commentaires pour la variance entre les pr√©visions et la fonction de revenus et de d√©penses.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_39_0.mp3\n",
      "[Debug] Segment 41 final translation: Cela me raconte le d√©tail de la raison pour laquelle nous avons la variance.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cela me raconte le d√©tail de la raison pour laquelle nous avons la variance.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_40_0.mp3\n",
      "[Debug] Segment 42 final translation: Vous verrez comment modifier un rapport existant et ajouter une nouvelle pr√©sentation de donn√©es.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Vous verrez comment modifier un rapport existant et ajouter une nouvelle pr√©sentation de donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_41_0.mp3\n",
      "[Debug] Segment 43 final translation: Permettez-moi de s√©lectionner ce rapport de d√©penses et pour ajouter une pr√©sentation de donn√©es, j'ajouterai une nouvelle page et je peux voir diverses options.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Permettez-moi de s√©lectionner ce rapport de d√©penses et pour ajouter une pr√©sentation de donn√©es, j'ajouterai une nouvelle page et je peux voir diverses options.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_42_0.mp3\n",
      "[Debug] Segment 44 final translation: Je cliquerai sur Graphic et cela me donnera une grille graphique et je peux modifier.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je cliquerai sur Graphic et cela me donnera une grille graphique et je peux modifier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_43_0.mp3\n",
      "[Debug] Segment 45 final translation: Je vais s√©lectionner une grille existante et elle va faire r√©f√©rence √† la grille de d√©penses qui existe d√©j√† et vous pouvez voir comment je peux voir la pr√©sentation des donn√©es et nous avons diff√©rentes options pour s√©lectionner le type de la fa√ßon dont nous voulons voir s'il s'agit d'un graphique √† tarte, allons-y et ex√©cutons cela.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais s√©lectionner une grille existante et elle va faire r√©f√©rence √† la grille de d√©penses qui existe d√©j√† et vous pouvez voir comment je peux voir la pr√©sentation des donn√©es et nous avons diff√©rentes options pour s√©lectionner le type de la fa√ßon dont nous voulons voir s'il s'agit d'un graphique √† tarte, allons-y et ex√©cutons cela.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_44_0.mp3\n",
      "[Debug] Segment 46 final translation: Une fois le rapport charg√©, nous voyons la grille habituelle et ci-dessous que nous avons le graphique √† tarte que nous venons de cr√©er sur la base des donn√©es du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entit√© et quel est le montant.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois le rapport charg√©, nous voyons la grille habituelle et ci-dessous que nous avons le graphique √† tarte que nous venons de cr√©er sur la base des donn√©es du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entit√© et quel est le montant.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois le rapport charg√©, nous voyons la grille habituelle et ci-dessous que nous avons le graphique √† tarte que nous venons de cr√©er sur la base des donn√©es du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entit√© et quel est le montant.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3380> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.32 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois le rapport charg√©, nous voyons la grille habituelle et ci-dessous que nous avons le graphique √† tarte que nous venons de cr√©er sur la base des donn√©es du rapport et de cliquer sur la grille et de nous montrer plus d'informations sur le compte et l'entit√© et quel est le montant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_45_0.mp3\n",
      "[Debug] Segment 47 final translation: Explorons les rapports narratifs, l'outil EPM d'Oracle utilis√© √† des fins de rapports extraordinaires avec des r√©cits et une gouvernance. Explorons-le.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Explorons les rapports narratifs, l'outil EPM d'Oracle utilis√© √† des fins de rapports extraordinaires avec des r√©cits et une gouvernance.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Explorons les rapports narratifs, l'outil EPM d'Oracle utilis√© √† des fins de rapports extraordinaires avec des r√©cits et une gouvernance.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA05F0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.33 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Explorons les rapports narratifs, l'outil EPM d'Oracle utilis√© √† des fins de rapports extraordinaires avec des r√©cits et une gouvernance.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_46_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Explorons-le.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_46_1.mp3\n",
      "[Debug] Segment 48 final translation: J'ai cr√©√© cette carte en ajoutant l'URL de rapport narrative √† l'outil de navigation. Cliquez sur ceci ouvrira l'instance de rapport narrative dans l'instance EPBCS existante et j'irai dans le package de rapports. Je vais ouvrir le rapport avec Montr√©al.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai cr√©√© cette carte en ajoutant l'URL de rapport narrative √† l'outil de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_47_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Cliquez sur ceci ouvrira l'instance de rapport narrative dans l'instance EPBCS existante et j'irai dans le package de rapports.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_47_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais ouvrir le rapport avec Montr√©al.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_47_2.mp3\n",
      "[Debug] Segment 49 final translation: Une fois que nous ouvrons le rapport, nous serons sur la page du package de rapport. Nous pouvons ajouter des auteurs qui peuvent √©diter ce rapport et ajouter des r√©cits et des explications et une fois qu'ils ont ajout√© les r√©cits, ils peuvent le soumettre pour examen aux examinateurs qui pourraient √™tre un chef de d√©partement ou un manager. Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que nous ouvrons le rapport, nous serons sur la page du package de rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_48_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons ajouter des auteurs qui peuvent √©diter ce rapport et ajouter des r√©cits et des explications et une fois qu'ils ont ajout√© les r√©cits, ils peuvent le soumettre pour examen aux examinateurs qui pourraient √™tre un chef de d√©partement ou un manager.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_48_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA39B0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.92 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3650> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.77 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Error] Attempt 3/5 failed for phrase: 'Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3F50> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 4.50 seconds...\n",
      "[Debug] Attempt 4: Synthesizing phrase: 'Une fois que le r√©viseur a termin√© l'examen, il peut soumettre le rapport √† un signataire qui pourrait √™tre un ministre pour obtenir un dernier signe d'approbation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_48_2.mp3\n",
      "[Debug] Segment 50 final translation: Nous avons diff√©rentes sections en expansion, nous pouvons voir divers fichiers au sein des sections responsables, qui est l'auteur et s'il y a un tumulte. Je vais cliquer sur l'aper√ßu et c'est un rapport de soumission budg√©taire et comment nous pouvons avoir le signe des ministres et les ministres adjoints. Nous pouvons voir les rapports pour les d√©penses. Nous pouvons √©galement voir l'interface graphique et nous pouvons ajouter des explications pour lesquelles nous voyons ces donn√©es et celles-ci sont entr√©es par les auteurs.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons diff√©rentes sections en expansion, nous pouvons voir divers fichiers au sein des sections responsables, qui est l'auteur et s'il y a un tumulte.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je vais cliquer sur l'aper√ßu et c'est un rapport de soumission budg√©taire et comment nous pouvons avoir le signe des ministres et les ministres adjoints.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons voir les rapports pour les d√©penses.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement voir l'interface graphique et nous pouvons ajouter des explications pour lesquelles nous voyons ces donn√©es et celles-ci sont entr√©es par les auteurs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_49_3.mp3\n",
      "[Debug] Segment 51 final translation: Nous pouvons avoir plusieurs rapports dans un package de rapport, ils peuvent √©galement acc√©der √† ce rapport depuis Smart. Nous sommes le Montr√©al que nous travaillions et je peux voir exactement les m√™mes dossiers et cliquer dessus. Je peux voir des commentaires suppl√©mentaires. Je peux ajouter des commentaires suppl√©mentaires en v√©rifiant et nous pouvons v√©rifier et t√©l√©charger. Et si je reviens au package du rapport et cliquez sur Aper√ßu, je devrais pouvoir voir le commentaire. J'ai ajout√© des num√©ros mis √† jour. Ces rapports peuvent √™tre utilis√©s pour les soumissions mensuelles trimestriellement et annuellement et je vais ouvrir un rapport PPT et je vais vous montrer comment nous pouvons faire cr√©er les variables. C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport t√©l√©chargez-le comme un PDF et cliquer sur Ex√©cuter enverra imm√©diatement un e-mail √† l'utilisateur respectif.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons avoir plusieurs rapports dans un package de rapport, ils peuvent √©galement acc√©der √† ce rapport depuis Smart.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous sommes le Montr√©al que nous travaillions et je peux voir exactement les m√™mes dossiers et cliquer dessus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux voir des commentaires suppl√©mentaires.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je peux ajouter des commentaires suppl√©mentaires en v√©rifiant et nous pouvons v√©rifier et t√©l√©charger.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Et si je reviens au package du rapport et cliquez sur Aper√ßu, je devrais pouvoir voir le commentaire.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai ajout√© des num√©ros mis √† jour.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai ajout√© des num√©ros mis √† jour.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB44200> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.70 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai ajout√© des num√©ros mis √† jour.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ces rapports peuvent √™tre utilis√©s pour les soumissions mensuelles trimestriellement et annuellement et je vais ouvrir un rapport PPT et je vais vous montrer comment nous pouvons faire cr√©er les variables.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport t√©l√©chargez-le comme un PDF et cliquer sur Ex√©cuter enverra imm√©diatement un e-mail √† l'utilisateur respectif.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport t√©l√©chargez-le comme un PDF et cliquer sur Ex√©cuter enverra imm√©diatement un e-mail √† l'utilisateur respectif.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA3C80> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.77 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'C'est si nous voulons envoyer ce rapport, nous devons simplement affecter un groupe ou un utilisateur et qu'ils pourront afficher ce rapport t√©l√©chargez-le comme un PDF et cliquer sur Ex√©cuter enverra imm√©diatement un e-mail √† l'utilisateur respectif.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_50_7.mp3\n",
      "[Debug] Segment 52 final translation: J'ai plusieurs e-mails et j'ai la possibilit√© de t√©l√©charger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confront√© ou les visages de r√©vision ont commenc√© les utilisateurs respectifs du groupe recevront des notifications par e-mail. Ils peuvent √©galement voir des notifications sur la page d'accueil. Les messages et cliquer sur cela les am√®neront directement au package de rapport. Nous pouvons √©galement voir la t√¢che √† laquelle l'utilisateur a √©t√© attribu√© et il montre des d√©tails suppl√©mentaires qui est responsable quelle est la date et cliquer sur la t√¢che me montrera exactement ce que je dois faire et o√π. Alors ouvrez ce rapport du PPT. Nous pouvons voir la repr√©sentation visuelle du rapport dans le PPT. Nous avons √©galement les options pour extraire des informations ad hoc et je vais extraire certaines donn√©es. Je veux voir les donn√©es de d√©penses au niveau de l'entit√© et je vais copier ceci et je peux avoir ceci ici sous un smartphone ici et vous pouvez voir comment il dit que les besoins doivent √™tre rafra√Æchis.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'J'ai plusieurs e-mails et j'ai la possibilit√© de t√©l√©charger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confront√© ou les visages de r√©vision ont commenc√© les utilisateurs respectifs du groupe recevront des notifications par e-mail.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'J'ai plusieurs e-mails et j'ai la possibilit√© de t√©l√©charger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confront√© ou les visages de r√©vision ont commenc√© les utilisateurs respectifs du groupe recevront des notifications par e-mail.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA31D0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.88 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'J'ai plusieurs e-mails et j'ai la possibilit√© de t√©l√©charger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confront√© ou les visages de r√©vision ont commenc√© les utilisateurs respectifs du groupe recevront des notifications par e-mail.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'J'ai plusieurs e-mails et j'ai la possibilit√© de t√©l√©charger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confront√© ou les visages de r√©vision ont commenc√© les utilisateurs respectifs du groupe recevront des notifications par e-mail.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAAA32F0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.91 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase: 'J'ai plusieurs e-mails et j'ai la possibilit√© de t√©l√©charger le rapport comme nous venons de le remarquer et chaque fois qu'un auteur est confront√© ou les visages de r√©vision ont commenc√© les utilisateurs respectifs du groupe recevront des notifications par e-mail.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ils peuvent √©galement voir des notifications sur la page d'accueil.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Les messages et cliquer sur cela les am√®neront directement au package de rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_2.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement voir la t√¢che √† laquelle l'utilisateur a √©t√© attribu√© et il montre des d√©tails suppl√©mentaires qui est responsable quelle est la date et cliquer sur la t√¢che me montrera exactement ce que je dois faire et o√π.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_3.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Alors ouvrez ce rapport du PPT.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_4.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons voir la repr√©sentation visuelle du rapport dans le PPT.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_5.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous avons √©galement les options pour extraire des informations ad hoc et je vais extraire certaines donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_6.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Je veux voir les donn√©es de d√©penses au niveau de l'entit√© et je vais copier ceci et je peux avoir ceci ici sous un smartphone ici et vous pouvez voir comment il dit que les besoins doivent √™tre rafra√Æchis.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_51_7.mp3\n",
      "[Debug] Segment 53 final translation: Si je clique sur Refresh, je devrais √™tre en mesure de voir les num√©ros 3474 et tous ces clics sur l'actualisation me donne le num√©ro une fois la face de l'auteur termin√©e et vous pouvez voir comment le visage de l'auteur dit est termin√© et nous pouvons cr√©er une base d'examen. Une ic√¥ne de revue est activ√©e en surbrillance sur la t√¢che permettra √† la section des commentaires d'ajouter des commentaires et de publier et il est livr√© avec le nom qui a fait le commentaire et nous pouvons √©galement joindre des fichiers avec le nom et il pourrait y avoir plusieurs commentaires et discussions. Une fois que la face du signataire est cr√©√©e, nous pouvons voir une ic√¥ne suppl√©mentaire pour le signe et le signataire peut prendre des mesures requises.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Si je clique sur Refresh, je devrais √™tre en mesure de voir les num√©ros 3474 et tous ces clics sur l'actualisation me donne le num√©ro une fois la face de l'auteur termin√©e et vous pouvez voir comment le visage de l'auteur dit est termin√© et nous pouvons cr√©er une base d'examen.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_52_0.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une ic√¥ne de revue est activ√©e en surbrillance sur la t√¢che permettra √† la section des commentaires d'ajouter des commentaires et de publier et il est livr√© avec le nom qui a fait le commentaire et nous pouvons √©galement joindre des fichiers avec le nom et il pourrait y avoir plusieurs commentaires et discussions.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_52_1.mp3\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Une fois que la face du signataire est cr√©√©e, nous pouvons voir une ic√¥ne suppl√©mentaire pour le signe et le signataire peut prendre des mesures requises.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Une fois que la face du signataire est cr√©√©e, nous pouvons voir une ic√¥ne suppl√©mentaire pour le signe et le signataire peut prendre des mesures requises.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x0000016FEAB6C320> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.59 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase: 'Une fois que la face du signataire est cr√©√©e, nous pouvons voir une ic√¥ne suppl√©mentaire pour le signe et le signataire peut prendre des mesures requises.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_52_2.mp3\n",
      "[Debug] Segment 54 final translation: Ils peuvent cliquer sur le point de soumettre et nous pouvons voir ou non approuv√©s, ce qui est entr√©, ce qui signifie que le processus de soumission du budget est compl√®tement approuv√© et ceux-ci peuvent √™tre publi√©s dans diff√©rents d√©partements et qu'ils peuvent avoir une copie finale t√©l√©charg√©e dans leur syst√®me local et ils peuvent consulter comme un PDF une fois sign√© avec tous les commentaires et mises √† jour effectu√©s.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Ils peuvent cliquer sur le point de soumettre et nous pouvons voir ou non approuv√©s, ce qui est entr√©, ce qui signifie que le processus de soumission du budget est compl√®tement approuv√© et ceux-ci peuvent √™tre publi√©s dans diff√©rents d√©partements et qu'ils peuvent avoir une copie finale t√©l√©charg√©e dans leur syst√®me local et ils peuvent consulter comme un PDF une fois sign√© avec tous les commentaires et mises √† jour effectu√©s.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_53_0.mp3\n",
      "[Debug] Segment 55 final translation: Nous pouvons √©galement voir les mises √† jour que nous avons faites aux commentaires.\n",
      "[Debug] Attempt 1: Synthesizing phrase: 'Nous pouvons √©galement voir les mises √† jour que nous avons faites aux commentaires.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_phrase_54_0.mp3\n",
      "‚úÖ Translated audio saved to: 4.2.3_La cr√©ation de rapports_run_20250415_181829\\4.2.3_La cr√©ation de rapports-french.wav\n",
      "üìù Debug log saved to: 4.2.3_La cr√©ation de rapports_run_20250415_181829\\translation_debug_log.txt\n",
      "Merging audio and video...\n",
      "Moviepy - Building video 4.2.3_La cr√©ation de rapports_run_20250415_181829\\4.2.3_La cr√©ation de rapports-french.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video 4.2.3_La cr√©ation de rapports_run_20250415_181829\\4.2.3_La cr√©ation de rapports-french.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 4.2.3_La cr√©ation de rapports_run_20250415_181829\\4.2.3_La cr√©ation de rapports-french.mp4\n",
      "Process completed! Output video: 4.2.3_La cr√©ation de rapports_run_20250415_181829\\4.2.3_La cr√©ation de rapports-french.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.3_La cr√©ation de rapports.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# For this version we rely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Silence Duration:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"----------------------------------------------------------------\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # default ms\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    print(\"Parsed review file overrides:\")\n",
    "    for idx, override in enumerate(segments_overrides, 1):\n",
    "        print(f\"  Segment {idx} final translation: {override['final_translation']}\")\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = re.split(r\"(?<=[.!?])\\s+(?=[A-Z])\", text)\n",
    "    return [phrase.strip() for phrase in phrases if phrase.strip()]\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    if total_fr_words == 0:\n",
    "        return [1 / len(translated_phrases)] * len(translated_phrases)\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    Note: In Edge TTS v7.0.0 the 'session' parameter is not supported.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session for each attempt.\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate\n",
    "                )\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "\n",
    "        print(f\"[Debug] Segment {idx+1} final translation: {final_translation}\")\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Synthesis failed for phrase '{phrase}': {e}. Skipping this phrase.\")\n",
    "                continue\n",
    "            try:\n",
    "                audio = AudioSegment.from_mp3(temp_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Unable to load audio from {temp_path}: {e}. Skipping this phrase.\")\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "                continue\n",
    "            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44 and audio:\n",
    "                try:\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"[Debug] Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        combined_audio += group_audio\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    with open(debug_log_path, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "print(edge_tts.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285235e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "from aiohttp import ClientConnectorError\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.3_La cr√©ation de rapports.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split('---') if blk.strip()]\n",
    "    \n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== Robust TTS Function with Retry and Jitter ==============\n",
    "async def robust_synthesize_phrase(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    connector: aiohttp.TCPConnector,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\",\n",
    "    max_retries: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Synthesize speech for a given phrase using Edge TTS with robust retry logic.\n",
    "    Uses exponential backoff with random jitter to mitigate transient connection issues.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create a new session using the shared persistent connector.\n",
    "            async with aiohttp.ClientSession(connector=connector, timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate,\n",
    "                    connector=connector\n",
    "                )\n",
    "                await communicate.save(output_path)\n",
    "                return\n",
    "        except (ClientConnectorError, ConnectionResetError) as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Connection error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Error on attempt {attempt+1}/{max_retries} for phrase: '{phrase}': {e}. Retrying in {wait_time:.2f} seconds.\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "# ============== TTS Functions Wrapper ==============\n",
    "# For backward compatibility, if you want to call the function by its former name.\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, connector: aiohttp.TCPConnector, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\"):\n",
    "    await robust_synthesize_phrase(phrase, output_path, connector, voice, rate)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Persistent Connector Creation ==============\n",
    "def create_persistent_connector():\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context, limit=10)\n",
    "    return connector\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path, persistent_connector):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    offset_threshold = 0.05\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await robust_synthesize_phrase(\n",
    "                    phrase, temp_path, connector=persistent_connector, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override\n",
    "                )\n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        \n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function (unchanged) ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    persistent_connector = create_persistent_connector()  # Create the persistent connector\n",
    "    try:\n",
    "        print(\"Extracting audio...\")\n",
    "        audio_path = extract_audio()\n",
    "    \n",
    "        print(\"Transcribing audio...\")\n",
    "        language, segments = transcribe(audio_path)\n",
    "    \n",
    "        print(\"Generating English subtitles...\")\n",
    "        generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "        print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "        await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file, persistent_connector)\n",
    "    \n",
    "        print(\"Merging audio and video...\")\n",
    "        merge_audio_video()\n",
    "    \n",
    "        print(f\"Process completed! Output video: {output_video}\")\n",
    "    finally:\n",
    "        await persistent_connector.close()  # Close the persistent connector\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio, datetime\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import tempfile\n",
    "import sys  # Import the sys module\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "subtitle_file_fr = os.path.join(output_dir, f\"{input_video_name}-french.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "\n",
    "# ============== Helper Functions ==============\n",
    "\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    original_texts = []\n",
    "\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            original_texts.append(original_text)\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            final_translation = auto_translated\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {final_translation}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations in the file as needed.\")\n",
    "\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "\n",
    "    return groups, original_texts\n",
    "\n",
    "def parse_final_translations(review_file_path):\n",
    "    final_translations = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    segments = content.strip().split('---')\n",
    "    for seg in segments:\n",
    "        if seg.strip() == \"\" or \"Final Translation:\" not in seg:\n",
    "            continue\n",
    "        match = re.search(r'\\*\\*Final Translation:\\*\\*\\s*(.*)', seg)\n",
    "        if match:\n",
    "            final_translation = match.group(1).strip()\n",
    "            final_translations.append(final_translation)\n",
    "    return final_translations\n",
    "\n",
    "def validate_review_with_retranslation(review_file_path, groups, original_texts, from_lang, to_lang):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "\n",
    "    while True:\n",
    "        current_originals = []\n",
    "        updated_segments = []\n",
    "\n",
    "        with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        segments = content.strip().split('---')\n",
    "        seg_index = 0\n",
    "        for i, seg in enumerate(segments):\n",
    "            if not seg.strip() or \"Segment\" not in seg:\n",
    "                continue\n",
    "\n",
    "            if seg_index < len(original_texts) and \"Original:\" in seg:\n",
    "                original_match = re.search(r'\\*\\*Original:\\*\\*\\s*(.*)', seg)\n",
    "                current_original = original_match.group(1).strip() if original_match else \"\"\n",
    "                current_originals.append(current_original)\n",
    "\n",
    "                if current_original != original_texts[seg_index]:\n",
    "                    updated_segments.append(seg_index)\n",
    "            else:\n",
    "                current_originals.append(\"\")\n",
    "\n",
    "            seg_index += 1\n",
    "\n",
    "        if updated_segments:\n",
    "            print(f\"‚ö†Ô∏è  Detected changes in {len(updated_segments)} original segments. Retranslating...\")\n",
    "            new_content = []\n",
    "            seg_index = 0\n",
    "\n",
    "            for seg in segments:\n",
    "                if not seg.strip() or \"Segment\" not in seg:\n",
    "                    new_content.append(seg)\n",
    "                    continue\n",
    "\n",
    "                if seg_index in updated_segments:\n",
    "                    new_translation = translator.translate(text=current_originals[seg_index])\n",
    "\n",
    "                    seg = re.sub(\n",
    "                        r'(\\*\\*Auto Translated:\\*\\*)(.*?)(\\n\\*\\*Final Translation:\\*\\*)',\n",
    "                        f'\\\\1 {new_translation}\\\\3 {new_translation}',\n",
    "                        seg,\n",
    "                        flags=re.DOTALL\n",
    "                    )\n",
    "\n",
    "                new_content.append(seg)\n",
    "                seg_index += 1\n",
    "\n",
    "            with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write('---'.join(new_content))\n",
    "\n",
    "            print(\"Updated translations written. Please review changes.\")\n",
    "            while True:\n",
    "                user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "                if user_confirmation == \"y\":\n",
    "                    break\n",
    "            original_texts = current_originals\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return parse_final_translations(review_file_path)\n",
    "\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        adjusted_audio = audio + silence\n",
    "        return adjusted_audio\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        adjusted_audio = audio[:-int(trim_duration_ms)]\n",
    "        return adjusted_audio\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "\n",
    "def synthesize_phrase_edge(text, output_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"):\n",
    "    \"\"\"Synthesize the given phrase using edge-tts, using shell=True for Windows compatibility.\"\"\"\n",
    "    command = [\n",
    "        \"edge-tts\",\n",
    "        \"--voice\", voice,\n",
    "        \"--text\", text,\n",
    "        \"--write-media\", output_path,\n",
    "        \"--rate\", rate\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        process = asyncio.create_subprocess_exec(\n",
    "            *command,\n",
    "            stdin=asyncio.subprocess.PIPE,\n",
    "            stdout=asyncio.subprocess.PIPE,\n",
    "            stderr=asyncio.subprocess.PIPE,\n",
    "            shell=True  # Enable shell execution\n",
    "        )\n",
    "\n",
    "        async def run_process():\n",
    "            proc = await process\n",
    "            stdout, stderr = await proc.communicate()\n",
    "\n",
    "            if proc.returncode != 0:\n",
    "                print(f\"Error executing edge-tts: {stderr.decode()}\")\n",
    "            else:\n",
    "                print(f\"Successfully synthesized phrase: {text[:50]}... to {output_path}\")\n",
    "                return output_path\n",
    "\n",
    "        return asyncio.run(run_process())\n",
    "\n",
    "    except NotImplementedError as e:\n",
    "        print(f\"NotImplementedError: {e}. This might be due to asyncio subprocess issues on Windows.\")\n",
    "        print(\"Trying a different approach using os.system (less robust)...\")\n",
    "        \n",
    "        # Fallback to os.system (less robust, but might work on Windows)\n",
    "        command_str = \" \".join(command)\n",
    "        return_code = os.system(command_str)\n",
    "        \n",
    "        if return_code == 0:\n",
    "            print(f\"Successfully synthesized phrase (using os.system): {text[:50]}... to {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            print(f\"Error executing edge-tts (using os.system): Return code {return_code}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "\n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "\n",
    "def generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    groups, original_texts = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    final_translations = validate_review_with_retranslation(review_file_path, groups, original_texts, \"en\", \"fr\")\n",
    "\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "\n",
    "    offset_threshold = 0.05\n",
    "\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = final_translations[idx]\n",
    "\n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "\n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "\n",
    "            audio_file = synthesize_phrase_edge(\n",
    "                phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"\n",
    "            )\n",
    "\n",
    "            if audio_file and os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                try:\n",
    "                    audio = AudioSegment.from_mp3(temp_path)\n",
    "                    audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                    phrase_audios.append(audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Audio corrompu ignor√© : {temp_path}. Erreur: {e}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Fichier manquant ou invalide: {temp_path}\")\n",
    "\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "\n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=100)\n",
    "\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : ajustement de vitesse appliqu√©, facteur={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "\n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "\n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration avant ajustement:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "\n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio = audio + extra_silence\n",
    "    \n",
    "    new_video = video.set_audio(audio)\n",
    "    new_video.write_videofile(output_video, codec=\"libx264\", audio_codec=\"aac\", temp_audiofile='temp-audio.m4a', remove_temp=True)\n",
    "    return output_video\n",
    "\n",
    "\n",
    "# ============== Main Flow ==============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if running on Windows\n",
    "    if os.name == 'nt':\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "    # 1. Extract Audio\n",
    "    print(\"Extracting audio...\")\n",
    "    extracted_audio = extract_audio()\n",
    "\n",
    "    # 2. Transcribe Audio\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, transcript_segments = transcribe(extracted_audio)\n",
    "\n",
    "    # 3. Generate English Subtitle File\n",
    "    print(\"Generating English subtitle file...\")\n",
    "    subtitle_file_en = generate_subtitle_file(transcript_segments, subtitle_file_en)\n",
    "\n",
    "    # 4. Generate Translation Review File\n",
    "    print(\"Generating translation review file...\")\n",
    "    groups, original_texts = generate_translation_review_file(subtitle_file_en, review_file)\n",
    "\n",
    "    # 5. NEW: Validate Review and Retranslate if Originals Changed\n",
    "    print(\"Validating and applying translations from review file...\")\n",
    "    final_translations = validate_review_with_retranslation(\n",
    "        review_file, groups, original_texts, \"en\", \"fr\"\n",
    "    )\n",
    "\n",
    "    # 6. Generate Translated Audio\n",
    "    print(\"Generating translated audio...\")\n",
    "    translated_audio = generate_translated_audio_with_sync_using_review(\n",
    "        subtitle_file_en, translated_audio, debug_log_file, review_file\n",
    "    )\n",
    "\n",
    "    # 7. Merge Audio and Video\n",
    "    print(\"Merging audio and video...\")\n",
    "    output_video = merge_audio_video()\n",
    "\n",
    "    print(f\"‚úÖ Final video saved to: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdadfe",
   "metadata": {},
   "source": [
    "4.2.2_Flux de navigation_Avr_08_Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime   \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.3_La cr√©ation de rapports.mp4\"  # Path to your input video\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]  # e.g. \"4.2.4_Configuration de la solution_Avr_10_Latest\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")            # e.g. \"20250414_173015\"\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"        # Whisper model size (tiny, base, small, medium, large)\n",
    "update_existing = True      # Set to True to allow interactive review/edit of translations\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "subtitle_file_fr = os.path.join(output_dir, f\"{input_video_name}-french.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "\n",
    "# ============== Helper Functions ==============\n",
    "\n",
    "def extract_audio():\n",
    "    \"\"\"Extract audio from video using ffmpeg\"\"\"\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)  # mono and 16kHz\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    \"\"\"Transcribe audio using faster-whisper.\"\"\"\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    \"\"\"Convert seconds to SubRipTime format\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    \"\"\"Generate subtitle file (SRT) from segments.\"\"\"\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    \"\"\"Generate a review file that lists each segment's original and auto translated text.\n",
    "    \n",
    "    The review file is written in a format that allows the user to update the final translation.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    # Group subtitles by sentence using a simple punctuation detection.\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    # Write the review file using the grouping information.\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            # Concatenate original texts.\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            # Auto-translate the concatenated text.\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            # Start with auto translation as the default final translation.\n",
    "            final_translation = auto_translated\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {final_translation}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations in the file as needed.\")\n",
    "    # Wait for user confirmation.\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_final_translations(review_file_path):\n",
    "    \"\"\"Parse the updated review file to extract the final translations for each segment group.\n",
    "    \n",
    "    This function expects that each segment block includes a line starting with \n",
    "    '**Final Translation:**' and returns a list of final translations (in the same order as groups).\n",
    "    \"\"\"\n",
    "    final_translations = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    # Split by segments based on the separator.\n",
    "    segments = content.strip().split('---')\n",
    "    for seg in segments:\n",
    "        if seg.strip() == \"\" or \"Final Translation:\" not in seg:\n",
    "            continue\n",
    "        # Extract the line that starts with '**Final Translation:**'\n",
    "        match = re.search(r'\\*\\*Final Translation:\\*\\*\\s*(.*)', seg)\n",
    "        if match:\n",
    "            final_translation = match.group(1).strip()\n",
    "            final_translations.append(final_translation)\n",
    "    return final_translations\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    \"\"\"Adjust the audio to match the target duration.\n",
    "    \n",
    "    If audio is too short, append silence; if too long, trim the end.\n",
    "    \"\"\"\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:  # Audio too short: add silence.\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        adjusted_audio = audio + silence\n",
    "        return adjusted_audio\n",
    "    elif difference < -0.1:  # Audio too long: trim the end.\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        adjusted_audio = audio[:-int(trim_duration_ms)]\n",
    "        return adjusted_audio\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "\n",
    "# ============== NEW: French Phrase Alignment Functions ==============\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text into phrases using punctuation aware of French grammar.\"\"\"\n",
    "    # Fixed regex pattern with atomic grouping for French abbreviations\n",
    "    sentence_end = re.compile(\n",
    "        r'(?<!\\bM(?:r|me|s|rs|mes))\\s*([.!?])(?:\\s+|$)'\n",
    "    )\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check for sentence-ending punctuation with French context\n",
    "        if sentence_end.search(word):\n",
    "            # Check if next word starts with uppercase (proper sentence end)\n",
    "            if i+1 < len(words) and words[i+1][0].isupper():\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text at natural phrase boundaries for technical content.\"\"\"\n",
    "    # Focus on sentence-ending punctuation followed by uppercase\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check if word ends with sentence punctuation\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            # Check if next word starts with uppercase or we're at the end\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    \n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    \"\"\"Calculate duration allocation weights for French phrases based solely on their word counts.\"\"\"\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    # Compute each weight as the fraction of the total French words\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "\n",
    "# ============== MODIFIED Audio Generat\n",
    "    \n",
    "  \n",
    "import tempfile\n",
    "\n",
    "# ============== MODIFIED Audio Generation Function ==============\n",
    "\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import tempfile\n",
    "import pysrt\n",
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    \"\"\"Version am√©lior√©e avec alignement au niveau des phrases fran√ßaises, d√©tection du d√©calage\n",
    "       et ajustement automatique de la vitesse de lecture pour corriger les √©carts.\"\"\"\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    final_translations = parse_final_translations(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    # Seuil pour d√©tecter un d√©calage notable (en secondes)\n",
    "    offset_threshold = 0.05  # par exemple 50 ms, √† ajuster selon vos tests\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = final_translations[idx]\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            # Utiliser une extension .mp3 car edge-tts produit du MP3\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            \n",
    "            try:\n",
    "                asyncio.run(synthesize_phrase_edge(\n",
    "                    phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"\n",
    "                ))\n",
    "                \n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Audio corrompu ignor√© : {temp_path}. Erreur: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Fichier manquant ou invalide: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=100)\n",
    "        \n",
    "        # Optionnel : on tronque si la dur√©e d√©passe\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        \n",
    "        # V√©rifier si le segment audio g√©n√©r√© colle exactement aux timings attendus\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        # Si l'√©cart est significatif, ajuster la vitesse.\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : ajustement de vitesse appliqu√©, facteur={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration avant ajustement:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "\n",
    "def merge_audio_video():\n",
    "    \"\"\"Merge the newly generated audio with the original video.\"\"\"\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    # If the audio is shorter than video, append silence.\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import edge_tts\n",
    "\n",
    "\n",
    "async def synthesize_phrase_edge(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\"\n",
    "):\n",
    "    communicate = edge_tts.Communicate(\n",
    "        text=phrase,\n",
    "        voice=voice,\n",
    "        rate=rate\n",
    "    )\n",
    "    await communicate.save(output_path)  # Removed format parameter\n",
    "\n",
    "\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    \"\"\"Change la vitesse de lecture de 'sound' par le facteur 'speed'.\"\"\"\n",
    "    # On modifie le frame rate, puis on remet √† la normale pour obtenir le nouveau son.\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Main Flow ==============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Extract audio.\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    \n",
    "    # Step 2: Transcribe audio.\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    \n",
    "    # Step 3: Generate English subtitles.\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "    # (Optional) Step 4: Translate subtitles (if needed for other purposes).\n",
    "    # In our flow, we now use the auto translation during review.\n",
    "    # print(\"Translating subtitles...\")\n",
    "    # translate_subtitles(subtitle_file_en, subtitle_file_fr)\n",
    "    \n",
    "    # Step 5: Generate French audio using the review file.\n",
    "    print(\"Generating French audio with synchronization...\")\n",
    "    generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(f\"Debug log written to: {debug_log_file}\")\n",
    "    \n",
    "    # Step 6: Merge audio and video.\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    \n",
    "    print(f\"Process completed! Output video: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime   \n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.4_Configuration de la solution_Avr_10_Latest.mp4\" \n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]  # e.g. \"4.2.4_Configuration de la solution_Avr_10_Latest\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")            # e.g. \"20250414_173015\"\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"        # Whisper model size (tiny, base, small, medium, large)\n",
    "update_existing = True      # Set to True to allow interactive review/edit of translations\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "subtitle_file_fr = os.path.join(output_dir, f\"{input_video_name}-french.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "\n",
    "# ============== Helper Functions ==============\n",
    "\n",
    "def extract_audio():\n",
    "    \"\"\"Extract audio from video using ffmpeg\"\"\"\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)  # mono and 16kHz\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    \"\"\"Transcribe audio using faster-whisper.\"\"\"\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    \"\"\"Convert seconds to SubRipTime format\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    \"\"\"Generate subtitle file (SRT) from segments.\"\"\"\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    \"\"\"Generate a review file that lists each segment's original and auto translated text.\n",
    "    \n",
    "    The review file is written in a format that allows the user to update the final translation.\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    # Group subtitles by sentence using a simple punctuation detection.\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    # Write the review file using the grouping information.\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            # Concatenate original texts.\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            # Auto-translate the concatenated text.\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            # Start with auto translation as the default final translation.\n",
    "            final_translation = auto_translated\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {final_translation}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations in the file as needed.\")\n",
    "    # Wait for user confirmation.\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_final_translations(review_file_path):\n",
    "    \"\"\"Parse the updated review file to extract the final translations for each segment group.\n",
    "    \n",
    "    This function expects that each segment block includes a line starting with \n",
    "    '**Final Translation:**' and returns a list of final translations (in the same order as groups).\n",
    "    \"\"\"\n",
    "    final_translations = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    # Split by segments based on the separator.\n",
    "    segments = content.strip().split('---')\n",
    "    for seg in segments:\n",
    "        if seg.strip() == \"\" or \"Final Translation:\" not in seg:\n",
    "            continue\n",
    "        # Extract the line that starts with '**Final Translation:**'\n",
    "        match = re.search(r'\\*\\*Final Translation:\\*\\*\\s*(.*)', seg)\n",
    "        if match:\n",
    "            final_translation = match.group(1).strip()\n",
    "            final_translations.append(final_translation)\n",
    "    return final_translations\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    \"\"\"Adjust the audio to match the target duration.\n",
    "    \n",
    "    If audio is too short, append silence; if too long, trim the end.\n",
    "    \"\"\"\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:  # Audio too short: add silence.\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        adjusted_audio = audio + silence\n",
    "        return adjusted_audio\n",
    "    elif difference < -0.1:  # Audio too long: trim the end.\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        adjusted_audio = audio[:-int(trim_duration_ms)]\n",
    "        return adjusted_audio\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "\n",
    "# ============== NEW: French Phrase Alignment Functions ==============\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text into phrases using punctuation aware of French grammar.\"\"\"\n",
    "    # Fixed regex pattern with atomic grouping for French abbreviations\n",
    "    sentence_end = re.compile(\n",
    "        r'(?<!\\bM(?:r|me|s|rs|mes))\\s*([.!?])(?:\\s+|$)'\n",
    "    )\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check for sentence-ending punctuation with French context\n",
    "        if sentence_end.search(word):\n",
    "            # Check if next word starts with uppercase (proper sentence end)\n",
    "            if i+1 < len(words) and words[i+1][0].isupper():\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def split_french_phrases(text):\n",
    "    \"\"\"Split French text at natural phrase boundaries for technical content.\"\"\"\n",
    "    # Focus on sentence-ending punctuation followed by uppercase\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        # Check if word ends with sentence punctuation\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            # Check if next word starts with uppercase or we're at the end\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    \n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    \"\"\"Calculate duration allocation weights for French phrases based solely on their word counts.\"\"\"\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    # Compute each weight as the fraction of the total French words\n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "\n",
    "# ============== MODIFIED Audio Generat\n",
    "    \n",
    "  \n",
    "import tempfile\n",
    "\n",
    "# ============== MODIFIED Audio Generation Function ==============\n",
    "\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import tempfile\n",
    "import pysrt\n",
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path):\n",
    "    \"\"\"Version am√©lior√©e avec alignement au niveau des phrases fran√ßaises, d√©tection du d√©calage\n",
    "       et ajustement automatique de la vitesse de lecture pour corriger les √©carts.\"\"\"\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    final_translations = parse_final_translations(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    # Seuil pour d√©tecter un d√©calage notable (en secondes)\n",
    "    offset_threshold = 0.05  # par exemple 50 ms, √† ajuster selon vos tests\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = final_translations[idx]\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            # Utiliser une extension .mp3 car edge-tts produit du MP3\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            \n",
    "            try:\n",
    "                asyncio.run(synthesize_phrase_edge(\n",
    "                    phrase, temp_path, voice=\"fr-FR-DeniseNeural\", rate=\"+0%\"\n",
    "                ))\n",
    "                \n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Audio corrompu ignor√© : {temp_path}. Erreur: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Fichier manquant ou invalide: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=100)\n",
    "        \n",
    "        # Optionnel : on tronque si la dur√©e d√©passe\n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        \n",
    "        # V√©rifier si le segment audio g√©n√©r√© colle exactement aux timings attendus\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        # Si l'√©cart est significatif, ajuster la vitesse.\n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : ajustement de vitesse appliqu√©, facteur={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration avant ajustement:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "\n",
    "def merge_audio_video():\n",
    "    \"\"\"Merge the newly generated audio with the original video.\"\"\"\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    # If the audio is shorter than video, append silence.\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import edge_tts\n",
    "\n",
    "\n",
    "async def synthesize_phrase_edge(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\"\n",
    "):\n",
    "    communicate = edge_tts.Communicate(\n",
    "        text=phrase,\n",
    "        voice=voice,\n",
    "        rate=rate\n",
    "    )\n",
    "    await communicate.save(output_path)  # Removed format parameter\n",
    "\n",
    "\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    \"\"\"Change la vitesse de lecture de 'sound' par le facteur 'speed'.\"\"\"\n",
    "    # On modifie le frame rate, puis on remet √† la normale pour obtenir le nouveau son.\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============== Main Flow ==============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Extract audio.\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    \n",
    "    # Step 2: Transcribe audio.\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    \n",
    "    # Step 3: Generate English subtitles.\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "    # (Optional) Step 4: Translate subtitles (if needed for other purposes).\n",
    "    # In our flow, we now use the auto translation during review.\n",
    "    # print(\"Translating subtitles...\")\n",
    "    # translate_subtitles(subtitle_file_en, subtitle_file_fr)\n",
    "    \n",
    "    # Step 5: Generate French audio using the review file.\n",
    "    print(\"Generating French audio with synchronization...\")\n",
    "    generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(f\"Debug log written to: {debug_log_file}\")\n",
    "    \n",
    "    # Step 6: Merge audio and video.\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    \n",
    "    print(f\"Process completed! Output video: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef903f90",
   "metadata": {},
   "source": [
    "UPDATE AFTER VIEWING VIDEO : adjust speed and silence\n",
    "Translation Review File\n",
    "You can update the following properties for each segment:\n",
    "  **Final Translation:** Your updated French text\n",
    "  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\n",
    "  **Silence Duration:** Silence (in ms) to append (default 100 ms)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba35835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "from aiohttp import ClientConnectorError\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"4.2.4_Configuration de la solution_Avr_10_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print('STDOUT:', e.stdout.decode('utf8'))\n",
    "        print('STDERR:', e.stderr.decode('utf8'))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    \n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding='utf-8')\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    \n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r'[.!?]\\s*$')\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    with open(review_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"You can update the following properties for each segment:\\n\")\n",
    "        f.write(\"  **Final Translation:** Your updated French text\\n\")\n",
    "        f.write(\"  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\\n\")\n",
    "        f.write(\"  **Silence Duration:** Silence (in ms) to append (default 100 ms)\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations and the additional properties as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue using the updated review file: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split('---') if blk.strip()]\n",
    "    \n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # in ms default\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation is not None:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    \n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== French Phrase Alignment Functions ==============\n",
    "def split_french_phrases(text):\n",
    "    phrases = []\n",
    "    current = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        current.append(word)\n",
    "        if re.search(r'[.!?]$', word):\n",
    "            if (i == len(words)-1) or (words[i+1][0].isupper()):\n",
    "                phrases.append(\" \".join(current))\n",
    "                current = []\n",
    "    if current:\n",
    "        phrases.append(\" \".join(current))\n",
    "    return phrases\n",
    "\n",
    "def calculate_phrase_weights(original_text, translated_phrases):\n",
    "    fr_phrase_word_counts = [len(phrase.split()) for phrase in translated_phrases]\n",
    "    total_fr_words = sum(fr_phrase_word_counts)\n",
    "    \n",
    "    if total_fr_words == 0:\n",
    "        return [1/len(translated_phrases)] * len(translated_phrases)\n",
    "    \n",
    "    return [count / total_fr_words for count in fr_phrase_word_counts]\n",
    "\n",
    "# ============== TTS Functions ==============\n",
    "async def synthesize_phrase_edge_hybrid(\n",
    "    phrase: str,\n",
    "    output_path: str,\n",
    "    connector: aiohttp.TCPConnector,\n",
    "    voice: str = \"fr-FR-DeniseNeural\",\n",
    "    rate: str = \"+0%\"\n",
    "):\n",
    "    max_retries = 3\n",
    "    delay_seconds = 1\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Each TTS call creates its own session using the shared connector.\n",
    "            async with aiohttp.ClientSession(connector=connector, timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                communicate = edge_tts.Communicate(\n",
    "                    text=phrase,\n",
    "                    voice=voice,\n",
    "                    rate=rate,\n",
    "                    connector=connector\n",
    "                )\n",
    "                await communicate.save(output_path)\n",
    "                return\n",
    "        except (ClientConnectorError, ConnectionResetError, Exception) as e:\n",
    "            print(f\"[Error] Hybrid TTS synthesis failed for phrase: '{phrase}' on attempt {attempt+1}/{max_retries}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                await asyncio.sleep(delay_seconds)\n",
    "                delay_seconds *= 2\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Persistent Connector Creation ==============\n",
    "def create_persistent_connector():\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context, limit=10)\n",
    "    return connector\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_path, review_file_path, persistent_connector):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    \n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    \n",
    "    offset_threshold = 0.05\n",
    "    \n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        \n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        voice_speed_override = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        silence_duration_override = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "        \n",
    "        french_phrases = split_french_phrases(final_translation)\n",
    "        weights = calculate_phrase_weights(original_text, french_phrases)\n",
    "        \n",
    "        phrase_audios = []\n",
    "        for i, phrase in enumerate(french_phrases):\n",
    "            phrase_duration = target_duration * weights[i]\n",
    "            temp_path = os.path.join(tempfile.gettempdir(), f\"temp_phrase_{idx}_{i}.mp3\")\n",
    "            try:\n",
    "                await synthesize_phrase_edge_hybrid(\n",
    "                    phrase, temp_path, connector=persistent_connector, voice=\"fr-FR-DeniseNeural\", rate=voice_speed_override\n",
    "                )\n",
    "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 44:\n",
    "                    try:\n",
    "                        audio = AudioSegment.from_mp3(temp_path)\n",
    "                        audio = adjust_audio_duration(audio, phrase_duration)\n",
    "                        phrase_audios.append(audio)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Warning] Ignoring corrupted audio file: {temp_path}. Error: {e}\")\n",
    "                else:\n",
    "                    print(f\"[Warning] Missing or invalid file: {temp_path}\")\n",
    "            finally:\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "        \n",
    "        group_audio = AudioSegment.silent(duration=0)\n",
    "        for audio in phrase_audios:\n",
    "            group_audio += audio\n",
    "            group_audio += AudioSegment.silent(duration=silence_duration_override)\n",
    "        \n",
    "        group_audio = group_audio[:int(target_duration * 1000)]\n",
    "        generated_duration = group_audio.duration_seconds\n",
    "        time_diff = target_duration - generated_duration\n",
    "        \n",
    "        if abs(time_diff) > offset_threshold:\n",
    "            speed_factor = target_duration / generated_duration\n",
    "            print(f\"Segment {group[0].index} : adjusting speed, factor={speed_factor:.3f}\")\n",
    "            group_audio = change_playback_speed(group_audio, speed_factor)\n",
    "        \n",
    "        required_start_ms = int(group_start * 1000)\n",
    "        current_duration_ms = len(combined_audio)\n",
    "        if required_start_ms > current_duration_ms:\n",
    "            silence = AudioSegment.silent(duration=required_start_ms - current_duration_ms)\n",
    "            combined_audio += silence\n",
    "        \n",
    "        combined_audio += group_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed:** {voice_speed_override}\\n\"\n",
    "            f\"**Silence Duration:** {silence_duration_override} ms\\n\"\n",
    "            f\"**French Phrases:** {french_phrases}\\n\"\n",
    "            f\"**Phrase Weights:** {weights}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            f\"**Generated Duration before adjustment:** {generated_duration:.2f}s\\n\"\n",
    "            f\"**Time Diff:** {time_diff:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "    \n",
    "    with open(debug_log_path, 'w', encoding='utf-8') as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    \n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_path}\")\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function (unchanged) ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    \n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    \n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    persistent_connector = create_persistent_connector()  # Create the persistent connector\n",
    "    try:\n",
    "        print(\"Extracting audio...\")\n",
    "        audio_path = extract_audio()\n",
    "    \n",
    "        print(\"Transcribing audio...\")\n",
    "        language, segments = transcribe(audio_path)\n",
    "    \n",
    "        print(\"Generating English subtitles...\")\n",
    "        generate_subtitle_file(segments, subtitle_file_en)\n",
    "    \n",
    "        print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "        await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file, persistent_connector)\n",
    "    \n",
    "        print(\"Merging audio and video...\")\n",
    "        merge_audio_video()\n",
    "    \n",
    "        print(f\"Process completed! Output video: {output_video}\")\n",
    "    finally:\n",
    "        await persistent_connector.close()  # Close the persistent connector\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a54ae",
   "metadata": {},
   "source": [
    "UPDATE AFTER VIEWING VIDEO : adjust speed and silence per words or phrases\n",
    "Translation Review File\n",
    "You can update the following properties for each segment:\n",
    "  **Final Translation:** Your updated French text\n",
    "  **Voice Speed:** Rate modifier such as '+0%', '+10%', '-5%', etc. (default '+0%')\n",
    "  **Silence Duration:** Silence (in ms) to append (default 100 ms)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b798c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ffmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "Extracting audio...\n",
      "Transcribing audio...\n",
      "Detected language: en\n",
      "Generating English subtitles...\n",
      "Generating French audio with synchronization and manual overrides...\n",
      "Review file created at: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\translation_review.txt\n",
      "Please review and update the final translations as needed.\n",
      "Parsed review file overrides:\n",
      "  Segment 1 final translation: Dans cette d√©mo, nous explorerons comment cr√©er un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.\n",
      "  Segment 2 final translation: Le flux de navigation am√©liore l'exp√©rience utilisateur avec des voies structur√©es intuitives pour la navigation sans effort √† travers les modules et les t√¢ches.\n",
      "  Segment 3 final translation: Permet une petite transition entre la saisie des donn√©es, les rapports et la gestion des processus, l'optimisation de l'efficacit√© avec les flux de travail de planification et d'analyse.\n",
      "  Segment 4 final translation: L'utilisateur s'est connect√© √† l'application de planification EPM. Ils verront cette page de destination.\n",
      "  Segment 5 final translation: En cliquant sur l'ic√¥ne du s√©lecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.\n",
      "  Segment 6 final translation: La planification EPM est livr√©e avec le flux de navigation par d√©faut. Vous pouvez basculer vers un flux de navigation diff√©rent simplement en cliquant dessus.\n",
      "  Segment 7 final translation: Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activ√©es pour ce flux de navigation particulier.\n",
      "  Segment 8 final translation: Revenons maintenant √† EPM Flow.\n",
      "  Segment 9 final translation: Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans diff√©rents modules sans perte de donn√©es.\n",
      "  Segment 10 final translation: Cliquez sur l'ic√¥ne Navigator pour voir plus d'options. Cliquez sur la carte de donn√©es et ouvrirons un formulaire de d√©penses dans le dossier de d√©monstration.\n",
      "  Segment 11 final translation: Je vais √©tendre l'ann√©e totale et je peux voir les quarts et je vais saisir certaines donn√©es.\n",
      "  Segment 12 final translation: C'√©tait donc 9000 et entrant dans un 6000 et enregistrons ceci.\n",
      "  Segment 13 final translation: Vous pouvez voir comment les donn√©es sont refl√©t√©es et nous pouvons voir un 15000 maintenant.\n",
      "  Segment 14 final translation: Je vais cliquer sur la page d'accueil et ouvrir un rapport.\n",
      "  Segment 15 final translation: Je vais rechercher un rapport et cela montre les r√©sultats de tous les rapports et je vais ouvrir le rapport du dossier de d√©monstration.\n",
      "  Segment 16 final translation: Je ferai ce rapport. Je vais cliquer sur la page d'accueil.\n",
      "  Segment 17 final translation: Je peux √©galement cliquer sur la carte de donn√©es de la page d'accueil.\n",
      "  Segment 18 final translation: Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.\n",
      "  Segment 19 final translation: Dans cette page de destination, nous pouvons voir 7 ic√¥nes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.\n",
      "  Segment 20 final translation: Nous allons d√©sactiver la mod√©lisation strat√©gique et nous allons activer une nouvelle mod√©lisation financi√®re de carte dans cette d√©mo.\n",
      "  Segment 21 final translation: Pour configurer le flux de navigation, un utilisateur doit avoir un acc√®s d'administration de service.\n",
      "  Segment 22 final translation: Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.\n",
      "  Segment 23 final translation: Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.\n",
      "  Segment 24 final translation: Vous pouvez s√©lectionner le flux de navigation et cliquer sur l'ic√¥ne de l'engrenage pour voir diverses options.\n",
      "  Segment 25 final translation: Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.\n",
      "  Segment 26 final translation: Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.\n",
      "  Segment 27 final translation: Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.\n",
      "  Segment 28 final translation: Cliquez sur le nom du flux de navigation pour commencer √† apporter des modifications.\n",
      "  Segment 29 final translation: Chaque √©l√©ment est d√©sign√© un type, un cluster ou une carte, un √©tat de visibilit√©, d√©sactiv√©, activ√©.\n",
      "  Segment 30 final translation: Option pour r√©organiser et supprimer.\n",
      "  Segment 31 final translation: Pour cette d√©mo, nous allons activer le cluster financier qui est d√©sactiv√© ici en haut et nous allons d√©sactiver la mod√©lisation strat√©gique.\n",
      "  Segment 32 final translation: Dans le cluster financier, nous allons r√©organiser en d√©pla√ßant les revenus en haut.\n",
      "  Segment 33 final translation: J'ai √©galement les options pour cr√©er un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.\n",
      "  Segment 34 final translation: J'ai √©galement les options pour attribuer des autorisations aux groupes d'utilisateurs ou des r√¥les attribu√©s √† ce flux de navigation particulier.\n",
      "  Segment 35 final translation: Et je vais √©conomiser et fermer ce flux de navigation.\n",
      "  Segment 36 final translation: Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.\n",
      "  Segment 37 final translation: En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la mod√©lisation strat√©gique et que nous ne voyons pas encore le cluster de mod√©lisation financi√®re.\n",
      "  Segment 38 final translation: Pour actualiser le flux de navigation, ouvrez l'ic√¥ne du s√©lecteur de flux de navigation et cliquez sur Actualiser.\n",
      "  Segment 39 final translation: La page recharge avec le cluster financier et nous ne voyons plus le cluster de mod√©lisation strat√©gique.\n",
      "  Segment 40 final translation: Cliquer sur le cluster financier montre les revenus au premier tel que nous avons r√©organis√©.\n",
      "  Segment 41 final translation: Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.\n",
      "  Segment 42 final translation: Ici, il s'agit d'une donn√©es de travail pour votre FY23.\n",
      "  Segment 43 final translation: Sur planant sur ces ic√¥nes nous jettera des informations d√©taill√©es dans ce tableau de bord particulier.\n",
      "  Segment 44 final translation: Nous pouvons obtenir plus de d√©tails en les survolant.\n",
      "  Segment 45 final translation: Nous pouvons √©galement naviguer vers diff√©rents onglets et voir plus d'informations.\n",
      "  Segment 46 final translation: Nous avons √©galement des onglets en bas et en haut.\n",
      "  Segment 47 final translation: Nous pouvons voir toutes les derni√®res tendances pour l'ann√©e particuli√®re et nous pouvons survoler les plus d'informations.\n",
      "  Segment 48 final translation: Dans cette d√©mo, nous avons explor√© notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux r√¥les.\n",
      "[Debug] Segment 1 final translation: Dans cette d√©mo, nous explorerons comment cr√©er un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.\n",
      "[Debug] Generated SSML for segment 1: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans cette d√©mo, nous explorerons comment cr√©er un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans cette d√©mo, nous explorerons comment cr√©er un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Dans cette d√©mo, nous explorerons comment cr√©er un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837D5B0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.62 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Dans cette d√©mo, nous explorerons comment cr√©er un flux de navigation, comment nous pouvons le personnaliser et attribuer des autorisations aux groupes d'utilisateurs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_0.mp3\n",
      "[Debug] Segment 2 final translation: Le flux de navigation am√©liore l'exp√©rience utilisateur avec des voies structur√©es intuitives pour la navigation sans effort √† travers les modules et les t√¢ches.\n",
      "[Debug] Generated SSML for segment 2: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"-10%\">Le flux de navigation am√©liore l'exp√©rience utilisateur avec des voies structur√©es intuitives pour la navigation sans effort √† travers les modules et les t√¢ches.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Le flux de navigation am√©liore l'exp√©rience utilisateur avec des voies structur√©es intuitives pour la navigation sans effort √† travers les modules et les t√¢ches.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_1.mp3\n",
      "[Debug] Segment 3 final translation: Permet une petite transition entre la saisie des donn√©es, les rapports et la gestion des processus, l'optimisation de l'efficacit√© avec les flux de travail de planification et d'analyse.\n",
      "[Debug] Generated SSML for segment 3: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Permet une petite transition entre la saisie des donn√©es, les rapports et la gestion des processus, l'optimisation de l'efficacit√© avec les flux de travail de planification et d'analyse.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Permet une petite transition entre la saisie des donn√©es, les rapports et la gestion des processus, l'optimisation de l'efficacit√© avec les flux de travail de planification et d'analyse.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_2.mp3\n",
      "[Debug] Segment 4 final translation: L'utilisateur s'est connect√© √† l'application de planification EPM. Ils verront cette page de destination.\n",
      "[Debug] Generated SSML for segment 4: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">L'utilisateur s'est connect√© √† l'application de planification EPM. Ils verront cette page de destination.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'L'utilisateur s'est connect√© √† l'application de planification EPM. Ils verront cette page de destination.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_3.mp3\n",
      "[Debug] Segment 5 final translation: En cliquant sur l'ic√¥ne du s√©lecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.\n",
      "[Debug] Generated SSML for segment 5: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">En cliquant sur l'ic√¥ne du s√©lecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'En cliquant sur l'ic√¥ne du s√©lecteur de flux de navigation, vous verrez tout le flux de navigation actif pour cette application.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_4.mp3\n",
      "[Debug] Segment 6 final translation: La planification EPM est livr√©e avec le flux de navigation par d√©faut. Vous pouvez basculer vers un flux de navigation diff√©rent simplement en cliquant dessus.\n",
      "[Debug] Generated SSML for segment 6: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">La planification EPM est livr√©e avec le flux de navigation par d√©faut. Vous pouvez basculer vers un flux de navigation diff√©rent simplement en cliquant dessus.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'La planification EPM est livr√©e avec le flux de navigation par d√©faut. Vous pouvez basculer vers un flux de navigation diff√©rent simplement en cliquant dessus.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_5.mp3\n",
      "[Debug] Segment 7 final translation: Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activ√©es pour ce flux de navigation particulier.\n",
      "[Debug] Generated SSML for segment 7: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activ√©es pour ce flux de navigation particulier.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur EPM Cloud Navigation Flow. Vous pouvez voir toutes les cartes et clusters activ√©es pour ce flux de navigation particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_6.mp3\n",
      "[Debug] Segment 8 final translation: Revenons maintenant √† EPM Flow.\n",
      "[Debug] Generated SSML for segment 8: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Revenons maintenant √† EPM Flow.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Revenons maintenant √† EPM Flow.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Revenons maintenant √† EPM Flow.'. Exception: No audio was received. Please verify that your parameters are correct.\n",
      "[Debug] Retrying in 1.67 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Revenons maintenant √† EPM Flow.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Revenons maintenant √† EPM Flow.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837E450> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.94 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase using SSML: 'Revenons maintenant √† EPM Flow.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_7.mp3\n",
      "[Debug] Segment 9 final translation: Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans diff√©rents modules sans perte de donn√©es.\n",
      "[Debug] Generated SSML for segment 9: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans diff√©rents modules sans perte de donn√©es.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous allons maintenant voir le panneau secondaire et rechercher des artefacts et voir comment la session reprend lorsque nous retournons dans diff√©rents modules sans perte de donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_8.mp3\n",
      "[Debug] Segment 10 final translation: Cliquez sur l'ic√¥ne Navigator pour voir plus d'options. Cliquez sur la carte de donn√©es et ouvrirons un formulaire de d√©penses dans le dossier de d√©monstration.\n",
      "[Debug] Generated SSML for segment 10: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur l'ic√¥ne Navigator pour voir plus d'options. Cliquez sur la carte de donn√©es et ouvrirons un formulaire de d√©penses dans le dossier de d√©monstration.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur l'ic√¥ne Navigator pour voir plus d'options. Cliquez sur la carte de donn√©es et ouvrirons un formulaire de d√©penses dans le dossier de d√©monstration.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_9.mp3\n",
      "[Debug] Segment 11 final translation: Je vais √©tendre l'ann√©e totale et je peux voir les quarts et je vais saisir certaines donn√©es.\n",
      "[Debug] Generated SSML for segment 11: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je vais √©tendre l'ann√©e totale et je peux voir les quarts et je vais saisir certaines donn√©es.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je vais √©tendre l'ann√©e totale et je peux voir les quarts et je vais saisir certaines donn√©es.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_10.mp3\n",
      "[Debug] Segment 12 final translation: C'√©tait donc 9000 et entrant dans un 6000 et enregistrons ceci.\n",
      "[Debug] Generated SSML for segment 12: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">C'√©tait donc 9000 et entrant dans un 6000 et enregistrons ceci.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'C'√©tait donc 9000 et entrant dans un 6000 et enregistrons ceci.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_11.mp3\n",
      "[Debug] Segment 13 final translation: Vous pouvez voir comment les donn√©es sont refl√©t√©es et nous pouvons voir un 15000 maintenant.\n",
      "[Debug] Generated SSML for segment 13: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Vous pouvez voir comment les donn√©es sont refl√©t√©es et nous pouvons voir un 15000 maintenant.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Vous pouvez voir comment les donn√©es sont refl√©t√©es et nous pouvons voir un 15000 maintenant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_12.mp3\n",
      "[Debug] Segment 14 final translation: Je vais cliquer sur la page d'accueil et ouvrir un rapport.\n",
      "[Debug] Generated SSML for segment 14: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je vais cliquer sur la page d'accueil et ouvrir un rapport.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je vais cliquer sur la page d'accueil et ouvrir un rapport.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_13.mp3\n",
      "[Debug] Segment 15 final translation: Je vais rechercher un rapport et cela montre les r√©sultats de tous les rapports et je vais ouvrir le rapport du dossier de d√©monstration.\n",
      "[Debug] Generated SSML for segment 15: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je vais rechercher un rapport et cela montre les r√©sultats de tous les rapports et je vais ouvrir le rapport du dossier de d√©monstration.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je vais rechercher un rapport et cela montre les r√©sultats de tous les rapports et je vais ouvrir le rapport du dossier de d√©monstration.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_14.mp3\n",
      "[Debug] Segment 16 final translation: Je ferai ce rapport. Je vais cliquer sur la page d'accueil.\n",
      "[Debug] Generated SSML for segment 16: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je ferai ce rapport. Je vais cliquer sur la page d'accueil.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je ferai ce rapport. Je vais cliquer sur la page d'accueil.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Je ferai ce rapport. Je vais cliquer sur la page d'accueil.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837EA80> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.22 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Je ferai ce rapport. Je vais cliquer sur la page d'accueil.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_15.mp3\n",
      "[Debug] Segment 17 final translation: Je peux √©galement cliquer sur la carte de donn√©es de la page d'accueil.\n",
      "[Debug] Generated SSML for segment 17: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Je peux √©galement cliquer sur la carte de donn√©es de la page d'accueil.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Je peux √©galement cliquer sur la carte de donn√©es de la page d'accueil.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_16.mp3\n",
      "[Debug] Segment 18 final translation: Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.\n",
      "[Debug] Generated SSML for segment 18: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837D9A0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.76 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.'\n",
      "[Error] Attempt 2/5 failed for phrase: 'Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837E3C0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 2.17 seconds...\n",
      "[Debug] Attempt 3: Synthesizing phrase using SSML: 'Et c'est pour montrer comment nous sommes revenus au formulaire de donn√©es o√π nous avons entr√© les donn√©es et cela ne nous am√®ne pas √† la session photo et nous pouvons reprendre la session d'o√π nous sommes partis.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_17.mp3\n",
      "[Debug] Segment 19 final translation: Dans cette page de destination, nous pouvons voir 7 ic√¥nes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.\n",
      "[Debug] Generated SSML for segment 19: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans cette page de destination, nous pouvons voir 7 ic√¥nes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans cette page de destination, nous pouvons voir 7 ic√¥nes, 3 sur des clusters qui, sur l'expansion, nous montreront des cartes et les autres sont des cartes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_18.mp3\n",
      "[Debug] Segment 20 final translation: Nous allons d√©sactiver la mod√©lisation strat√©gique et nous allons activer une nouvelle mod√©lisation financi√®re de carte dans cette d√©mo.\n",
      "[Debug] Generated SSML for segment 20: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous allons d√©sactiver la mod√©lisation strat√©gique et nous allons activer une nouvelle mod√©lisation financi√®re de carte dans cette d√©mo.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous allons d√©sactiver la mod√©lisation strat√©gique et nous allons activer une nouvelle mod√©lisation financi√®re de carte dans cette d√©mo.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_19.mp3\n",
      "[Debug] Segment 21 final translation: Pour configurer le flux de navigation, un utilisateur doit avoir un acc√®s d'administration de service.\n",
      "[Debug] Generated SSML for segment 21: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Pour configurer le flux de navigation, un utilisateur doit avoir un acc√®s d'administration de service.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Pour configurer le flux de navigation, un utilisateur doit avoir un acc√®s d'administration de service.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_20.mp3\n",
      "[Debug] Segment 22 final translation: Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.\n",
      "[Debug] Generated SSML for segment 22: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez maintenant sur le cluster d'outils et vous pouvez voir la carte de flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_21.mp3\n",
      "[Debug] Segment 23 final translation: Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.\n",
      "[Debug] Generated SSML for segment 23: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Ici, vous pouvez voir plusieurs flux de navigation. Certains d'entre eux sont actifs et certains d'entre eux sont inactifs.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_22.mp3\n",
      "[Debug] Segment 24 final translation: Vous pouvez s√©lectionner le flux de navigation et cliquer sur l'ic√¥ne de l'engrenage pour voir diverses options.\n",
      "[Debug] Generated SSML for segment 24: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Vous pouvez s√©lectionner le flux de navigation et cliquer sur l'ic√¥ne de l'engrenage pour voir diverses options.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Vous pouvez s√©lectionner le flux de navigation et cliquer sur l'ic√¥ne de l'engrenage pour voir diverses options.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_23.mp3\n",
      "[Debug] Segment 25 final translation: Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.\n",
      "[Debug] Generated SSML for segment 25: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Vous pouvez copier, vous pouvez supprimer et vous pouvez valider le flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_24.mp3\n",
      "[Debug] Segment 26 final translation: Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.\n",
      "[Debug] Generated SSML for segment 26: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Avant de modifier un flux de navigation, assurez-vous qu'il est inactif.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_25.mp3\n",
      "[Debug] Segment 27 final translation: Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.\n",
      "[Debug] Generated SSML for segment 27: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur le flux de navigation actif rendra le flux de navigation inactif.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_26.mp3\n",
      "[Debug] Segment 28 final translation: Cliquez sur le nom du flux de navigation pour commencer √† apporter des modifications.\n",
      "[Debug] Generated SSML for segment 28: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquez sur le nom du flux de navigation pour commencer √† apporter des modifications.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquez sur le nom du flux de navigation pour commencer √† apporter des modifications.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_27.mp3\n",
      "[Debug] Segment 29 final translation: Chaque √©l√©ment est d√©sign√© un type, un cluster ou une carte, un √©tat de visibilit√©, d√©sactiv√©, activ√©.\n",
      "[Debug] Generated SSML for segment 29: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Chaque √©l√©ment est d√©sign√© un type, un cluster ou une carte, un √©tat de visibilit√©, d√©sactiv√©, activ√©.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Chaque √©l√©ment est d√©sign√© un type, un cluster ou une carte, un √©tat de visibilit√©, d√©sactiv√©, activ√©.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_28.mp3\n",
      "[Debug] Segment 30 final translation: Option pour r√©organiser et supprimer.\n",
      "[Debug] Generated SSML for segment 30: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Option pour r√©organiser et supprimer.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Option pour r√©organiser et supprimer.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_29.mp3\n",
      "[Debug] Segment 31 final translation: Pour cette d√©mo, nous allons activer le cluster financier qui est d√©sactiv√© ici en haut et nous allons d√©sactiver la mod√©lisation strat√©gique.\n",
      "[Debug] Generated SSML for segment 31: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Pour cette d√©mo, nous allons activer le cluster financier qui est d√©sactiv√© ici en haut et nous allons d√©sactiver la mod√©lisation strat√©gique.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Pour cette d√©mo, nous allons activer le cluster financier qui est d√©sactiv√© ici en haut et nous allons d√©sactiver la mod√©lisation strat√©gique.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_30.mp3\n",
      "[Debug] Segment 32 final translation: Dans le cluster financier, nous allons r√©organiser en d√©pla√ßant les revenus en haut.\n",
      "[Debug] Generated SSML for segment 32: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans le cluster financier, nous allons r√©organiser en d√©pla√ßant les revenus en haut.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans le cluster financier, nous allons r√©organiser en d√©pla√ßant les revenus en haut.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_31.mp3\n",
      "[Debug] Segment 33 final translation: J'ai √©galement les options pour cr√©er un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.\n",
      "[Debug] Generated SSML for segment 33: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">J'ai √©galement les options pour cr√©er un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'J'ai √©galement les options pour cr√©er un nouveau cluster, ajouter un nouveau cluster, ajouter une nouvelle carte et ajouter une carte dans un cluster.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_32.mp3\n",
      "[Debug] Segment 34 final translation: J'ai √©galement les options pour attribuer des autorisations aux groupes d'utilisateurs ou des r√¥les attribu√©s √† ce flux de navigation particulier.\n",
      "[Debug] Generated SSML for segment 34: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">J'ai √©galement les options pour attribuer des autorisations aux groupes d'utilisateurs ou des r√¥les attribu√©s √† ce flux de navigation particulier.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'J'ai √©galement les options pour attribuer des autorisations aux groupes d'utilisateurs ou des r√¥les attribu√©s √† ce flux de navigation particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_33.mp3\n",
      "[Debug] Segment 35 final translation: Et je vais √©conomiser et fermer ce flux de navigation.\n",
      "[Debug] Generated SSML for segment 35: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Et je vais √©conomiser et fermer ce flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Et je vais √©conomiser et fermer ce flux de navigation.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Et je vais √©conomiser et fermer ce flux de navigation.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837DE20> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.97 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Et je vais √©conomiser et fermer ce flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_34.mp3\n",
      "[Debug] Segment 36 final translation: Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.\n",
      "[Debug] Generated SSML for segment 36: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Et je devrai cliquer sur le bouton inactif pour activer ce flux de navigation.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_35.mp3\n",
      "[Debug] Segment 37 final translation: En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la mod√©lisation strat√©gique et que nous ne voyons pas encore le cluster de mod√©lisation financi√®re.\n",
      "[Debug] Generated SSML for segment 37: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la mod√©lisation strat√©gique et que nous ne voyons pas encore le cluster de mod√©lisation financi√®re.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'En cliquant sur la page d'accueil, vous pouvez voir que nous pourrions encore voir la mod√©lisation strat√©gique et que nous ne voyons pas encore le cluster de mod√©lisation financi√®re.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_36.mp3\n",
      "[Debug] Segment 38 final translation: Pour actualiser le flux de navigation, ouvrez l'ic√¥ne du s√©lecteur de flux de navigation et cliquez sur Actualiser.\n",
      "[Debug] Generated SSML for segment 38: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Pour actualiser le flux de navigation, ouvrez l'ic√¥ne du s√©lecteur de flux de navigation et cliquez sur Actualiser.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Pour actualiser le flux de navigation, ouvrez l'ic√¥ne du s√©lecteur de flux de navigation et cliquez sur Actualiser.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_37.mp3\n",
      "[Debug] Segment 39 final translation: La page recharge avec le cluster financier et nous ne voyons plus le cluster de mod√©lisation strat√©gique.\n",
      "[Debug] Generated SSML for segment 39: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">La page recharge avec le cluster financier et nous ne voyons plus le cluster de mod√©lisation strat√©gique.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'La page recharge avec le cluster financier et nous ne voyons plus le cluster de mod√©lisation strat√©gique.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_38.mp3\n",
      "[Debug] Segment 40 final translation: Cliquer sur le cluster financier montre les revenus au premier tel que nous avons r√©organis√©.\n",
      "[Debug] Generated SSML for segment 40: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquer sur le cluster financier montre les revenus au premier tel que nous avons r√©organis√©.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquer sur le cluster financier montre les revenus au premier tel que nous avons r√©organis√©.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_39.mp3\n",
      "[Debug] Segment 41 final translation: Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.\n",
      "[Debug] Generated SSML for segment 41: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Cliquer sur la carte de revenus dans le cluster financier nous chargera un tableau de bord en quelques secondes.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_40.mp3\n",
      "[Debug] Segment 42 final translation: Ici, il s'agit d'une donn√©es de travail pour votre FY23.\n",
      "[Debug] Generated SSML for segment 42: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Ici, il s'agit d'une donn√©es de travail pour votre FY23.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Ici, il s'agit d'une donn√©es de travail pour votre FY23.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_41.mp3\n",
      "[Debug] Segment 43 final translation: Sur planant sur ces ic√¥nes nous jettera des informations d√©taill√©es dans ce tableau de bord particulier.\n",
      "[Debug] Generated SSML for segment 43: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Sur planant sur ces ic√¥nes nous jettera des informations d√©taill√©es dans ce tableau de bord particulier.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Sur planant sur ces ic√¥nes nous jettera des informations d√©taill√©es dans ce tableau de bord particulier.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_42.mp3\n",
      "[Debug] Segment 44 final translation: Nous pouvons obtenir plus de d√©tails en les survolant.\n",
      "[Debug] Generated SSML for segment 44: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous pouvons obtenir plus de d√©tails en les survolant.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous pouvons obtenir plus de d√©tails en les survolant.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_43.mp3\n",
      "[Debug] Segment 45 final translation: Nous pouvons √©galement naviguer vers diff√©rents onglets et voir plus d'informations.\n",
      "[Debug] Generated SSML for segment 45: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous pouvons √©galement naviguer vers diff√©rents onglets et voir plus d'informations.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous pouvons √©galement naviguer vers diff√©rents onglets et voir plus d'informations.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_44.mp3\n",
      "[Debug] Segment 46 final translation: Nous avons √©galement des onglets en bas et en haut.\n",
      "[Debug] Generated SSML for segment 46: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous avons √©galement des onglets en bas et en haut.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous avons √©galement des onglets en bas et en haut.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_45.mp3\n",
      "[Debug] Segment 47 final translation: Nous pouvons voir toutes les derni√®res tendances pour l'ann√©e particuli√®re et nous pouvons survoler les plus d'informations.\n",
      "[Debug] Generated SSML for segment 47: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Nous pouvons voir toutes les derni√®res tendances pour l'ann√©e particuli√®re et nous pouvons survoler les plus d'informations.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Nous pouvons voir toutes les derni√®res tendances pour l'ann√©e particuli√®re et nous pouvons survoler les plus d'informations.'\n",
      "[Error] Attempt 1/5 failed for phrase: 'Nous pouvons voir toutes les derni√®res tendances pour l'ann√©e particuli√®re et nous pouvons survoler les plus d'informations.'. Exception: Cannot connect to host speech.platform.bing.com:443 ssl:<ssl.SSLContext object at 0x000001B87837EDE0> [Une connexion existante a d√ª √™tre ferm√©e par l‚Äôh√¥te distant]\n",
      "[Debug] Retrying in 1.73 seconds...\n",
      "[Debug] Attempt 2: Synthesizing phrase using SSML: 'Nous pouvons voir toutes les derni√®res tendances pour l'ann√©e particuli√®re et nous pouvons survoler les plus d'informations.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_46.mp3\n",
      "[Debug] Segment 48 final translation: Dans cette d√©mo, nous avons explor√© notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux r√¥les.\n",
      "[Debug] Generated SSML for segment 48: <?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\"><prosody rate=\"+0%\">Dans cette d√©mo, nous avons explor√© notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux r√¥les.</prosody><break time=\"100.0ms\"/></speak>\n",
      "[Debug] Attempt 1: Synthesizing phrase using SSML: 'Dans cette d√©mo, nous avons explor√© notre flux de navigation et comment nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs et aux r√¥les.'\n",
      "[Debug] Phrase synthesized successfully to C:\\Users\\061181~1\\AppData\\Local\\Temp\\temp_segment_47.mp3\n",
      "‚úÖ Translated audio saved to: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.wav\n",
      "üìù Debug log saved to: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\translation_debug_log.txt\n",
      "Merging audio and video...\n",
      "Moviepy - Building video 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4\n",
      "Process completed! Output video: 4.2.2_Flux de navigation_Avr_08_Latest_run_20250416_084328\\4.2.2_Flux de navigation_Avr_08_Latest-french.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ffmpeg\n",
    "import pysrt\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from shutil import which\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import aiohttp\n",
    "import ssl\n",
    "import random\n",
    "import concurrent.futures\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----- Configuration -----\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "if not ffmpeg_path:\n",
    "    raise RuntimeError(\"ffmpeg not found. Please install ffmpeg first.\")\n",
    "print(f\"‚úÖ ffmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "input_video = \"to translate/4.2.2_Flux de navigation_Avr_08_Latest.mp4\"\n",
    "base_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"{base_name}_run_{timestamp}\"\n",
    "model_size = \"small\"\n",
    "update_existing = True\n",
    "\n",
    "# We rely solely on cloud-based Edge TTS.\n",
    "USE_EDGE_TTS = True\n",
    "\n",
    "# Files and paths\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "input_video_name = os.path.splitext(os.path.basename(input_video))[0]\n",
    "extracted_audio = os.path.join(output_dir, f\"{input_video_name}-extracted-audio.wav\")\n",
    "subtitle_file_en = os.path.join(output_dir, f\"{input_video_name}-english.srt\")\n",
    "translated_audio = os.path.join(output_dir, f\"{input_video_name}-french.wav\")\n",
    "output_video = os.path.join(output_dir, f\"{input_video_name}-french.mp4\")\n",
    "review_file = os.path.join(output_dir, \"translation_review.txt\")\n",
    "debug_log_file = os.path.join(output_dir, \"translation_debug_log.txt\")\n",
    "\n",
    "# ============== Helper Functions (extract_audio, transcribe, etc.) ==============\n",
    "def extract_audio():\n",
    "    try:\n",
    "        (ffmpeg\n",
    "         .input(input_video)\n",
    "         .output(extracted_audio, ac=1, ar=16000)\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "        return extracted_audio\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"STDOUT:\", e.stdout.decode(\"utf8\"))\n",
    "        print(\"STDERR:\", e.stderr.decode(\"utf8\"))\n",
    "        raise\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "    language = info.language\n",
    "    print(f\"Detected language: {language}\")\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        transcript_segments.append({\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"text\": segment.text.strip()\n",
    "        })\n",
    "    return language, transcript_segments\n",
    "\n",
    "def time_to_subrip(seconds: float) -> pysrt.SubRipTime:\n",
    "    hours = int(seconds // 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds %= 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=int(seconds), milliseconds=milliseconds)\n",
    "\n",
    "def generate_subtitle_file(segments, output_path):\n",
    "    subs = pysrt.SubRipFile()\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        sub = pysrt.SubRipItem(\n",
    "            index=i,\n",
    "            start=time_to_subrip(segment[\"start\"]),\n",
    "            end=time_to_subrip(segment[\"end\"]),\n",
    "            text=segment[\"text\"]\n",
    "        )\n",
    "        subs.append(sub)\n",
    "    subs.save(output_path, encoding=\"utf-8\")\n",
    "    return output_path\n",
    "\n",
    "# ============== Translation & Review Functions ==============\n",
    "def generate_translation_review_file(source_path, review_file_path, from_lang=\"en\", to_lang=\"fr\"):\n",
    "    translator = GoogleTranslator(source=from_lang, target=to_lang)\n",
    "    subs = pysrt.open(source_path)\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    sentence_end_pattern = re.compile(r\"[.!?]\\s*$\")\n",
    "    for sub in subs:\n",
    "        current_group.append(sub)\n",
    "        if sentence_end_pattern.search(sub.text):\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    with open(review_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Translation Review File\\n\")\n",
    "        f.write(\"Please update the French text in the **Final Translation:** field below.\\n\")\n",
    "        f.write(\"DO NOT change the keys (**Final Translation:**, **Voice Speed:**, **Silence Duration:**).\\n\")\n",
    "        f.write(\"----------------------------------------------------------------\\n\")\n",
    "        for i, group in enumerate(groups, 1):\n",
    "            group_start = group[0].start.ordinal / 1000\n",
    "            group_end = group[-1].end.ordinal / 1000\n",
    "            original_text = \" \".join([sub.text for sub in group])\n",
    "            auto_translated = translator.translate(text=original_text)\n",
    "            default_voice_speed = \"+0%\"\n",
    "            default_silence = \"100\"\n",
    "            f.write(f\"Segment {i} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\")\n",
    "            f.write(f\"**Original:** {original_text}\\n\")\n",
    "            f.write(f\"**Auto Translated:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Final Translation:** {auto_translated}\\n\")\n",
    "            f.write(f\"**Voice Speed:** {default_voice_speed}\\n\")\n",
    "            f.write(f\"**Silence Duration:** {default_silence}\\n\")\n",
    "            f.write(\"----------------------------------------------------------------\\n\")\n",
    "    print(f\"Review file created at: {review_file_path}\")\n",
    "    print(\"Please review and update the final translations as needed.\")\n",
    "    while True:\n",
    "        user_confirmation = input(\"Type 'Y' when ready to continue: \").strip().lower()\n",
    "        if user_confirmation == \"y\":\n",
    "            break\n",
    "    return groups\n",
    "\n",
    "def parse_review_overrides(review_file_path):\n",
    "    segments_overrides = []\n",
    "    with open(review_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    blocks = [blk.strip() for blk in content.split(\"----------------------------------------------------------------\") if blk.strip()]\n",
    "    for blk in blocks:\n",
    "        final_translation = None\n",
    "        voice_speed = \"+0%\"\n",
    "        silence_duration = 100.0  # default in ms\n",
    "        for line in blk.splitlines():\n",
    "            if line.startswith(\"**Final Translation:**\"):\n",
    "                final_translation = line.split(\"**Final Translation:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Voice Speed:**\"):\n",
    "                voice_speed = line.split(\"**Voice Speed:**\", 1)[1].strip()\n",
    "            elif line.startswith(\"**Silence Duration:**\"):\n",
    "                try:\n",
    "                    silence_duration = float(line.split(\"**Silence Duration:**\", 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    silence_duration = 100.0\n",
    "        if final_translation:\n",
    "            segments_overrides.append({\n",
    "                \"final_translation\": final_translation,\n",
    "                \"voice_speed\": voice_speed,\n",
    "                \"silence_duration\": silence_duration\n",
    "            })\n",
    "    print(\"Parsed review file overrides:\")\n",
    "    for idx, override in enumerate(segments_overrides, 1):\n",
    "        print(f\"  Segment {idx} final translation: {override['final_translation']}\")\n",
    "    return segments_overrides\n",
    "\n",
    "# ============== Audio Synchronization Functions ==============\n",
    "def adjust_audio_duration(audio, target_duration):\n",
    "    current_duration = audio.duration_seconds\n",
    "    difference = target_duration - current_duration\n",
    "    if difference > 0.1:\n",
    "        silence = AudioSegment.silent(duration=difference * 1000)\n",
    "        return audio + silence\n",
    "    elif difference < -0.1:\n",
    "        trim_duration_ms = abs(difference) * 1000\n",
    "        return audio[:-int(trim_duration_ms)]\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# ============== Inline Tag Parsing and SSML Generation ==============\n",
    "def parse_segment_with_tags(text: str):\n",
    "    \"\"\"\n",
    "    Parse a text segment containing inline tags.\n",
    "    Supported custom tags:\n",
    "      - <speed value=\"120%\"> ... </speed> or <speed value=\"120%\"/> (both accepted)\n",
    "      - <pause duration=\"300ms\"/> (self-closing)\n",
    "    Returns a list of tuples (text, options) where options is a dict.\n",
    "    \"\"\"\n",
    "    tag_pattern = re.compile(r\"\"\"\n",
    "        (?P<pre_text>.*?)                              # text before the tag\n",
    "        (?:\n",
    "            <speed\\s+value=[\"'](?P<speed>[\\d.+%-]+)[\"']>  # speed tag opening\n",
    "            (?P<speed_text>.+?)(?:</speed>|<speed\\s*/>)    # speed tag content and closing\n",
    "          |\n",
    "            <pause\\s+duration=[\"'](?P<pause>[\\d.]+ms)[\"']\\s*/>  # self-closing pause tag\n",
    "        )\n",
    "    \"\"\", re.VERBOSE | re.DOTALL)\n",
    "    \n",
    "    results = []\n",
    "    pos = 0\n",
    "    while pos < len(text):\n",
    "        match = tag_pattern.search(text, pos)\n",
    "        if not match:\n",
    "            remaining = text[pos:]\n",
    "            if remaining:\n",
    "                results.append((remaining, {}))\n",
    "            break\n",
    "        if match.group(\"pre_text\"):\n",
    "            results.append((match.group(\"pre_text\"), {}))\n",
    "        if match.group(\"speed\"):\n",
    "            results.append((match.group(\"speed_text\"), {\"speed\": match.group(\"speed\").strip()}))\n",
    "        elif match.group(\"pause\"):\n",
    "            results.append((\"\", {\"pause\": match.group(\"pause\").strip()}))\n",
    "        pos = match.end()\n",
    "    return results\n",
    "\n",
    "def generate_ssml_for_phrase(text: str, default_speed: str, default_pause: int) -> str:\n",
    "    \"\"\"\n",
    "    Generates an SSML string from a text segment that may include inline tags.\n",
    "    Replaces custom tags with valid SSML instructions and wraps the result in <speak> tags.\n",
    "    An XML declaration is also prepended to ensure proper SSML processing.\n",
    "    \"\"\"\n",
    "    segments = parse_segment_with_tags(text)\n",
    "    ssml_parts = []\n",
    "    for seg_text, options in segments:\n",
    "        if \"pause\" in options:\n",
    "            ssml_parts.append(f'<break time=\"{options[\"pause\"]}\"/>')\n",
    "        elif \"speed\" in options:\n",
    "            spd = options[\"speed\"]\n",
    "            ssml_parts.append(f'<prosody rate=\"{spd}\">{seg_text}</prosody>')\n",
    "        else:\n",
    "            ssml_parts.append(f'<prosody rate=\"{default_speed}\">{seg_text}</prosody>')\n",
    "    full_ssml = \"\".join(ssml_parts) + f'<break time=\"{default_pause}ms\"/>'\n",
    "    # Prepend XML declaration and wrap in speak element.\n",
    "    return f'<?xml version=\"1.0\"?><speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"fr-FR\">{full_ssml}</speak>'\n",
    "\n",
    "# ============== TTS Functions: Edge TTS Only with Debug Logging ==============\n",
    "async def robust_synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", ssml: str = None, max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Synthesize speech using Edge TTS with robust retry logic.\n",
    "    If an SSML string is provided, it is passed as the text parameter.\n",
    "    Detailed debug messages are printed for each attempt.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n",
    "                if ssml is not None:\n",
    "                    communicate = edge_tts.Communicate(text=ssml, voice=voice)\n",
    "                else:\n",
    "                    communicate = edge_tts.Communicate(text=phrase, voice=voice, rate=rate)\n",
    "                print(f\"[Debug] Attempt {attempt+1}: Synthesizing phrase using {'SSML' if ssml else 'plain text'}: '{phrase}'\")\n",
    "                await communicate.save(output_path)\n",
    "                print(f\"[Debug] Phrase synthesized successfully to {output_path}\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            wait_time = 2 ** attempt + random.uniform(0, 1)\n",
    "            print(f\"[Error] Attempt {attempt+1}/{max_retries} failed for phrase: '{phrase}'. Exception: {e}\")\n",
    "            print(f\"[Debug] Retrying in {wait_time:.2f} seconds...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "    raise Exception(f\"Failed to synthesize phrase after {max_retries} attempts: {phrase}\")\n",
    "\n",
    "async def synthesize_phrase(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", ssml: str = None):\n",
    "    await robust_synthesize_phrase(phrase, output_path, voice, rate, ssml)\n",
    "\n",
    "# For backward compatibility:\n",
    "async def synthesize_phrase_edge_hybrid(phrase: str, output_path: str, voice: str = \"fr-FR-DeniseNeural\", rate: str = \"+0%\", ssml: str = None):\n",
    "    await synthesize_phrase(phrase, output_path, voice, rate, ssml)\n",
    "\n",
    "def change_playback_speed(sound, speed=1.0):\n",
    "    new_frame_rate = int(sound.frame_rate * speed)\n",
    "    altered_sound = sound._spawn(sound.raw_data, overrides={\"frame_rate\": new_frame_rate})\n",
    "    return altered_sound.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "# ============== Updated Async Audio Generation Function ==============\n",
    "async def async_generate_translated_audio_with_sync_using_review(subtitle_source_path, output_audio_path, debug_log_file, review_file_path):\n",
    "    groups = generate_translation_review_file(subtitle_source_path, review_file_path)\n",
    "    overrides = parse_review_overrides(review_file_path)\n",
    "    subs = pysrt.open(subtitle_source_path)\n",
    "    grouped_subs = groups\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "    debug_lines = []\n",
    "    offset_threshold = 0.05\n",
    "\n",
    "    for idx, group in enumerate(grouped_subs):\n",
    "        group_start = group[0].start.ordinal / 1000\n",
    "        group_end = group[-1].end.ordinal / 1000\n",
    "        target_duration = group_end - group_start\n",
    "        original_text = \" \".join([sub.text for sub in group])\n",
    "        final_translation = overrides[idx][\"final_translation\"] if idx < len(overrides) else original_text\n",
    "        seg_voice_speed = overrides[idx][\"voice_speed\"] if idx < len(overrides) else \"+0%\"\n",
    "        seg_silence_duration = overrides[idx][\"silence_duration\"] if idx < len(overrides) else 100.0\n",
    "\n",
    "        print(f\"[Debug] Segment {idx+1} final translation: {final_translation}\")\n",
    "        # Generate SSML including inline tags.\n",
    "        ssml = generate_ssml_for_phrase(final_translation, default_speed=seg_voice_speed, default_pause=seg_silence_duration)\n",
    "        print(f\"[Debug] Generated SSML for segment {idx+1}: {ssml}\")\n",
    "        temp_segment_path = os.path.join(tempfile.gettempdir(), f\"temp_segment_{idx}.mp3\")\n",
    "        try:\n",
    "            await synthesize_phrase_edge_hybrid(final_translation, temp_segment_path, voice=\"fr-FR-DeniseNeural\", ssml=ssml)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Synthesis failed for segment {idx+1}: {e}. Skipping this segment.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            segment_audio = AudioSegment.from_mp3(temp_segment_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Unable to load audio from {temp_segment_path}: {e}. Skipping this segment.\")\n",
    "            if os.path.exists(temp_segment_path):\n",
    "                os.remove(temp_segment_path)\n",
    "            continue\n",
    "\n",
    "        segment_audio = adjust_audio_duration(segment_audio, target_duration)\n",
    "        combined_audio += AudioSegment.silent(duration=int(group_start * 1000) - len(combined_audio))\n",
    "        combined_audio += segment_audio\n",
    "\n",
    "        debug_entry = (\n",
    "            f\"Segment {group[0].index} (start: {group_start:.2f}s, end: {group_end:.2f}s):\\n\"\n",
    "            f\"**Original:** {original_text}\\n\"\n",
    "            f\"**Final Translation:** {final_translation}\\n\"\n",
    "            f\"**Voice Speed (segment):** {seg_voice_speed}\\n\"\n",
    "            f\"**Silence Duration (segment):** {seg_silence_duration} ms\\n\"\n",
    "            f\"**Generated SSML:** {ssml}\\n\"\n",
    "            f\"**Target Duration:** {target_duration:.2f}s\\n\"\n",
    "            \"---\\n\"\n",
    "        )\n",
    "        debug_lines.append(debug_entry)\n",
    "        if os.path.exists(temp_segment_path):\n",
    "            os.remove(temp_segment_path)\n",
    "\n",
    "    with open(debug_log_file, \"w\", encoding=\"utf-8\") as debug_file:\n",
    "        debug_file.write(\"Translation Debug Log\\n\\n\")\n",
    "        debug_file.writelines(debug_lines)\n",
    "    combined_audio.export(output_audio_path, format=\"wav\")\n",
    "    print(f\"‚úÖ Translated audio saved to: {output_audio_path}\")\n",
    "    print(f\"üìù Debug log saved to: {debug_log_file}\")\n",
    "    return output_audio_path\n",
    "\n",
    "# ============== Merge Audio and Video Function ==============\n",
    "def merge_audio_video():\n",
    "    video = VideoFileClip(input_video)\n",
    "    audio = AudioFileClip(translated_audio)\n",
    "    if audio.duration < video.duration:\n",
    "        extra_silence = AudioSegment.silent(duration=(video.duration - audio.duration) * 1000)\n",
    "        audio_path_temp = os.path.join(output_dir, \"temp_full_audio.wav\")\n",
    "        audio_seg = AudioSegment.from_file(translated_audio, format=\"wav\")\n",
    "        full_audio = audio_seg + extra_silence\n",
    "        full_audio.export(audio_path_temp, format=\"wav\")\n",
    "        audio = AudioFileClip(audio_path_temp)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(\n",
    "        output_video,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        temp_audiofile=\"temp-audio.m4a\",\n",
    "        remove_temp=True,\n",
    "        threads=4\n",
    "    )\n",
    "\n",
    "# ============== Main Asynchronous Flow ==============\n",
    "async def async_main():\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Transcribing audio...\")\n",
    "    language, segments = transcribe(audio_path)\n",
    "    print(\"Generating English subtitles...\")\n",
    "    generate_subtitle_file(segments, subtitle_file_en)\n",
    "    print(\"Generating French audio with synchronization and manual overrides...\")\n",
    "    await async_generate_translated_audio_with_sync_using_review(subtitle_file_en, translated_audio, debug_log_file, review_file)\n",
    "    print(\"Merging audio and video...\")\n",
    "    merge_audio_video()\n",
    "    print(f\"Process completed! Output video: {output_video}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(async_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd834a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
