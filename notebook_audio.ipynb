{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating transcript to French...\n",
      "French translation obtained.\n",
      "Generating French voice audio...\n",
      "French voice audio generated as 'french_voice_over.mp3'.\n",
      "Merging the French audio with the original video...\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'https://clipchamp.com', 'comment': 'Create videos with https://clipchamp.com/en/video-editor - free online video editor, video compressor, video converter.'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [3840, 2160], 'bitrate': 4947, 'fps': 30.0, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 48000, 'bitrate': 192, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 440.6, 'bitrate': 5146, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [3840, 2160], 'video_bitrate': 4947, 'video_fps': 30.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 48000, 'audio_bitrate': 192, 'video_duration': 440.6, 'video_n_frames': 13218}\n",
      "c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe -i Navigation_Flow_COM.mp4 -loglevel error -f image2pipe -vf scale=3840:2160 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VideoFileClip' object has no attribute 'set_audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 161\u001b[39m\n\u001b[32m    159\u001b[39m original_video = \u001b[33m\"\u001b[39m\u001b[33mNavigation_Flow_COM.mp4\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your MP4 video file path\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMerging the French audio with the original video...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[43mmerge_audio_with_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrench_voice_over.mp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNavigation_Flow_COM_French.mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal video saved as \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfinal_video.mp4\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mmerge_audio_with_video\u001b[39m\u001b[34m(video_path, audio_path, output_video)\u001b[39m\n\u001b[32m     69\u001b[39m audio_clip = AudioFileClip(audio_path)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Set the new audio to the video clip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m final_video = \u001b[43mvideo_clip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_audio\u001b[49m(audio_clip)\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Write the final video to file (adjust codec and audio settings as needed)\u001b[39;00m\n\u001b[32m     73\u001b[39m final_video.write_videofile(output_video, codec=\u001b[33m\"\u001b[39m\u001b[33mlibx264\u001b[39m\u001b[33m\"\u001b[39m, audio_codec=\u001b[33m\"\u001b[39m\u001b[33maac\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'VideoFileClip' object has no attribute 'set_audio'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import edge_tts\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip,AudioFileClip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set your OpenAI API key (you can also set it via environment variables)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# STEP 1: Translate and Improve the Transcript with OpenAI's LLM\n",
    "# ---------------------------------------------------------------------------\n",
    "def improve_translation(transcript: str) -> str:\n",
    "    \"\"\"\n",
    "    Translate the given transcript into natural, fluent French and improve its clarity.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Please translate the following transcript into natural, fluent French. \"\n",
    "        \"Improve the translation for clarity and natural tone:\\n\\n\" + transcript\n",
    "    )\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",  # or \"gpt-3.5-turbo\" if GPT-4 is unavailable\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3 # Adjust temperature for creativity vs. accuracy\n",
    "    )\n",
    "    \n",
    "    # Extract the translated content from the response\n",
    "    translated_text = response.choices[0].message[\"content\"].strip()\n",
    "    return translated_text\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# STEP 2: Generate French Voice-Over Audio Using Edge-TTS\n",
    "# ---------------------------------------------------------------------------\n",
    "async def generate_french_audio(text: str, output_audio: str = \"french_voice_over.mp3\"):\n",
    "    \"\"\"\n",
    "    Generate French speech audio using Edge-TTS with the desired voice and rate.\n",
    "    \"\"\"\n",
    "    # French voice and speech rate settings\n",
    "    voice = \"fr-BE-GerardNeural\"  # Change if needed\n",
    "    rate = \"-10%\"  # Slightly slower for clarity\n",
    "\n",
    "    # Create the TTS communicator and save the audio file\n",
    "    communicator = edge_tts.Communicate(text, voice, rate=rate)\n",
    "    await communicator.save(output_audio)\n",
    "\n",
    "def run_generate_audio(text: str, output_audio: str = \"french_voice_over.mp3\"):\n",
    "    \"\"\"\n",
    "    Run the asynchronous TTS generation using nest_asyncio to avoid event loop issues.\n",
    "    \"\"\"\n",
    "    nest_asyncio.apply()  # Allows asyncio to run in environments like Jupyter\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(generate_french_audio(text, output_audio))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# STEP 3: Merge the New French Audio with the Original Video\n",
    "# ---------------------------------------------------------------------------\n",
    "def merge_audio_with_video(video_path: str, audio_path: str, output_video: str = \"final_video.mp4\"):\n",
    "    \"\"\"\n",
    "    Replace the original audio in the video with the new French voice-over.\n",
    "    \"\"\"\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "    # Set the new audio to the video clip\n",
    "     # final_video = video_clip.set_audio(audio_clip)\n",
    "    final_video = video_clip.with_audio(audio_clip)\n",
    "\n",
    "    # Write the final video to file (adjust codec and audio settings as needed)\n",
    "    final_video.write_videofile(output_video, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_timestamps(transcript: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove common timestamp patterns (e.g., '0:00:', '1:23:', or 'minuit') from the transcript.\n",
    "    Adjust the regex pattern if your timestamps have a different format.\n",
    "    \"\"\"\n",
    "    # This regex matches timestamps like \"0:00:\" or \"1:23:\" at the beginning of lines\n",
    "    cleaned_lines = []\n",
    "    for line in transcript.splitlines():\n",
    "        # Remove timestamp pattern at start of the line\n",
    "        cleaned_line = re.sub(r'^\\s*\\d{1,2}:\\d{2}:\\s*', '', line)\n",
    "        # Optionally remove occurrences of the word \"minuit\" if they are only meant for timing\n",
    "        cleaned_line = re.sub(r'\\bminuit\\b', '', cleaned_line, flags=re.IGNORECASE)\n",
    "        cleaned_lines.append(cleaned_line.strip())\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# MAIN EXECUTION\n",
    "# ---------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Original transcript text with timestamps (as provided)\n",
    "    transcript_text = \"\"\"0:00: In this demo, we will explore about navigation flow. \n",
    "0:06: And how we can customize and assign provisions to user groups. \n",
    "0:12: Navigation flow enhances user experience with intuitive structured pathways for effortless navigation across modules and tasks. \n",
    "0:24: Enables smooth transition between data entry, reporting, and process management, optimizing efficiency within planning and analytics workflows. \n",
    "0:38: Once a user has logged into EPM planning application, they will see this landing page. \n",
    "0:47: Clicking on the 4 dots on the right corner, you will see. \n",
    "0:54: All the active navigation flows for this application. \n",
    "0:59: EPM planning comes with default navigation flow. \n",
    "1:06: You can toggle to different navigation flow simply by clicking on it. \n",
    "1:13: Let's click on EBM cloud navigation flow. \n",
    "1:18: You can see all the cards and cluster enabled for this particular navigation floor. \n",
    "1:27: Now let's toggle back to the SM flow navigation flow. \n",
    "1:35: And we will take a look at how we can customize the SM navigation flow. \n",
    "1:42: You can see on the screen we have 6 cards and cluster. \n",
    "1:48: Cluster is group of cuts. \n",
    "1:54: And we are going to enable a new cluster called Financials, and we're going to disable the cluster strategic modeling in this demo. \n",
    "2:08: To configure navigation flow, a user needs to have service admin access. \n",
    "2:16: Now clicking on tools. \n",
    "2:20: You will see the cluster navigation flow. \n",
    "2:25: Here you can see multiple navigation flows configured and some of them are active. \n",
    "2:34: And some of them are inactive. \n",
    "2:39: You can select a navigation flow. \n",
    "2:43: And clicking on the action gear on the right corner. \n",
    "2:49: We'll let you to copy this navigation flow. \n",
    "2:54: Delete and validate. \n",
    "3:00: Before modifying any navigation flow, we need to make sure the navigation flow is inactive. \n",
    "3:09: So clicking on it will make it inactive. \n",
    "3:14: To configure the navigation flow. \n",
    "3:18: I'm going to click on the SM navigation flow name. \n",
    "3:26: And we can start making changes here. \n",
    "3:29: Once I have clicked and navigated to this flow, and here you can see the type where it defines the cluster. \n",
    "3:41: Or it's a card? \n",
    "3:43: And the state of visibility enable or disabled. \n",
    "3:51: The order which you can sort. \n",
    "3:54: And the option to delete. \n",
    "3:58: From this navigation. \n",
    "4:01: For this demo, let's enable financials. \n",
    "4:07: We're going to expand financials, so financials is a cluster, and it will have multiple cards. \n",
    "4:16: I'm going to move this car up because I want to see revenue first. \n",
    "4:25: And I'm going to collapse the final shells. \n",
    "4:30: Now, there is strategic modeling enabled, I'm going to disable this. \n",
    "4:36: And also, I have the permission to assign to a particular group. \n",
    "4:44: Or Particular user role. \n",
    "4:47: And this will allow only users belonging to those groups or roles to access this navigation flow. \n",
    "4:57: So it helps in maintaining security and limiting departments from accessing these financial modules. \n",
    "5:07: are going to save and close. \n",
    "5:13: And once I'm done with all the changes, I will have to activate this back, so clicking on it will activate the navigation flow. \n",
    "5:23: Now to refresh the flow, I'm going to go to the homepage where I'm still seeing the old view. \n",
    "5:30: I don't see the financial card and I'm seeing the strategy which I should not be seeing, so I need to go to the 4 dots and refresh the navigation flow from this refresh button. \n",
    "5:47: Once I do that, you can see I have a new card financials. \n",
    "5:54: I won't see the strategic modeling card. \n",
    "5:56: And Clicking on the financial cluster, you can see multiple cards and you can see revenue as we moved it to the top to display on the first. \n",
    "6:09: So let me click on revenue, and it lost the revenue for your FY 23, and you can see consolidated financial data in multiple graphical views, and you can see how the data is retrieved within seconds. \n",
    "6:28: We can hover over these options to see more details for different graphical views with all the data. \n",
    "6:39: You can notice that we have multiple tabs, and clicking on those tabs take us to those views with more detailed revenue details. \n",
    "6:50: There are also tabs on the top. \n",
    "6:53: And the taps on the bottom and just clicking on them will take you to that particular dashboard. \n",
    "7:02: Hovering over the graphical view. \n",
    "7:06: You can see the more detailed information. \n",
    "7:12: In this demo we explored our nation flow and how we can customize and assign permissions to user groups.\"\"\"\n",
    "    \n",
    "    \n",
    "    # Remove the timestamps\n",
    "    clean_transcript = remove_timestamps(transcript_text)\n",
    "    print(\"Clean Transcript:\\n\", clean_transcript)\n",
    "        # -----------------------------------------------------------------------\n",
    "    # Translate the transcript into natural, fluent French\n",
    "    print(\"Translating transcript to French...\")\n",
    "    french_translation = improve_translation(clean_transcript)\n",
    "    print(\"French translation obtained.\")\n",
    "    \n",
    "    # Save the translated transcript to a text file (optional)\n",
    "    with open(\"french_transcript.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(french_translation)\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # Generate French voice-over audio from the improved translation\n",
    "    print(\"Generating French voice audio...\")\n",
    "    run_generate_audio(french_translation, output_audio=\"french_voice_over.mp3\")\n",
    "    print(\"French voice audio generated as 'french_voice_over.mp3'.\")\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # Merge the generated French audio with the original video\n",
    "    original_video = \"Navigation_Flow_COM.mp4\"  # Replace with your MP4 video file path\n",
    "    print(\"Merging the French audio with the original video...\")\n",
    "    merge_audio_with_video(original_video, \"french_voice_over.mp3\", output_video=\"Navigation_Flow_COM_French.mp4\")\n",
    "    print(\"Final video saved as 'final_video.mp4'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résumé du code :\n",
    "Ce script transforme une vidéo anglophone en version française en générant une piste audio synchronisée via synthèse vocale (TTS). Il traduit d'abord les sous-titres avec OpenAI (optionnel), ajuste les durées des segments audio pour correspondre à la vidéo, puis fusionne le tout avec la vidéo originale.\n",
    "\n",
    "Principales librairies :\n",
    "\n",
    "edge_tts : Génère la voix française synthétique (SylvieNeural) pour chaque segment de texte.\n",
    "\n",
    "openai : Traduit/améliore le texte en français via GPT-4/3.5 (optionnel).\n",
    "\n",
    "pydub : Manipule les fichiers audio (découpage, ajout de silence, concaténation).\n",
    "\n",
    "moviepy : Fusionne l'audio final avec la vidéo originale.\n",
    "\n",
    "asyncio/nest_asyncio : Gère les appels asynchrones pour la synthèse vocale.\n",
    "\n",
    "Étapes clés :\n",
    "\n",
    "Configuration :\n",
    "\n",
    "Charge la clé OpenAI depuis .env.\n",
    "\n",
    "Définit les paramètres de voix (débit, voix FR) et les chemins des fichiers.\n",
    "\n",
    "Parsing du transcript :\n",
    "\n",
    "Extrait les segments texte + timestamps avec une regex (0:00: Texte...).\n",
    "\n",
    "Traduction (optionnelle) :\n",
    "\n",
    "Utilise GPT-4/3.5 pour traduire/améliorer le texte en français naturel.\n",
    "\n",
    "Génération audio :\n",
    "\n",
    "Crée un fichier MP3 par segment via edge_tts (asynchrone).\n",
    "\n",
    "Ajuste les durées : ajoute du silence ou tronque pour synchroniser avec la vidéo.\n",
    "\n",
    "Fusion finale :\n",
    "\n",
    "Concatène tous les segments audio en un fichier unique.\n",
    "\n",
    "Remplace la piste audio de la vidéo originale avec moviepy.\n",
    "\n",
    "Cas d'usage typique :\n",
    "Localiser une vidéo tutorielle en français en conservant le timing original entre l'audio et les visuels, avec une voix synthétique personnalisée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.exe\n",
      "\n",
      "--- Segment 0 (Start: 0s) ---\n",
      "Translated text: Dans cette démonstration, nous allons explorer le flux de navigation.\n",
      "\n",
      "Generating audio for segment 0...\n",
      "\n",
      "--- Segment 1 (Start: 6s) ---\n",
      "Translated text: Et comment nous pouvons personnaliser et attribuer des dispositions aux groupes d'utilisateurs.\n",
      "\n",
      "Generating audio for segment 1...\n",
      "\n",
      "--- Segment 2 (Start: 12s) ---\n",
      "Translated text: Le flux de navigation améliore l'expérience utilisateur grâce à des parcours structurés et intuitifs, permettant une navigation sans effort à travers les modules et les tâches.\n",
      "\n",
      "Generating audio for segment 2...\n",
      "\n",
      "--- Segment 3 (Start: 24s) ---\n",
      "Translated text: Permet une transition fluide entre la saisie de données, la création de rapports et la gestion des processus, optimisant ainsi l'efficacité des flux de travail en planification et en analyse.\n",
      "\n",
      "Generating audio for segment 3...\n",
      "\n",
      "--- Segment 4 (Start: 38s) ---\n",
      "Translated text: Une fois qu'un utilisateur s'est connecté à l'application de planification EPM, il verra cette page d'accueil.\n",
      "\n",
      "Generating audio for segment 4...\n",
      "\n",
      "--- Segment 5 (Start: 47s) ---\n",
      "Translated text: En cliquant sur les quatre points dans le coin droit, vous verrez.\n",
      "\n",
      "Generating audio for segment 5...\n",
      "\n",
      "--- Segment 6 (Start: 54s) ---\n",
      "Translated text: Tous les flux de navigation actifs de cette application.\n",
      "\n",
      "Generating audio for segment 6...\n",
      "\n",
      "--- Segment 7 (Start: 59s) ---\n",
      "Translated text: La planification EPM est accompagnée d'un flux de navigation par défaut.\n",
      "\n",
      "Generating audio for segment 7...\n",
      "\n",
      "--- Segment 8 (Start: 66s) ---\n",
      "Translated text: Vous pouvez facilement basculer entre les différents flux de navigation en cliquant simplement dessus.\n",
      "\n",
      "Generating audio for segment 8...\n",
      "\n",
      "--- Segment 9 (Start: 73s) ---\n",
      "Translated text: Cliquons sur le flux de navigation du cloud EBM.\n",
      "\n",
      "Generating audio for segment 9...\n",
      "\n",
      "--- Segment 10 (Start: 78s) ---\n",
      "Translated text: Vous pouvez voir toutes les cartes et les regroupements activés pour ce parcours de navigation spécifique.\n",
      "\n",
      "Generating audio for segment 10...\n",
      "\n",
      "--- Segment 11 (Start: 87s) ---\n",
      "Translated text: Revenons maintenant au flux de navigation du flux SM.\n",
      "\n",
      "Generating audio for segment 11...\n",
      "\n",
      "--- Segment 12 (Start: 95s) ---\n",
      "Translated text: Nous allons examiner comment personnaliser le flux de navigation SM.\n",
      "\n",
      "Generating audio for segment 12...\n",
      "\n",
      "--- Segment 13 (Start: 102s) ---\n",
      "Translated text: Vous pouvez voir à l'écran que nous avons six cartes et un groupe.\n",
      "\n",
      "Generating audio for segment 13...\n",
      "\n",
      "--- Segment 14 (Start: 108s) ---\n",
      "Translated text: Un cluster est un groupe de coupures.\n",
      "\n",
      "Generating audio for segment 14...\n",
      "\n",
      "--- Segment 15 (Start: 114s) ---\n",
      "Translated text: Nous allons activer un nouveau cluster appelé \"Financiers\" et désactiver le cluster \"Modélisation stratégique\" dans cette démonstration.\n",
      "\n",
      "Generating audio for segment 15...\n",
      "\n",
      "--- Segment 16 (Start: 128s) ---\n",
      "Translated text: Pour configurer le flux de navigation, l'utilisateur doit disposer des droits d'administrateur du service.\n",
      "\n",
      "Generating audio for segment 16...\n",
      "\n",
      "--- Segment 17 (Start: 136s) ---\n",
      "Translated text: Maintenant, cliquez sur Outils.\n",
      "\n",
      "Generating audio for segment 17...\n",
      "\n",
      "--- Segment 18 (Start: 140s) ---\n",
      "Translated text: Vous verrez le flux de navigation du cluster.\n",
      "\n",
      "Generating audio for segment 18...\n",
      "\n",
      "--- Segment 19 (Start: 145s) ---\n",
      "Translated text: Ici, vous pouvez voir plusieurs flux de navigation configurés, dont certains sont actifs.\n",
      "\n",
      "Generating audio for segment 19...\n",
      "\n",
      "--- Segment 20 (Start: 154s) ---\n",
      "Translated text: Et certains d'entre eux sont inactifs.\n",
      "\n",
      "Generating audio for segment 20...\n",
      "\n",
      "--- Segment 21 (Start: 159s) ---\n",
      "Translated text: Vous pouvez choisir un parcours de navigation.\n",
      "\n",
      "Generating audio for segment 21...\n",
      "\n",
      "--- Segment 22 (Start: 163s) ---\n",
      "Translated text: Et en cliquant sur l'icône d'action dans le coin supérieur droit.\n",
      "\n",
      "Generating audio for segment 22...\n",
      "\n",
      "--- Segment 23 (Start: 169s) ---\n",
      "Translated text: Nous vous permettrons de reproduire ce flux de navigation.\n",
      "\n",
      "Generating audio for segment 23...\n",
      "\n",
      "--- Segment 24 (Start: 174s) ---\n",
      "Translated text: Supprimez et validez.\n",
      "\n",
      "Generating audio for segment 24...\n",
      "\n",
      "--- Segment 25 (Start: 180s) ---\n",
      "Translated text: Avant de modifier un flux de navigation, nous devons nous assurer qu'il est inactif.\n",
      "\n",
      "Generating audio for segment 25...\n",
      "\n",
      "--- Segment 26 (Start: 189s) ---\n",
      "Translated text: En cliquant dessus, vous le rendrez inactif.\n",
      "\n",
      "Generating audio for segment 26...\n",
      "\n",
      "--- Segment 27 (Start: 194s) ---\n",
      "Translated text: Pour configurer le flux de navigation.\n",
      "\n",
      "Generating audio for segment 27...\n",
      "\n",
      "--- Segment 28 (Start: 198s) ---\n",
      "Translated text: Je vais cliquer sur le nom du flux de navigation SM.\n",
      "\n",
      "Generating audio for segment 28...\n",
      "\n",
      "--- Segment 29 (Start: 206s) ---\n",
      "Translated text: Et nous pouvons commencer à apporter des changements ici.\n",
      "\n",
      "Generating audio for segment 29...\n",
      "\n",
      "--- Segment 30 (Start: 209s) ---\n",
      "Translated text: Une fois que j'ai cliqué et navigué vers ce flux, vous pouvez voir ici le type qui définit le cluster.\n",
      "\n",
      "Generating audio for segment 30...\n",
      "\n",
      "--- Segment 31 (Start: 221s) ---\n",
      "Translated text: Ou est-ce une carte ?\n",
      "\n",
      "Generating audio for segment 31...\n",
      "\n",
      "--- Segment 32 (Start: 223s) ---\n",
      "Translated text: Et l'état de visibilité activé ou désactivé.\n",
      "\n",
      "Generating audio for segment 32...\n",
      "\n",
      "--- Segment 33 (Start: 231s) ---\n",
      "Translated text: L'ordre dans lequel vous pouvez trier.\n",
      "\n",
      "Generating audio for segment 33...\n",
      "\n",
      "--- Segment 34 (Start: 234s) ---\n",
      "Translated text: Et l'option de suppression.\n",
      "\n",
      "Generating audio for segment 34...\n",
      "\n",
      "--- Segment 35 (Start: 238s) ---\n",
      "Translated text: À partir de cette navigation.\n",
      "\n",
      "Generating audio for segment 35...\n",
      "\n",
      "--- Segment 36 (Start: 241s) ---\n",
      "Translated text: Pour cette démonstration, activons les fonctionnalités financières.\n",
      "\n",
      "Generating audio for segment 36...\n",
      "\n",
      "--- Segment 37 (Start: 247s) ---\n",
      "Translated text: Nous allons développer le secteur financier, qui sera un ensemble comprenant plusieurs cartes.\n",
      "\n",
      "Generating audio for segment 37...\n",
      "\n",
      "--- Segment 38 (Start: 256s) ---\n",
      "Translated text: Je vais déplacer cette carte vers le haut car je veux voir les revenus en premier.\n",
      "\n",
      "Generating audio for segment 38...\n",
      "\n",
      "--- Segment 39 (Start: 265s) ---\n",
      "Translated text: Et je vais faire s'effondrer les dernières coquilles.\n",
      "\n",
      "Generating audio for segment 39...\n",
      "\n",
      "--- Segment 40 (Start: 270s) ---\n",
      "Translated text: Il y a maintenant une modélisation stratégique activée, je vais la désactiver.\n",
      "\n",
      "Generating audio for segment 40...\n",
      "\n",
      "--- Segment 41 (Start: 276s) ---\n",
      "Translated text: De plus, j'ai l'autorisation d'assigner à un groupe spécifique.\n",
      "\n",
      "Generating audio for segment 41...\n",
      "\n",
      "--- Segment 42 (Start: 284s) ---\n",
      "Translated text: Ou un rôle d'utilisateur spécifique.\n",
      "\n",
      "Generating audio for segment 42...\n",
      "\n",
      "--- Segment 43 (Start: 287s) ---\n",
      "Translated text: Cela permettra uniquement aux utilisateurs appartenant à ces groupes ou rôles d'accéder à ce flux de navigation.\n",
      "\n",
      "Generating audio for segment 43...\n",
      "\n",
      "--- Segment 44 (Start: 297s) ---\n",
      "Translated text: Cela aide à maintenir la sécurité et à limiter l'accès des départements à ces modules financiers.\n",
      "\n",
      "Generating audio for segment 44...\n",
      "\n",
      "--- Segment 45 (Start: 307s) ---\n",
      "Translated text: Nous allons enregistrer et fermer.\n",
      "\n",
      "Generating audio for segment 45...\n",
      "\n",
      "--- Segment 46 (Start: 313s) ---\n",
      "Translated text: Une fois que j'aurai terminé toutes les modifications, je devrai le réactiver, ce qui permettra de lancer le flux de navigation en cliquant dessus.\n",
      "\n",
      "Generating audio for segment 46...\n",
      "\n",
      "--- Segment 47 (Start: 323s) ---\n",
      "Translated text: Pour actualiser le flux, je vais retourner à la page d'accueil où je vois encore l'ancienne version.\n",
      "\n",
      "Generating audio for segment 47...\n",
      "\n",
      "--- Segment 48 (Start: 330s) ---\n",
      "Translated text: Je ne vois pas la carte financière et je vois la stratégie que je ne devrais pas voir. Je dois donc cliquer sur les quatre points et actualiser le flux de navigation à partir de ce bouton de rafraîchissement.\n",
      "\n",
      "Generating audio for segment 48...\n",
      "\n",
      "--- Segment 49 (Start: 347s) ---\n",
      "Translated text: Une fois que j'aurai fait cela, vous pourrez voir que j'ai une nouvelle carte de finances.\n",
      "\n",
      "Generating audio for segment 49...\n",
      "\n",
      "--- Segment 50 (Start: 354s) ---\n",
      "Translated text: Je ne verrai pas la carte de modélisation stratégique.\n",
      "\n",
      "Generating audio for segment 50...\n",
      "\n",
      "--- Segment 51 (Start: 356s) ---\n",
      "Translated text: En cliquant sur le cluster financier, vous pouvez voir plusieurs cartes, et vous remarquerez que nous avons déplacé le chiffre d'affaires en haut pour qu'il s'affiche en premier.\n",
      "\n",
      "Generating audio for segment 51...\n",
      "\n",
      "--- Segment 52 (Start: 369s) ---\n",
      "Translated text: Permettez-moi de cliquer sur le revenu, et cela affichera le revenu pour votre exercice 2023. Vous pourrez voir les données financières consolidées sous plusieurs formes graphiques.\n",
      "\n",
      "Generating audio for segment 52...\n",
      "\n",
      "--- Segment 53 (Start: 388s) ---\n",
      "Translated text: Nous pouvons survoler ces options pour afficher plus de détails sur les différentes vues graphiques contenant toutes les données.\n",
      "\n",
      "Generating audio for segment 53...\n",
      "\n",
      "--- Segment 54 (Start: 399s) ---\n",
      "Translated text: Vous remarquerez que nous avons plusieurs onglets. En cliquant sur ces onglets, vous accédez à des vues offrant des détails plus précis sur les revenus.\n",
      "\n",
      "Generating audio for segment 54...\n",
      "\n",
      "--- Segment 55 (Start: 410s) ---\n",
      "Translated text: Il y a également des onglets en haut.\n",
      "\n",
      "Generating audio for segment 55...\n",
      "\n",
      "--- Segment 56 (Start: 413s) ---\n",
      "Translated text: Les onglets en bas vous permettent d'accéder directement à chaque tableau de bord en cliquant simplement dessus.\n",
      "\n",
      "Generating audio for segment 56...\n",
      "\n",
      "--- Segment 57 (Start: 422s) ---\n",
      "Translated text: Survoler la vue graphique.\n",
      "\n",
      "Generating audio for segment 57...\n",
      "\n",
      "--- Segment 58 (Start: 426s) ---\n",
      "Translated text: Vous pouvez consulter des informations plus détaillées.\n",
      "\n",
      "Generating audio for segment 58...\n",
      "\n",
      "--- Segment 59 (Start: 432s) ---\n",
      "Translated text: Dans cette démonstration, nous avons exploré notre flux de navigation et la manière dont nous pouvons personnaliser et attribuer des autorisations aux groupes d'utilisateurs.\n",
      "\n",
      "Generating audio for segment 59...\n",
      "Final synchronized audio saved as final_french_voice.mp3\n",
      "Merging the French audio with the original video...\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'https://clipchamp.com', 'comment': 'Create videos with https://clipchamp.com/en/video-editor - free online video editor, video compressor, video converter.'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [3840, 2160], 'bitrate': 4947, 'fps': 30.0, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 48000, 'bitrate': 192, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 440.6, 'bitrate': 5146, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [3840, 2160], 'video_bitrate': 4947, 'video_fps': 30.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 48000, 'audio_bitrate': 192, 'video_duration': 440.6, 'video_n_frames': 13218}\n",
      "c:\\AI PROJECTS\\video_transcript\\myenv\\Lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe -i Navigation_Flow_COM.mp4 -loglevel error -f image2pipe -vf scale=3840:2160 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Building video Navigation_Flow_COM_French.mp4.\n",
      "MoviePy - Writing audio in Navigation_Flow_COM_FrenchTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video Navigation_Flow_COM_French.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready Navigation_Flow_COM_French.mp4\n",
      "Final video saved as Navigation_Flow_COM_French.mp4\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import openai\n",
    "import edge_tts\n",
    "from pydub.utils import which\n",
    "from pydub import AudioSegment\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# Set your OpenAI API key (if using translation/improvement)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# TTS settings for French voice\n",
    "FRENCH_VOICE = \"fr-CA-SylvieNeural\"  # Adjust if needed\n",
    "FRENCH_RATE = \"-10%\"  # Slightly slower for clarity\n",
    "\n",
    "# Original video file path\n",
    "VIDEO_PATH = \"Navigation_Flow_COM.mp4\"  # Replace with your MP4 video file\n",
    "OUTPUT_VIDEO = \"Navigation_Flow_COM_French.mp4\"\n",
    "\n",
    "# Final concatenated audio file name\n",
    "FINAL_AUDIO_FILE = \"final_french_voice.mp3\"\n",
    "\n",
    "# Temporary folder to store audio segments\n",
    "SEGMENTS_DIR = \"segments_temp\"\n",
    "os.makedirs(SEGMENTS_DIR, exist_ok=True)\n",
    "\n",
    "# --- Set FFmpeg Path ---\n",
    "\n",
    "# Manually set the path to FFmpeg to ensure the correct version is used\n",
    "os.environ[\"PATH\"] = r\"C:\\ffmpeg\\bin\" + \";\" + os.environ[\"PATH\"]\n",
    "\n",
    "# Ensure that the path is correctly detected\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "print(f\"FFmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "\n",
    "# --- FUNCTIONS ---\n",
    "\n",
    "def parse_transcript(transcript: str):\n",
    "    \"\"\"\n",
    "    Parse a transcript with timestamps in the format 'mm:ss: text' (one per line)\n",
    "    and return a list of segments: (start_time_seconds, text)\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    # Regex pattern for lines like \"0:00: In this demo...\"\n",
    "    pattern = r'^\\s*(\\d{1,2}):(\\d{2}):\\s*(.*)$'\n",
    "    for line in transcript.splitlines():\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            minutes, seconds, text = match.groups()\n",
    "            start_time = int(minutes) * 60 + int(seconds)\n",
    "            segments.append((start_time, text.strip()))\n",
    "    return segments\n",
    "\n",
    "def improve_translation(text: str) -> str:\n",
    "    \"\"\"\n",
    "    (Optional) Use OpenAI's LLM to translate/improve the text into natural French.\n",
    "    If you don't need this step, simply return the original text.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Please translate the following text into natural, fluent French, \"\n",
    "        \"improving the wording for clarity:\\n\\n\" + text\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",  # or \"gpt-3.5-turbo\"\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    translated_text = response.choices[0].message[\"content\"].strip()\n",
    "    return translated_text\n",
    "\n",
    "async def generate_segment_audio(text: str, output_file: str, voice: str = FRENCH_VOICE, rate: str = FRENCH_RATE):\n",
    "    \"\"\"\n",
    "    Asynchronously generate TTS audio for the given text segment using Edge-TTS.\n",
    "    \"\"\"\n",
    "    communicator = edge_tts.Communicate(text, voice, rate=rate)\n",
    "    await communicator.save(output_file)\n",
    "\n",
    "def run_generate_audio_for_segment(text: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Run the asynchronous TTS generation for a segment.\n",
    "    \"\"\"\n",
    "    nest_asyncio.apply()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(generate_segment_audio(text, output_file))\n",
    "\n",
    "def create_synchronized_audio(segments, final_output=FINAL_AUDIO_FILE):\n",
    "    \"\"\"\n",
    "    Generate audio for each transcript segment, pad/truncate to match the intended duration,\n",
    "    and concatenate them into one final audio file.\n",
    "    \n",
    "    Parameters:\n",
    "      segments: list of tuples (start_time, text)\n",
    "    \"\"\"\n",
    "    audio_segments = []\n",
    "    num_segments = len(segments)\n",
    "    \n",
    "    for i, (start_time, text) in enumerate(segments):\n",
    "        translated_text = improve_translation(text) # use translated_text = text if you don't want to use OpenAI for translation\n",
    "        \n",
    "        # Add validation for the translated text\n",
    "        if not translated_text or len(translated_text.strip()) == 0:\n",
    "            raise ValueError(f\"Segment {i} (start: {start_time}s) has empty translated text!\")\n",
    "        \n",
    "        print(f\"\\n--- Segment {i} (Start: {start_time}s) ---\")\n",
    "        print(f\"Translated text: {translated_text}\\n\")  # <-- Critical for debugging\n",
    "        \n",
    "        segment_filename = os.path.join(SEGMENTS_DIR, f\"segment_{i}.mp3\")\n",
    "        print(f\"Generating audio for segment {i}...\")\n",
    "        run_generate_audio_for_segment(translated_text, segment_filename)\n",
    "        segment_audio = AudioSegment.from_file(segment_filename)\n",
    "        \n",
    "        # Determine intended duration (if not the last segment, use difference to next segment's start time)\n",
    "        if i < num_segments - 1:\n",
    "            next_start = segments[i+1][0]\n",
    "            intended_duration_ms = (next_start - start_time) * 1000\n",
    "        else:\n",
    "            intended_duration_ms = len(segment_audio)\n",
    "        \n",
    "        # Adjust the segment audio length:\n",
    "        if len(segment_audio) < intended_duration_ms:\n",
    "            # Append silence if audio is shorter than intended\n",
    "            silence = AudioSegment.silent(duration=intended_duration_ms - len(segment_audio))\n",
    "            segment_audio = segment_audio + silence\n",
    "        else:\n",
    "            # Truncate if longer\n",
    "            segment_audio = segment_audio[:intended_duration_ms]\n",
    "        \n",
    "        # If this is the first segment and it doesn't start at time 0, add leading silence.\n",
    "        if i == 0 and start_time > 0:\n",
    "            leading_silence = AudioSegment.silent(duration=start_time * 1000)\n",
    "            audio_segments.append(leading_silence)\n",
    "        \n",
    "        audio_segments.append(segment_audio)\n",
    "    \n",
    "    # Concatenate all segments\n",
    "    final_audio = sum(audio_segments)\n",
    "    final_audio.export(final_output, format=\"mp3\")\n",
    "    print(f\"Final synchronized audio saved as {final_output}\")\n",
    "    return final_output\n",
    "\n",
    "def merge_audio_with_video(video_path: str, audio_path: str, output_video: str = OUTPUT_VIDEO):\n",
    "    \"\"\"\n",
    "    Merge the final French audio with the original video.\n",
    "    \"\"\"\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "    final_video = video_clip.with_audio(audio_clip)\n",
    "    final_video.write_videofile(output_video, codec=\"libx264\", audio_codec=\"aac\")\n",
    "    print(f\"Final video saved as {output_video}\")\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample transcript with timestamps\n",
    "    transcript_text = \"\"\"0:00: In this demo, we will explore about navigation flow.\n",
    "0:06: And how we can customize and assign provisions to user groups.\n",
    "0:12: Navigation flow enhances user experience with intuitive structured pathways for effortless navigation across modules and tasks.\n",
    "0:24: Enables smooth transition between data entry, reporting, and process management, optimizing efficiency within planning and analytics workflows.\n",
    "0:38: Once a user has logged into EPM planning application, they will see this landing page.\n",
    "0:47: Clicking on the 4 dots on the right corner, you will see.\n",
    "0:54: All the active navigation flows for this application.\n",
    "0:59: EPM planning comes with default navigation flow.\n",
    "1:06: You can toggle to different navigation flow simply by clicking on it.\n",
    "1:13: Let's click on EBM cloud navigation flow.\n",
    "1:18: You can see all the cards and cluster enabled for this particular navigation flow.\n",
    "1:27: Now let's toggle back to the SM flow navigation flow.\n",
    "1:35: And we will take a look at how we can customize the SM navigation flow.\n",
    "1:42: You can see on the screen we have 6 cards and cluster.\n",
    "1:48: Cluster is group of cuts.\n",
    "1:54: And we are going to enable a new cluster called Financials, and we're going to disable the cluster strategic modeling in this demo.\n",
    "2:08: To configure navigation flow, a user needs to have service admin access.\n",
    "2:16: Now clicking on tools.\n",
    "2:20: You will see the cluster navigation flow.\n",
    "2:25: Here you can see multiple navigation flows configured and some of them are active.\n",
    "2:34: And some of them are inactive.\n",
    "2:39: You can select a navigation flow.\n",
    "2:43: And clicking on the action gear on the right corner.\n",
    "2:49: We'll let you to copy this navigation flow.\n",
    "2:54: Delete and validate.\n",
    "3:00: Before modifying any navigation flow, we need to make sure the navigation flow is inactive.\n",
    "3:09: So clicking on it will make it inactive.\n",
    "3:14: To configure the navigation flow.\n",
    "3:18: I'm going to click on the SM navigation flow name.\n",
    "3:26: And we can start making changes here.\n",
    "3:29: Once I have clicked and navigated to this flow, and here you can see the type where it defines the cluster.\n",
    "3:41: Or it's a card?\n",
    "3:43: And the state of visibility enable or disabled.\n",
    "3:51: The order which you can sort.\n",
    "3:54: And the option to delete.\n",
    "3:58: From this navigation.\n",
    "4:01: For this demo, let's enable financials.\n",
    "4:07: We're going to expand financials, so financials is a cluster, and it will have multiple cards.\n",
    "4:16: I'm going to move this card up because I want to see revenue first.\n",
    "4:25: And I'm going to collapse the final shells.\n",
    "4:30: Now, there is strategic modeling enabled, I'm going to disable this.\n",
    "4:36: And also, I have the permission to assign to a particular group.\n",
    "4:44: Or particular user role.\n",
    "4:47: And this will allow only users belonging to those groups or roles to access this navigation flow.\n",
    "4:57: So it helps in maintaining security and limiting departments from accessing these financial modules.\n",
    "5:07: We're going to save and close.\n",
    "5:13: And once I'm done with all the changes, I will have to activate this back, so clicking on it will activate the navigation flow.\n",
    "5:23: Now to refresh the flow, I'm going to go to the homepage where I'm still seeing the old view.\n",
    "5:30: I don't see the financial card and I'm seeing the strategy which I should not be seeing, so I need to go to the 4 dots and refresh the navigation flow from this refresh button.\n",
    "5:47: Once I do that, you can see I have a new card financials.\n",
    "5:54: I won't see the strategic modeling card.\n",
    "5:56: And clicking on the financial cluster, you can see multiple cards and you can see revenue as we moved it to the top to display on the first.\n",
    "6:09: So let me click on revenue, and it shows the revenue for your FY 23, and you can see consolidated financial data in multiple graphical views.\n",
    "6:28: We can hover over these options to see more details for different graphical views with all the data.\n",
    "6:39: You can notice that we have multiple tabs, and clicking on those tabs takes us to those views with more detailed revenue details.\n",
    "6:50: There are also tabs on the top.\n",
    "6:53: And the tabs on the bottom, and just clicking on them will take you to that particular dashboard.\n",
    "7:02: Hovering over the graphical view.\n",
    "7:06: You can see more detailed information.\n",
    "7:12: In this demo we explored our navigation flow and how we can customize and assign permissions to user groups.\"\"\"\n",
    "\n",
    "    # --- Parse the transcript ---\n",
    "    segments = parse_transcript(transcript_text)\n",
    "    if not segments:\n",
    "        print(\"No segments found. Please check your transcript format.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # --- Create the synchronized audio track from segments ---\n",
    "    final_audio_file = create_synchronized_audio(segments, final_output=FINAL_AUDIO_FILE)\n",
    "    \n",
    "    # --- Merge the generated French audio with the original video ---\n",
    "    print(\"Merging the French audio with the original video...\")\n",
    "    merge_audio_with_video(VIDEO_PATH, final_audio_file, output_video=OUTPUT_VIDEO)\n",
    "    print(\"Process completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if file exists: segments_temp\\segment_0.mp3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "segment_filename = os.path.join(\"segments_temp\", \"segment_0.mp3\")\n",
    "\n",
    "print(f\"Checking if file exists: {segment_filename}\")\n",
    "print(os.path.exists(segment_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading audio: [WinError 2] Le fichier spécifié est introuvable\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "try:\n",
    "    audio = AudioSegment.from_file(\"segments_temp/segment_0.mp3\")\n",
    "    print(\"Audio loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading audio: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to file: segments_temp/segment_0.mp3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "segment_filename = \"segments_temp/segment_0.mp3\"\n",
    "print(f\"Path to file: {segment_filename}\")\n",
    "print(os.path.exists(segment_filename))  # Check if file exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading audio: [WinError 2] Le fichier spécifié est introuvable\n"
     ]
    }
   ],
   "source": [
    "from pydub.utils import which\n",
    "AudioSegment.ffmpeg = r\"C:\\ffmpeg\\bin\\ffmpeg.exe\"  # Replace with your actual path to ffmpeg.exe\n",
    "\n",
    "# Now try loading the audio again\n",
    "try:\n",
    "    audio = AudioSegment.from_mp3(r\"C:\\AI PROJECTS\\video_transcript\\segments_temp\\segment_0.mp3\")\n",
    "    print(\"Audio loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading audio: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg found at: C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\ffmpeg.exe\n"
     ]
    }
   ],
   "source": [
    "from pydub.utils import which\n",
    "\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "print(f\"FFmpeg found at: {ffmpeg_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.utils import which\n",
    "AudioSegment.ffmpeg = r\"C:\\ffmpeg\\bin\\ffmpeg.exe\"  # Replace with your actual path to ffmpeg.exe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg found at: C:\\ffmpeg\\bin\\ffmpeg.exe\n",
      "Audio loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub.utils import which\n",
    "\n",
    "# Manually set the path to FFmpeg to ensure correct version is used\n",
    "os.environ[\"PATH\"] = r\"C:\\ffmpeg\\bin\" + \";\" + os.environ[\"PATH\"]\n",
    "\n",
    "# Now import AudioSegment after updating the path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Ensure that the path is correctly detected\n",
    "ffmpeg_path = which(\"ffmpeg\")\n",
    "print(f\"FFmpeg found at: {ffmpeg_path}\")\n",
    "\n",
    "# Try loading the audio again\n",
    "try:\n",
    "    audio = AudioSegment.from_mp3(r\"C:\\AI PROJECTS\\video_transcript\\segments_temp\\segment_0.mp3\")\n",
    "    print(\"Audio loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading audio: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
